\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Markov chain Monte Carlo} \label{MCMC}

This appendix outlines the basic theory and implementation of Markov chain Monte Carlo (MCMC) methods.
Any reader interested in more technical details or proofs of the results here should consult the references within.

\section{Metropolis-Hastings}

A common way of constructing a Markov chain with $p(\psi \mid y)$ as its stationary distribution is using the Metropolis-Hastings algorithm~\autocite{hastingsMCMC}.
The algorithm requires a proposal distribution $q(\psi' \mid \psi)$, which proposes that the chain moves to a new state $\psi'$ from its current state $\psi$; $\pi(\psi)$, a calculation of $p(\psi \mid y)$ up to some constant.
At each iteration, a proposal is draw from $q$ and then accepted or rejected based on the \emph{acceptance ratio}, computed using $\pi$.
The full algorithm is given in \cref{inc-prev:algorithm:MH}, with further details in available in a wide-range of sources~\autocites[e.g.][]{brooksMCMCNotes}[chapter 11]{gelmanBDA}.
\begin{algorithm}
 set $\psi^0$ to some initial value\;
 \For{$i = 1, \dots, M$}{
  sample a proposal $\psi' \sim q(\psi' \mid \psi)$ \;
  calculate the acceptance probability $\alpha(\psi, \psi') = \min \left( 1, \frac{\pi(\psi') q(\psi \mid \psi')}{\pi(\psi) q(\psi' \mid \psi)} \right)$ \;
  with probability $\alpha(\psi, \psi')$ set $\psi^i$ to $\psi'$, otherwise set $\psi^i$ to $\psi^{i-1}$ \;
 }
 \caption{The Metropolis-Hastings algorithm.}
 \label{inc-prev:algorithm:MH}
\end{algorithm}

The proposal distribution $q$ is most commonly a (possibly multivariate) Normal distribution centred on $\psi$; this scheme is used in \cref{E-SEIR}.
Tuning the proposal distribution to propose ``good'' moves is a key part of MCMC.
The ideal proposal distribution is the posterior of interest, however, this is impossible because that is what MCMC is trying to estimate~\autocite[296]{gelmanBDA}.
One alternative is \emph{adaptive} algorithms which tune the proposal distribution based on previous draws in an attempt to approximate the posterior; I use such a scheme in \cref{E-SEIR:sec:inference}.

\section{Improving MCMC efficiency}

MCMC using a Normal proposal distribution can be inefficient.
In particular, it often poorly explores the tails of the posterior in finite time~\autocite[e.g.][]{turitsynIrreversible}.
\emph{Hamiltonian Monte Carlo} (HMC)~\autocite{nealMCMC,nealImproved,duaneHybrid} improves the proposals by using information from the gradient of the posterior density (taken with respect to the parameters).
HMC simulates a physical system travelling through the posterior space with momentum.
The momentum increases in the direction the posterior density increases, using the gradient.
This means that the sampler tends to propose moves with higher posterior density.
The Metropolis-Hastings algorithm is then used to accept or reject the proposed move.

The \emph{No U-Turn Sampler} (NUTS)~\autocite{hoffmanNUTS} is a variant of HMC that automatically tunes the Hamiltonian dynamics hyperparameters.
NUTS has been implemented in a variety of software packages making it easy to apply to arbitrary posterior distributions.
I will make use of the implementation in the package \emph{Sampling through adaptive neighborhoods} (Stan)~\autocite{Stan-2-32-2}.
Stan implements \emph{automatic differentiation}~\autocite{griewankAutoDiff} to calculate the gradient of the posterior density without any user input.
Automatic differentiation uses the chain rule to calculate the gradient of a function from its code by breaking it down into a series of elementary operations, for which the gradient is known~\autocite{autodiff}.
For a more detailed introduction to HMC, NUTS, and Stan see \textcite[chapter 12]{gelmanBDA}.

\section{Convergence}

The simplest technique for assessing convergence is graphically, using traceplots~\autocite[81]{brooksMCMCNotes}.
Traceplots show the value of $\psi^i$ against $i$.
If the chain has converged, then the traceplot will show a random walk around the stationary distribution.
This can be improved by using multiple chains with different starting points~\autocite[283]{gelmanBDA}.
If all chains have converged, then they will be in the same location.

A more complex measure of convergence when running multiple MCMC chains is comparing the within-chain variance to the between-chains variance.
This is the basis of the Rhat statistic used throughout this thesis (see \cref{E-intro:sec:MCMC}).
The principle here is that if all chains have converged then they are sampling from the same distribution.
Therefore, the within-chain and between-chain variances are the same~\autocite[82]{brooksMCMCNotes}.

\end{document}