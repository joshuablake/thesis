\documentclass[thesis.tex]{subfiles}

\title{Estimating duration in the presence of misclassification}
\author{Joshua Blake}
\date{\today}

\begin{document}

\ifSubfilesClassLoaded{
  \setcounter{chapter}{6}
}

\chapter{Survival analysis with false negatives} \label{imperf-test}

In \cref{E-perf-test}, a framework for analysing the CIS to produce estimates of the duration of positivity was developed.
However, initial application of this framework produced implausibly short estimates; I identified the issue as being due to the presence of false negatives, a form of misclassification bias, within the CIS (\cref{imperf-test:sec:problem}).
There exists little prior work on the incorporation of misclassification bias within similar survival analysis frameworks.
\todo[inline]{Check exactly what has been done and verify exactly what I can claim here}
In this chapter, I modify the previous model to include false negatives (\cref{imperf-test:sec:modelling}).
I show in simulation that this model will recover the duration distribution (\cref{imperf-test:sec:sim-study-results}) and apply it to the CIS data (\cref{imperf-test:sec:application}).
Plausible estimates of the duration distribution are produced, however, they require assuming that the test sensitivity (the probability of testing positive given being detectable) is known; I discuss what would be required to relax this assumption in \cref{imperf-test:sec:discussion}.

\section{The problem} \label{imperf-test:sec:problem}

Applying the method of \cref{E-perf-test} to CIS data gave implausible estimates of the duration distribution (see \cref{imperf-test:fig:problem-cis-estimates}).
In particular, I estimate a very high probability of the episode lasting less than five days, in conflict with the results of \cref{E-ATACCC} and other prior work~\autocite[e.g.:][]{cevikShedding}.

\begin{figure}
  \centering %\includegraphic{}
  \todo[inline]{Figure showing estimates without false negatives}
  \caption[Estimating survival using CIS data assuming perfect testing]{Estimating the survival function using CIS data and the model of \cref{E-perf-test} gives implausibly short estimates. \label{imperf-test:fig:problem-cis-estimates}}
\end{figure}

Comparing the simulated and CIS data suggested that this is due to the high frequency of single positive episodes in the CIS data.
A single positive episode is one in which the episode contains exactly one positive test, intuitively these cause short estimates because there is no lower bound on the length of time the episode lasts.
Furthermore, due to the truncation, there is little or no ability to upper bound the number of very short episodes because these would almost all be missed.
\Textcite{shenNonparametrica} (building on \textcite{panNote}) showed, in a related setting, that the maximum likelihood (frequentist) estimator is inconsistent and can lead to severe underestimation (bias) of the survival function.
While the result is not directly applicable, and can not simply be extended, to the more complex scenario within CIS, it does still build an intuition that these single positive episodes could be causing this issue.
Furthermore, simulations building in even a few excess single positive episodes led to problematic estimation even within the CIS setting.
\todo[inline]{My previous application and discussion of \textcite{shenNonparametrica} in this setting would need quite significant reworking to include; is this needed or is this slightly hand-wavy discussion enough?}

Discussion and interrogation of the data led me to believe the most likely reason for an unexpectedly high number of single positive episodes was the presence of false negatives, meaning a false negative as a negative test result returned by a detectable individual.
This can occur for a variety of reasons, most commonly that an individual swabs themselves poorly and hence the concentration of virus on the swab is too low to be detected by the PCR process (see \cref{E-intro:sec:PCR}).
Plausibly, a variety of other reasons could also lead to a false negative such as logistical issues or mislabelling of samples.
Consideration of these reasons are beyond the scope of this thesis, and I group all of these possible reasons together.

There are two strands of evidence that support this hypothesis.
First, it is well known that PCR testing can return false negatives \todo{refs for sensitivity} and I needed to explicitly include these in the viral load model of \cref{E-ATACCC}; they can be directly observed within CIS as intermittent negatives (see below).
Second, adjusting the simulation to include false negatives can reproduce both the CIS data more faithfully and exhibits the same issues when estimating the duration distribution (see \cref{imperf-test:sec:simulate}).

\todo[inline]{These next two paragraphs are kinda disjointed but not sure how to bring them in}

\emph{Intermittent negatives} are the clearest example of a false negative.
An intermittent negative is when an individual tests negative but tested positive previously and subsequently.
Intermittent negatives are stripped out when creating the dataset used for all duration analyses in this chapter (as described in \cref{E-episode-def}), but demonstrate that false negatives do occur.

Whether a future positive is part of the same episode of a reinfection is not always trivial; I rely on a process developed previously by Sarah Walker, see \cref{E-episode-def}.
However, up until the emergence of the Omicron variant, reinfections are rare, especially in a short time frame, and hence the tricky cases are rare until this time (late 2021).

\section{Simulating false negatives} \label{imperf-test:sec:simulate}

The simplest model for false negatives is a constant probability of returning a negative test even when detectable.
The probability of testing positive given being detectable is known as the test sensitivity.
The impact of a test sensitivity, $\psens$, less than perfect (\ie less than 100\%) is formalised by replacing the deterministic $y_i(t)$ with a random binary variable such that:
\begin{equation}
  \prob(Y_i(t) = 1) \begin{cases}
      \psens &b_i \leq t \leq e_i \\
      0 &\text{otherwise}
  \end{cases} 
\end{equation}
with $Y_i(t)$ still only defined for $t \in t_i$.
However, an implausibly low value for $\psens$ is required to reproduce the rate of single positive episodes seen in CIS.
\todo[inline]{Figure demonstrating this and references to what reasonable test sensitivities are, including the estimate from the ATACCC chapter}

More plausibly, the rate of false negatives varies over the course of an episode.
False negatives are more likely to occur when the viral load of an individual is low, because there is less virus in their body to be sampled.
Following the short, initial period of growth, viral load largely declines monotonically with time (see \cref{E-ATACCC}).
This suggests that a model with a declining test sensitivity as a function of time since infection might be more suitable.

\todo[inline]{Next paragraph needs editing for clarity}
Examination of the CIS data also provides evidence for a declining test sensitivity.
We can approximately bound the test sensitivity by assuming that all intermittent negatives are false negatives, that the negative following the last positive in an episode could be either a true or false negative, and all other negatives are true negatives.
The point estimate for the test sensitivity is the true positives / (true positives + false negatives).
In \cref{imperf-test:fig:bounding-cis-sensitivity} we consider the values produced by assuming the negative following the last positive in an episode could be either a true or false negative as a function of time since the individual was detected (\ie: the first positive test in the episode).
While the bounds are broad, they clearly suggest a declining test sensitivity over the course of an episode.
\begin{figure}
  \todo[inline]{Include the analysis of CIS data with bounding test sensitivity}
  \caption[Bounding test sensitivity using CIS data]{Bounding the test sensitivity using CIS data as a function of time since the infection was detected (see main text for explanation of how the bounds are formed).\label{imperf-test:fig:bounding-cis-sensitivity}}
\end{figure}

I propose the following model for test sensitivity compatible with \cref{imperf-test:fig:bounding-cis-sensitivity}, consisting of a linearly declining period then a constant period:
\begin{equation}
  p_\text{sens}(t) = \begin{cases}
    0.9 - \frac{0.9-0.5}{50}t &t \leq 50 \\
    0.5 &t > 50
  \end{cases}
\end{equation}
where $t$ is the time in days since infection.
Simulated data using this test sensitivity is much more similar to the data, while being more plausible than very low probabilities of false negatives.
\todo{Figure comparing the variable test sensitivity to fixed and CIS data}

\todo[inline]{Add the evidence that false negatives do create the ssame issue in inference in real and simulated data}

\section{Modelling} \label{imperf-test:sec:modelling}

In this section, I introduce a simple model of false negatives into the model of \cref{E-perf-test:sec:model}.
The simple model ensures the likelihood remains tractable.
This requires modifying both $p_{ia}$ to allow for the episode possibly being longer than observed, and $p_{it}$ to allow for additional episodes being missed.

A constant test sensitivity is assumed throughout this section.
Further work is required to introduce the more realistic varying test sensitivity (discussed in \cref{imperf-test:sec:discussion}).

\subsection{Modifying \texorpdfstring{$p_{ia}$}{pia}} \label{modifying-p_ia}

I modify $p_{ia}$ to allow the negative test following the last positive to be a false negative.
If it is a false negative, then we consider the episode's length right-censored.
However, if it is in fact a true negative, then we are in the same case as before with a bound on the length of the episode.
A mixture of these scenarios then forms the episode's likelihood contribution, with the mixture probability determined by the test sensitivity.

For tractability, assume that the negative test bounding the start of the infection, at $l_i^{(b)}$, is a true negative.
This assumption is reasonable because the test sensitivity is high early in an infection, therefore $l_i^{(b)}$ is unlikely to be a false negative.
\todo{Are these bounds correct?}
We will consider only the tests between $r_i^{(b)}$ and $l_i^{(e)}$ inclusive (the positive tests providing a lower bound on the length of the episode).
Denote these tests by $t'_i = \{ t \in t_i : r_i^{(b)} \leq t \leq l_i^{(e)} \}$ and their results by $y_i'$.
We know that the test results at times in $t_i'$ are either true positives or false negatives. 
By definition, the test at $r_i^{(e)}$ is a false negative if and only if $e_i > r_i^{(e)}$.
We proceed by considering the two cases.

First, if $e_i \leq r_i^{(e)}$.
In this case, the test at $r_i^{(e)}$ is a true negative, as are all other tests not in $t_i'$, and these occur with probability 1.
\begin{align}
&p(y_i', e_i \leq r_i^{(e)} | b_i, p_\text{sens}, \theta) \\
&= p(y_i', l_i^{(e)} \leq e_i \leq r_i^{(e)} | t_i, b_i, p_\text{sens}, \theta) \\ % &\text{as no false positives}
&= p(y_i' \mid l_i^{(e)} \leq e_i \leq r_i^{(e)}, t_i, b_i, p_\text{sens}, \theta) p(l_i^{(e)} \leq e_i \leq r_i^{(e)} | t_i, b_i, p_\text{sens}, \theta) \\
&= \left( \prod_{t \in t_i'} p_\text{sens}^{y_i(t)} (1 - p_\text{sens})^{(1 - y_i(t))} \right) \left( S_\theta(l_i^{(e)} - b_i - 1) - S_\theta(r_i^{(e)} - b_i - 1) \right)
\end{align}

Second, if $e_i > r_i^{(e)}$.
In this case, the test at $r_i^{(e)}$ is a false negative, occurring with probability $(1 - p_\text{sens})$, and we have no upper bound on the end of the infection.
\begin{align}
&p(y_i', e_i > r_i^{(e)} | b_i, p_\text{sens}, \theta) \\
&= p(y_i \mid e_i > r_i^{(e)}, t_i, b_i, p_\text{sens}, \theta) p(e_i > r_i^{(e)} | t_i, b_i, p_\text{sens}, \theta) \\
&= \left( \prod_{t \in t_i'} p_\text{sens}^{y_i(t)} (1 - p_\text{sens})^{(1 - y_i(t))} \right) (1 - p_\text{sens}) S_\theta(r_i^{(e)} - b_i - 1)
\end{align}

Combining the above, the replacement for $p_{ia}$ is:
\todo[inline]{Fix the length of the lines of these equations}
\begin{align}
p_{ia}'
&= p(y_i' \mid p_\text{sens}, \theta) \\
&= \sum_{b_i = l_i^{(b)}}^{r_i^{(b)}} \left( p(y_i', b_i, e_i \leq r_i^{(e)} \mid p_\text{sens}, \theta) p(y_i', b_i e_i > r_i^{(e)} \mid p_\text{sens}, \theta) \right) p(b_i \mid p_\text{sens}, \theta) \\
&= \left( \prod_{t \in t_i'} p_\text{sens}^{y_i(t)} (1 - p_\text{sens})^{(1 - y_i(t))} \right) \\ & \ \times \sum_{b_i = l_i^{(b)}}^{r_i^{(b)}} \left( S_\theta(l_i^{(e)} - b_i - 1) - S_\theta(r_i^{(e)} - b_i - 1) + (1 - p_\text{sens}) S_\theta(r_i^{(e)} - b_i - 1) \right) p(b_i \mid p_\text{sens}, \theta) \\
&= \left( \prod_{t \in t_i'} p_\text{sens}^{y_i(t)} (1 - p_\text{sens})^{(1 - y_i(t))} \right)\sum_{b_i = l_i^{(b)}}^{r_i^{(b)}} \left( S_\theta(l_i^{(e)} - b_i - 1) - p_\text{sens} S_\theta(r_i^{(e)} - b_i - 1) \right) p(b_i \mid p_\text{sens}, \theta).
\end{align}
Note that if $p_\text{sens} = 1$ then $p_{ia}' = p_{ia}$.

\subsection{Modifying \texorpdfstring{$p_{it}$}{pit}} \label{modifying-p_it}

With false negatives, an episode with can be undetected in the following
ways:

\begin{enumerate}
\item
  The episode begins before $\min(t_i)$ (assuming there is a
  negligible probability of a false negative test at this point).
\item
  The duration of the episode is less than $t_{ib_i}^N$. These first
  two mechanisms are how truncation previously occurred, with
  probability $p_{it}$.
\item
  The duration of the episode is at least as long as $t_{it}^N$ but
  less than the time to the second test after $t$, $t_{it}^{2N}$,
  and a false negative episode occurred at the first test after $t$.
  This occurs with probability:
  \begin{math}
    (1 - p_\text{sens})\frac{1}{T} \sum_{b=\min(t_i)}^T \left( S_\theta(t_{ib}^N + 1) - S_\theta(t_{ib}^{2N} + 1)\right).
  \end{math}
\item
  The duration of the episode is at least as long as $t_{it}^{2N}$,
  and all the tests within the episode (at least two) are false
  negatives. We assume this occurs with negligible probability.
\end{enumerate}

Hence, the replacement for $1 - p_{it}$ is:
\begin{align}
1 - p_{it}'
&= 1 - p_{it} - (1 - p_\text{sens})\frac{1}{T} \sum_{b=\min(t_i)}^T \left( S_\theta(t_{ib}^N + 1) - S_\theta(t_{ib}^{2N} + 1)\right) \\
&= \frac{1}{T} \sum_{b=\min(t_i)}^T \left( p_\text{sens} S_\theta(t_{ib}^N + 1) + (1 - p_\text{sens}) S_\theta(t_{ib}^{2N} + 1)\right) \\
\end{align}

\section{Simulation study results} \label{imperf-test:sec:sim-study-results}

\begin{itemize}
  \item When sensitivity is too bad (0.6), cannot recover the true distribution. The assumptions in the model, that the first test is a true positive and no missed infections prior, cannot hold.
  \item Assuming too low a test sensitivity (bottom left triangle) means that number of missed infections will be overestimated and the duration distribution will be overestimated (\ie episodes are too long on average).
\end{itemize}

\section{Application to CIS data} \label{imperf-test:sec:application}

\subsection{Data}

I use the CIS data described in \cref{E-intro:sec:cis}, with positive tests heuristically divided into episodes.
Prior work categorised a series of positive tests within the same individual CIS were heuristically categorised into episodes (see \cref{E-episode-def}).

I filter the episodes as follows.
\begin{itemize}
\item
  The first positive in the episode occurred between 16th Oct 2020 and
  5th Dec 2020 inclusive.
\item
  The individual had recorded a negative test prior to their episode
  beginning (this could have happened at any time, including prior to
  16th Oct).
\item
  A negative test to end the episode (\ie: following the final positive in the episode) has been recorded.
\end{itemize}

\todo[inline]{Descriptive analyses of the data here}

\subsection{Methods}

Think about what I need to include here.
Might include hyperparameters etc or assumptions made?

\subsection{Results}

\section{Discussion} \label{imperf-test:sec:discussion}

\begin{itemize}
  \item Survival prior matters for quantitative details but not qualitative shape. 
  \item Number of missed infections prior is more important.
  \item Unclear why this is the case, probably model misspecification meaning that fewer missed infections than expected.
  \item Two possible misspecifications: test sensitivity (not constant) and constant incidence.
\end{itemize}

\section{Conclusion} \label{imperf-test:sec:conclusion}

\ifSubfilesClassLoaded{
  \listoftodos
}{}

\end{document}