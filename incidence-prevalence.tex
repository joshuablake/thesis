\documentclass[thesis.tex]{subfiles}

\begin{document}
\ifSubfilesClassLoaded{
  \setcounter{chapter}{2}
}

\chapter{Statistical and epidemiological background} \label{inc-prev}

%\todo[inline]{This chapter is pretty short. Not sure if this matters or it needs to merged with another chapter? For example, one background chapter split into epi/biology and stats.}

This chapter defines incidence and prevalence, and the relationship between these quantities.
In the course of explaining this relationship, it will become clear that the duration of PCR positivity, and its distribution in the population, is the vital parameter which will allow estimation of incidence from prevalence, a major aim of this thesis.
I start by defining these terms in \cref{inc-prev:sec:definitions}.
I then move on to explaining the three processes that are involved: the \emph{infection process}, the \emph{prevalence process} and the \emph{observation process}.
The infection process (\cref{inc-prev:sec:infection-process}) models how infections arise.
The concepts here are well-established within infectious disease epidemiology (see\todo{ref intro chapter}).
The prevalence process describes the relationship between incidence and prevalence.
Here, I adapt previous work to the SARS-CoV-2 context.
In particular, the recoveries need explicit modelling which was not required for HIV/AIDS.
The observation process describes the relationship between prevalence and the observed data.
Unlike in HIV/AIDS backcalculation, the CIS has a sampling mechanism that needs to be modelled.
This model is guided by its specific study design of the CIS.
Therefore, the model is specific to this context, although much would be applicable to other, similarly designed prevalence surveys.
Finally, \cref{inc-prev:sec:MCMC} will introduce Markov chain Monte Carlo (MCMC), an inference technique I will make extensive use of in this thesis, before \cref{inc-prev:sec:conclusion} concludes the chapter.

\section{Definitions} \label{inc-prev:sec:definitions}

Time will be considered discrete in this chapter.
I use days, however, the results generalise in the obvious way to other time units.
Most epidemiological data is only available at daily granularity or, when more granular data exists, is often unreliable.
Furthermore, within-day patterns produce variations in transmission (\eg due to sleep) and data (\eg due to logistical considerations around collection); these variations are not of interest in most contexts.

\emph{Incidence} on day $t$, $Z_t$, is the number of people in a given population who become infected on day $t$; when expressed as a proportion of the population it is the \emph{incidence proportion}~\autocite[89]{lashModern}.
The incidence proportion is $Z_t/\Npop$, where $\Npop$ is the number of people in the population.
As discussed in\todo{ref intro}, the timing of infection events is not directly observable and must be inferred from other data.
Despite this issue, it remains the single most important quantity for informing the response to an epidemic or pandemic.

\emph{Prevalence} of a disease on day $t$, is the number of people with the disease on that day~\autocite[90]{lashModern}.
What it means to have a disease can vary by context (see\todo{ref section discussing what it means to have covid}).
I define an individual to have SARS-CoV-2 on day $t$ if, had they been swabbed on day $t$, that swab would have returned a positive PCR test.
I refer to these individuals as \emph{prevalent} individuals.
I assume that an individual's prevalent status cannot change over the course of a day.
Therefore, prevalence is constant over any single day $t$.
I denote the number of prevalent individuals on day $t$ as $P_t$.
Therefore, the prevalence is $P_t/\Npop$.

Duration distributions can be expressed in several equivalent ways.
The duration distribution I will be concerned with is the distribution of the number of days for which an individual is prevalent.
Consider an individual $i$ infected on day $B_i$ that is prevalent during the interval $[B_i, E_i]$.
I define their \emph{infection episode} as beginning on day $B_i$ and ending on day $E_i$.
$D_i = E_i - B_i + 1$ is their \emph{duration of positivity}, the number of days for which they are prevalent.
I model each $D_i$ as a discrete independent and identically distributed random variable; extending the methodology to account for covariates is left to further work.
The duration is a positive integer, \ie $D \in \{1, 2, \dots\}$.
The first way of expressing the distribution of $D_i$ is as the standard probability mass function (pmf), $f_{D}(d) = \prob(D = d)$; or cumulative density function (CDF), $F_{D}(d) = \prob(D \leq d) = \sum_{i=0}^d f_{D}(i)$.
The \emph{survival function} gives the probability that the duration is at least $d$ days: $S(d) = \prob(D \geq d) = 1 - F_{D}(D - 1)$ with $S(1) = 1$~\autocite{yanDistribution}.
The \emph{hazard} at time $t$ is the probability of recovering at time $t$ conditional on having survived to time $t$: $\lambda(t) = \prob(D = t \mid D \geq t) = f_{D}(d) / S(d)$.
For discrete variables, the convention that the survival function is $\prob(D >d)$, rather than $\prob(D \geq d)$, is also commonly used, I adapt that latter convention.
Throughout this thesis, the survival function will be the primary quantity of interest, and it will normally be parameterised in terms of the hazard; these two quantities are related by $S(t) = \prod_{i=1}^{t-1} (1 - \lambda(i))$.


\section{Infection process} \label{inc-prev:sec:infection-process}
The infection process is a \emph{point} or \emph{counting} process, where each infection is an event.

A point process is a random function of continuous time $K(\tau)$.
$K(t)$ must take non-negative integer values and be non-decreasing in $\tau$.
The interpretation of $K(t)$ is the number of events, here infections, that have occurred in the interval $(-\infty, t]$~\autocites[244]{yanDistribution}.
In the context of a disease, the point process is discretised into incidence for integer $t$ as $Z_t = K(t) - K(t-1)$.

A counting process has \emph{independent increments} if the number of events in disjoint intervals are independent.
That is, for any $t_1 < t_2 < t_3 < t_4$, $K(t_2) - K(t_1)$ and $K(t_4) - K(t_3)$ are independent.

A commonly-used point process for infectious disease epidemiology is the time-inhomogenous Poisson process~\autocites{brookmeyerMethod}{paganoHIV}{rosenbergBackcalculation}{brookmeyerBackcalculation}.
A Poisson process is a point process with independent increments, and the property that $K(s) - K(t) \dist \Poi\left(\int_s^t \lambda(r) dr \right)$ where $\lambda(r) \geq 0$ is the \emph{intensity} of the epidemic at time $r$~\autocites[244]{yanDistribution}.
That is, a Poisson process where the intensity varies over time, and possibly with other covariates.
Extensions to this model can incorporate covariates, such as space or age~\autocite[e.g.][]{diggleModeling}.

The target of inference can be either the process's intensity or the counts of the specific realisation that occurred.
The realised counts are normally of greater interest because we care about the realised epidemic, not what may happen if there were future realisations of the same epidemic.
Furthermore, there is only one realisation of the epidemic, and hence

Two features of a Poisson process can be violated for epidemics.
Epidemics commonly exhibit overdispersion and have feedback loops.
Overdispersion means that the variance in the number of infections in a time interval is higher than its mean.
In a Poisson process these counts have a Poisson distribution, hence, their mean and variance are equal.
Feedback loops mean that the stochastically low or high numbers of infections, possibly due to overdispersion, affect the future number of infections.
This violates the assumption of independent increments.
Both of these features violate the properties of a Poisson process.
Despite these issues, consistent inference on the incidence can still be produced using the Poisson process model, although the uncertainty in the estimates may be understated~\autocite{beckerDependent}.

A common cause of overdispersion is super-spreading events~\autocite{lloyd-smithSuperspreading}.
A super-spreading event is an event where many more people than average are infected.
That is, $Z_t >> \E(Z_t)$ for some $t$ during which a super-spreading event occurs.
Coronaviruses, such as SARS-CoV-2, have particularly high overdispersion~\autocites{endoEstimating}{adamClustering}{mccloskeySARS}.
An infamous example of a SARS-CoV-2 super-spreading event was the Skagit County choir practice in March 2020~\autocite{hamnerHigh}.
One infected individual is thought to have infected at least 32 further individuals during a single choir practice.
For comparison, the average individual infected around three others in the early stages of the pandemic~\autocite{pellisChallenges}. 
Overdispersion could be incorporated by modelling the counts in a given time interval as a negative binomial, rather than Poisson, distribution.
The mean of these distributions is equal, but the negative binomial introduces an additional overdispersion parameter, commonly notated $k$.
The negative binomial tends to Poisson as $k\to\infty$.
Generally, $k<1$ is considered as significant levels of overdispersion.
Estimates for SARS-CoV-2 indicate $k \approx 0.1$~\autocite{endoEstimating}, increased by some interventions including lockdowns~\autocites{quiltyReconstructing}{quiltyUnderstanding}.
For a negative binomial process, the count's standard deviation scales on the order of the mean.
Conversely, for a Poisson process, the standard deviation is on the order of the square root of the mean.
A particular implication of this is that the coefficient of variation (the standard deviation divided by the mean) tends to zero for a Poisson process, but tends to a constant for a negative binomial process.
The disadvantage of the negative binomial distribution is that it loses much of the mathematical convenience of a Poisson distribution.

The independence assumption of a Poisson or negative binomial process is violated because if the number of infections is stochastically high (or low), this feeds back to the process intensity at future times.
This can be seen simply in the event of a super-spreading event.
If a super-spreading event occurs, then many more individuals than suggested by the process intensity will be infected.
These additional infections will propagate the epidemic further, increasing the intensity at future times.
Point processes can be extended to \emph{branching processes} to account for this feedback~\autocite[246]{yanDistribution}, although these are beyond the scope of this thesis.

An alternative to a Poisson process is \emph{mechanistic models}.
Mechanistic models explicitly describe the population and transmission between individuals.
They vary greatly in their details and realism~\autocite{murilloMultiscale}.
Mechanistic models are discussed further in \cref{E-SEIR}.

% In \emph{deterministic backcalculation}, the observed prevalence, $x_t/n_t$, is assumed to be equal to $P_t/\Npop$.
% However, this is often a poor approximation.
% \emph{Statistical backcalculation} retains the sampling distribution of $x_t$ (or an approximation of it, such as a Poisson).

% Define the first day of an infection episode in individual $i$ as $B_i$, and assume that the probability of $i$ being infected multiple times within the period of interest is negligible.
% The time between being infected and first being detectable is short (see\todo{ref relevant part}), and therefore I often assume that $B_i$ is the same as the time of infection.
% I keep this assumption for the remainder of this chapter.


% Backcalculation makes use of this relationship to estimate incidence from prevalence, assuming that the duration is known.

% Deterministic backcalculation assumes that the variance in the population is negligible, and therefore that the prevalence is equal to the mean prevalence.
% This is justified because the variance due to sampling is much larger than the variance due to the true prevalence.

\section{Prevalence process}

The relationship between incidence and prevalence can be derived by considering the probability that an individual is prevalent at any time following an infection.
I define the period the individual is prevalent for as their \emph{infection episode}.
I index infection episodes with $i$.
Denote the time that the infection episode begins as $B_i$ and the time it ends as $E_i \geq B_i$.
The individual is prevalent during the interval $[B_i, E_i]$ (\ie including $B_i$ and $E_i$).
The duration of the infection episode, the number of days for which they are prevalent, is $D_i = E_i - B_i + 1$.
I assume that the $D_i$s are iid, with a discrete distribution defined by $\prob(D_i = d) = f_D(d)$ for $d = 1, \dots, d_\text{max}$, for some maximum episode length $d_\text{max}$, and $\prob(D_i = d) = 0$ otherwise.
Denote by $F_D$ the cdf of $D_i$, that is $F_D(d) = \prob(D_i \leq d)$.

From this, we can derive the relationship between incidence and prevalence.
Denote by $R_{t,t'}$ be the number of infection episodes that begin at time $t$ and end at time $t'$.
For each infection beginning at $t$, the probability that it ends at $t'$ is $\prob(E_i = t' \mid B_i = t) = \prob(D_i = t' - t + 1 \mid B_i = t) = f_D(t' - t + 1)$.
Since these durations are assumed independent, the number of episodes of each duration is multinomially distributed~\autocite{paganoHIV}.
Therefore:
\begin{align}
\begin{bmatrix}
  R_{t,t} \\ R_{t,t+1} \\ \vdots \\ R_{t,t+d_\text{max}-1}
\end{bmatrix} \mid Z_t
\sim \MN \left(
  Z_t, 
  \begin{bmatrix}
    f_D(1) \\ f_D(2) \\ \vdots \\ f_D(d_\text{max})
  \end{bmatrix}
\right).
\end{align}
Now, denote by $P_{t_z,t_p}$ the number of infection episodes with $B_i = t_z$ and $E_i \geq t_p$.
Therefore, the individuals in which these infection episodes occur are prevalent at time $t_p$.
$P_{t_z,t_p}$ is $Z_{t_z}$ minus those that recover before $t_p$ (\ie at or up to $t_p - 1$).
Hence:
\begin{align}
    P_{t_z,t_p} = \begin{cases}
      0 &t_p < t_z\\
      Z_{t_z} - \sum_{i=0}^{t_p-t_z-1} R_{t_z,t_z+i} &t_z \leq t_p < t_z + d_\text{max}\\
      0 &t_p \geq t_z + d_\text{max}.
  \end{cases} \label{inc-prev:eq:Ptt-to-R}
\end{align}
Finally, the $P_t$ can be expressed as the total number of people prevalent at time $t$, regardless of when they were infected.
The limits of the sum are limited by the zeroes in \cref{inc-prev:eq:Ptt-to-R}.
\begin{align}
  P_t
  &= \sum_{t_z=-\infty}^\infty P_{t_z,t} \\
  &= \sum_{i=0}^{\dmax-1} P_{t-i,t} \label{inc-prev:eq:Pt-to-Ptt} \\
  &= \sum_{i=0}^{\dmax-1} \left(Z_{t_z} - \sum_{j=0}^{i-1} R_{t-i,t-i+j} \right) &\text{by \cref{inc-prev:eq:Ptt-to-R}}\label{inc-prev:eq:Pt-to-Rtt}.
\end{align}

In general, all the random variables in this section are dependent.
This is because they are linked by the $Z_t$s, which are themselves dependent (as explained in \cref{inc-prev:sec:infection-process}).
However, if we condition on the vector of incidence, $\vec{Z} = (Z_1, Z_2, \dots)^T$, then we will induce some independence.
This reduces the stochasticity to only that attributable to the prevalence process.
In particular, because the duration of individuals is independent, $R_{t_z,t_p}$ and $R_{t_z',t_p'}$ will be independent if $t_z \neq t_z'$; importantly, this holds even if $t_p = t_p'$.
Therefore, $P_{t_z,t_p}$ and $P_{t_z',t_p'}$ will be independent if $t_z \neq t_z'$.

In \cref{inc-prev:sec:observation-process} I will show that only $\E(P_t \mid \vec{Z})$ and bounds on $\V(P_t \mid \vec{Z})$ will be relevant.
These can be derived from their constituent parts.

Start by considering the recoveries.
The sum of recoveries of infections that occurred on the same day $t$ is the sum of multinomial cell probabilities, and hence binomially distributed~\autocite{alamAnalysis}.
Specifically:
\begin{align}
  \sum_{i=0}^{t'} R_{t,t+i} \mid \vec{Z} &\sim \text{Binomial}(Z_t, F_D(t'+1)). \label{inc-prev:eq:binomialRt}
\end{align}
where $F_D(t) = \sum_{i=1}^t f_D(t) = \prob(D \leq t)$ is the CDF of $D$.
Therefore:
\begin{align}
  \E \left( \sum_{i=0}^{t'} R_{t,t+i} \mid \vec{Z} \right) &= Z_t F_D(t'+1) \label{inc-prev:eq:EsumRt} \\
  \V \left( \sum_{i=0}^{t'} R_{t,t+i} \mid \vec{Z} \right) &= Z_t F_D(t'+1) (1 - F_D(t'+1)) \label{inc-prev:eq:VsumRt}
\end{align}

The first moment follows.
\begin{align}
\E(P_t \mid \vec{Z})
  &= \E\left(\sum_{i=0}^{d_\text{max}-1} \left( Z_{t-i} - \sum_{j=0}^{i-1} R_{t-i,t-i+j} \right) \mid \vec{Z} \right) &\text{by \cref{inc-prev:eq:Pt-to-Rtt}}\\
  &= \sum_{i=0}^{d_\text{max}-1} \left( Z_{t-i} - \sum_{j=0}^{i-1} \E( R_{t-i,t-i+j} \mid \vec{Z}) \right) \\
  &= \sum_{i=0}^{d_\text{max}-1} \left( Z_{t-i} - Z_{t-i} F_D(i) \right) &\text{by \cref{inc-prev:eq:EsumRt}}\\
  &= \sum_{i=0}^{d_\text{max}-1} Z_{t-i} (1 - F_D(i)) \\
  &= \sum_{i=0}^{d_\text{max}-1} Z_{t-i} S(i+1) \label{inc-prev:eq:EPt}
\end{align}
where $S(i+1) = 1-F_D(i) = \prob(D \geq i+1)$ is the \emph{survival function} of $D$.
The survival function will be further explored in \cref{inc-prev:sec:duration}.

The second moment is simplified by the independence.
\begin{align}
\V(P_t \mid \vec{Z})
  &= \V\left(\sum_{i=1}^{d_\text{max}-1} P_{t-i,t} \mid \vec{Z} \right) &\text{by \cref{inc-prev:eq:Pt-to-Ptt}} \\
  &= \sum_{i=1}^{d_\text{max}-1} \V\left(P_{t-i,t} \mid \vec{Z} \right) &\text{by the conditionl independence} \\
  &= \sum_{i=1}^{d_\text{max}-1} \V\left(\sum_{j=0}^{i-1} R_{t-i,t-i+j} \mid \vec{Z} \right) &\text{by~\cref{inc-prev:eq:Ptt-to-R}}\\
  &= \sum_{i=1}^{d_\text{max}-1} Z_{t-i} F_D(i) (1 - F_D(i)) &\text{by~\cref{inc-prev:eq:VsumRt}} \\
  &\leq \sum_{i=1}^{d_\text{max}-1} Z_{t-i} (1 - F_D(i)) &\text{as $F_D \leq 1$}\\
  &= \E(P_t \mid \vec{Z}). \label{inc-prev:eq:boundVPt}
\end{align}

% The probability of being positive can be modelled in different ways depending on what assumptions are most reasonable.
% The most important assumption from a statistical perspective is the whether the probability of testing positive on a given day is independent conditional on the infection time.

% \todo[inline]{Is the discussion of this model just a distraction?}
% Assuming that the probability of testing positive depends only on the infection time implies no individual variation.
% This model is formalised as $Pr(Z_i(t) = 1 \mid B_i, Z_i(1), Z_i(2) \dots) = Pr(Z_i(t) \mid B_i) = p_{t-B_i}$, that is the probability of individual $i$ testing positive $t$ days after infection depends only on the infection start time and no other quantities.
% A slight relaxation of this model is introducing covariates, allowing some variation based on an individual's characteristics.

% The model with the most dependence between times, while remaining realistic, is a multi-state model.
% Therefore, if an individual has tested negative before the present time $t$ but after $B_i$ then they will test negative at time $t$.
% The complexity of the transitions between positive and negative can be very complex.
% I consider a slight extension to allow for the possibility of false negatives, meaning a negative test between $B_i$ and $E_i$, and that this probability may change.
% This leads to the following model.
% \begin{align}
%   \prob(Z_i(t) = 1 \mid B_i, \leq E_i) &= \begin{cases}
%     \psens(t - B_i) &B_i \leq t \leq E_i\\
%     0 &\text{otherwise}
%   \end{cases}\\
%   \prob(E_i = t \mid B_i) = f_i(B_i)
% \end{align}
% Conditional on both $B_i$ and $E_i$, then $Z_i(t)$ and $Z_i(t')$ are independent for $t \neq t'$.
% However, unlike the previous model, conditioning only on $B_i$ is not sufficient for $Z_i(t)$ and $Z_i(t')$ to be independent because each $Z_i(t)$ provides information on $E_i(t)$ (in particular, $Z_i(t) = 1$ implies $E_i > t$).
% For SARS-CoV-2, the latter model is more appropriate, although, as we shall see, the assumption that $\psens$ is independent of $t$ is violated.

The expectation in \cref{inc-prev:eq:EPt} is a discrete convolution equation, specifically a discrete version of the Volterra equation of the first kind~\autocite{brookmeyerBackcalculation}.
\todo{Go back to this reference and clarify why this matters}
The variance is upper bounded by this expectation, a fact that will prove useful in \cref{inc-prev:sec:observation-process}.
\Cref{inc-prev:eq:EPt} shows that knowledge of the survival function, $S$, is crucial to the prevalence process; I will discuss $S$ further in \cref{inc-prev:sec:duration}.

\section{Observation process} \label{inc-prev:sec:observation-process}

% A \emph{prevalence survey} is a survey that tests a sample of the population for the presence of an infection.
% Series of prevalence surveys are the form of measuring prevalence that this thesis is concerned with.
% This thesis aims to infer the incidence rate from prevalence surveys.
% I use Bayesian inference, therefore the data contributes through the likelihood.
The previous sections have explained the processes leading to the population prevalence.
However, we do not directly observe the population prevalence but a sample of it.
This section describes the observation process, that is, the process by which the prevalence surveys are conducted.
The survey design considered here reflects the CIS, although is applicable to many randomly sampled prevalence survey with samples for all $t$.

On day $t$ (for $t = 1, \dots, T$) a prevalence survey such as the CIS samples $n_t$ individuals at random from the population of interest and tests if they are prevalent.
Therefore, I model the number of positive tests, $X_t$, as $X_t \mid P_t, n_t, \Npop \dist \Bin(n_t, P_t/\Npop)$.
The conditioning on $n_t$ and $\Npop$ is implicit in what follows.

The $X_t$s are conditionally independent, given the population prevalences at each time, $\vec{P} = (P_1, \dots, P_t)^T$. 
%For now, I assume that the sample is chosen uniformly at random from the population of interest.
%Assume that the surveys are independent of each other and $\vec{Z}$, conditional on the population prevalence at that time.
%The population prevalence is a latent quantity.
Prevalence surveys are used in this thesis to infer incidence.
I base this inference on the likelihood, $p(\vec{x} \mid \vec{Z})$.% = \int p(\vec{x} \mid \vec{P}) p(\vec{P} \mid \vec{Z}) d\vec{P} = \int \prod_t p(x_t \mid P_t) p(\vec{P} \mid \vec{Z}) d\vec{P}$, where $\vec{x} = (x_1, x_2, \dots)^T$.
Here $\vec{x} = (x_1, \dots, x_T)$ is the vector of observed number of positive tests in the prevalence survey on each day and $\vec{Z} = (Z_{-\dmax}, Z_{-\dmax+1} \dots, Z_T)$ is the vector of incidence on each day.
The incidence back to day $-\dmax$ will affect $P_1$ and therefore need to be included in $\vec{Z}$. 

This section argues that $p(\vec{x} \mid \vec{Z}) \approx \prob(\vec{X} = \vec{x} \mid \vec{P} = \E(\vec{P} \mid \vec{Z}))$.
As the $x_t$s are independent conditional on $\vec{P}$, it follows that $p(\vec{x} \mid \vec{Z}) \approx \prod_t \prob(X_t = x_t \mid P_t = \E(P_t \mid \vec{Z}))$.
This relationship will make inference for $\vec{Z}$ much simpler because the latent vector $\vec{P}$ and the dependence of the $x_t$s can be ignored.

The basis of the argument is that the first two moments of $\vec{x} \mid \vec{Z}$ and $\vec{X} \mid \vec{P} = \E(\vec{P} \mid \vec{Z})$ have negligible difference.
The first moment follows directly from the tower property of expectations.
The majority of the argument is to show that the variance-covariance matrix $\V(\vec{X} \mid \vec{Z}) \approx \V(\vec{X} \mid \vec{P} = \E(P \mid Z))$.
There are two steps to this argument.
I start with the diagonal elements, the variances.
I show that $\V(X_t \mid \vec{Z}) \approx \V(X_t \mid \vec{P} = \E(\vec{P} = \vec{Z}))$.
The conditional independence of the $x_t$s implies that the conditional covariances are 0.
Therefore, I show that the correlation between $X_t$ and $X_{t'}$ conditional only on $\vec{Z}$ is negligible.

Starting with the variances, by the law of total variance:
\begin{align}
  &\var\left( X_t \mid \vec{Z} \right) \\
    &= \var\left[\E\left( X_t \mid \vec{Z}, \vec{P} \right) \mid \vec{Z} \right] + \E\left[\var\left( X_t \mid \vec{Z}, \vec{P} \right) \mid \vec{Z} \right] \\
    &= \var\left( n_t \frac{P_t}{\Npop} \mid \vec{Z} \right) + \E\left( n_t \frac{P_t}{\Npop} \left(1 - \frac{P_t}{\Npop} \right) \mid \vec{Z} \right) \\
    &= \left( \frac{n_t}{\Npop} \right)^2 \var\left(P_t \mid \vec{Z} \right) + \frac{n_t}{\Npop} \E\left(P_t \mid \vec{Z} \right)  - \frac{n_t}{\Npop^2} \E\left(P_t^2 \mid \vec{Z} \right) \\
    &= \left( \frac{n_t}{\Npop} \right)^2 \var\left(P_t \mid \vec{Z} \right) + \frac{n_t}{\Npop} \E\left(P_t \mid \vec{Z} \right)  - \frac{n_t}{\Npop^2} \left(\E\left(P_t \mid \vec{Z} \right) ^ 2 + \V(P_t \mid \vec{X})\right) \\
    &= \frac{n_t(n_t - 1)}{\Npop^2} \var\left(P_t \mid \vec{Z} \right) + n_t \frac{\E\left(P_t \mid \vec{Z} \right)}{\Npop}\left(1 - \frac{\E\left(P_t \mid \vec{Z} \right)}{\Npop} \right) \\
    &= \frac{n_t(n_t - 1)}{\Npop^2} \var\left(P_t \mid \vec{Z} \right) + \V(X_t \mid P_t = \E(P_t \mid \vec{Z})).
\end{align}
The first term of this expression is negligible in the contexts I consider.
These contexts have $n_t << \Npop$.
$\Npop$ is the population of England (around 56 million) while $n_t$ is the daily sample size (10s of thousands).
Further $\V(P_t \mid \vec{Z}) \leq \E(P_t \mid \vec{Z})$ (\cref{inc-prev:eq:boundVPt}).
Therefore, $\var\left( X_t \mid \vec{Z} \right) \approx \V(X_t \mid P_t = \E(P_t \mid \vec{Z}))$.

A similar argument will show that the correlation between $x_t$ and $x_{t'}$ ($t \neq t'$) is negligible.
The basic structure of this argument is as the previous one.
The result follows because the observation noise dominates, and this is uncorrelated.
In the following, all are implicitly conditioned on $\vec{Z}$.
However, for clarity this is omitted from the notation.
\begin{align}
  &\lvert \cor(X_t, X_{t'}) \rvert \\
  &= \frac{\lvert\cov(X_t, X_{t'})\rvert}{\sqrt{\var(X_t) \var(X_{t'})}} &\text{by definition}\\
  &= \frac{\lvert \E(\cov(X_t, X_{t'} \mid \vec{P})) + \cov(\E(X_t \mid \vec{P}), \E(X_{t'} \mid \vec{P})) \rvert}{\sqrt{\var(X_t) \var(X_{t'})}} &\text{by law of total covariance} \\
  &= \frac{\lvert 0 + \cov(n_t P_t / \Npop, n_{t'} P_{t'} / \Npop) \rvert}{\sqrt{\var(X_t) \var(X_{t'})}} \\
  &= \frac{n_t n_{t'} \lvert \cov(P_t, P_{t'}) \rvert}{\Npop^2 \sqrt{\var(X_t) \var(X_{t'})}}  \\
  &<< \frac{n_t n_{t'} \lvert \cov(P_t, P_{t'}) \rvert}{\Npop^2 \sqrt{\var(P_t) \var(P_{t'})}} &\text{as $\V(X_t) >> \V(P_t)$} \\
  &= \frac{n_t n_{t'}}{\Npop^2} \lvert \cor(P_t, P_{t'}) \rvert \\
  &\leq \frac{n_t n_{t'}}{\Npop^2}.
\end{align}
$n_t n_{t'} / \Npop^2$ is very small, for the same reason that $n_t / \Npop$ is small.
The argument above shows that $\lvert \cor(X_t, X_{t'}) \rvert$ is much smaller than this.
Therefore, neglecting the correlation between $X_t$ and $X_{t'}$ is a good approximation.

This section showed that, when using a prevalence survey such as CIS, the likelihood $p(\vec{x} \mid \vec{Z})$ is very well approximated by $\prob(\vec{X} = \vec{x} \mid \vec{P} = \E(\vec{P} \mid \vec{Z}))$.


\section{Markov chain Monte Carlo} \label{inc-prev:sec:MCMC}

\section{Conclusion} \label{inc-prev:sec:conclusion}

Robust, unbiased prevalence estimates already exist (see\todo{ref prevalence estimates}), and incidence estimates are the objective of this thesis.
This chapter has shown that the key quantity relating these quantities is the distribution of the duration of PCR positivity.
However, no estimates of this quantity in the general population exist.
Therefore, I now turn to estimating the duration of PCR positivity.

\ifSubfilesClassLoaded{
  \listoftodos
}{}

\end{document}