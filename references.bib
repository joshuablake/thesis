@article{bacchettiNonparametric,
  title = {Nonparametric Estimation of the Incubation Period of {{AIDS}} Based on a Prevalent Cohort with Unknown Infection Times},
  author = {Bacchetti, Peter and Jewell, Nicholas P.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  number = {3},
  eprint = {2532651},
  eprinttype = {jstor},
  pages = {947--960},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10/cmxqpp},
  url = {https://www.jstor.org/stable/2532651?origin=crossref},
  urldate = {2022-01-10},
  abstract = {Estimation of the incubation period distribution of human immunodeficiency virus based on prevalent cohorts of subjects, already infected at the time of recruitment, is complicated by the absence of information on the original times of infection. Here, we overcome this difficulty by using a prior distribution for the infection times, based on external data. Our estimate is nonparametric, but uses smoothness assumptions to avoid instability. The method is illustrated on two prevalent cohorts from San Francisco, separately and combined. The estimates produced agree with other published estimates of the incubation period distribution.}
}

@book{bogaertsSurvival,
  title = {Survival Analysis with Interval-Censored Data: A Practical Approach with Examples in {{R}}, {{SAS}}, and {{BUGS}}},
  shorttitle = {Survival Analysis with Interval-Censored Data},
  author = {Bogaerts, Kris and Komárek, Arnošt and Lesaffre, Emmanuel},
  date = {2017-11-21},
  publisher = {{Chapman and Hall/CRC}},
  location = {{New York}},
  doi = {10.1201/9781315116945},
  abstract = {Survival Analysis with Interval-Censored Data: A Practical Approach with Examples in R, SAS, and BUGS provides the reader with a practical introduction into the analysis of interval-censored survival times. Although many theoretical developments have appeared in the last fifty years, interval censoring is often ignored in practice. Many are unaware of the impact of inappropriately dealing with interval censoring. In addition, the necessary software is at times difficult to trace. This book fills in the gap between theory and practice.  Features: -Provides an overview of frequentist as well as Bayesian methods. -Include a focus on practical aspects and applications. -Extensively illustrates the methods with examples using R, SAS, and BUGS. Full programs are available on a supplementary website. The authors: Kris Bogaerts is project manager at I-BioStat, KU Leuven. He received his PhD in science (statistics) at KU Leuven on the analysis of interval-censored data. He has gained expertise in a great variety of statistical topics with a focus on the design and analysis of clinical trials. Arnošt Komárek is associate professor of statistics at Charles University, Prague. His subject area of expertise covers mainly survival analysis with the emphasis on interval-censored data and classification based on longitudinal data. He is past chair of the Statistical Modelling Society　and editor of　Statistical Modelling: An International Journal. Emmanuel Lesaffre is professor of biostatistics at I-BioStat, KU Leuven. His research interests include Bayesian methods, longitudinal data analysis, statistical modelling, analysis of dental data, interval-censored data, misclassification issues, and clinical trials. He is the founding chair of the　Statistical Modelling Society, past-president of the　International Society for Clinical Biostatistics,　and fellow of　ISI　and　ASA.},
  isbn = {978-1-315-11694-5},
  pagetotal = {616}
}

@article{caoBias,
  title = {Bias Adjustment in {{Bayesian}} Estimation of Bird Nest Age-Specific Survival Rates},
  author = {Cao, Jing and He, Chong Z.},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  number = {3},
  pages = {877--878},
  issn = {1541-0420},
  doi = {10.1111/j.1541-020X.2005.000417.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-020X.2005.000417.x},
  urldate = {2022-06-21},
  abstract = {The populations of many North American landbirds are showing signs of declining. Gathering information on breeding productivity allows early detection of unhealthy populations and helps develop good habitat-management practices. In this paper, we study the performance of the Bayesian model (He, 2003, Biometrics59, 962–973) for age-specific nest survival rates with irregular visits. We find that the estimates are satisfactory except for the age-one survival rate. Usually the more days skipped between two visits, the more serious the underestimation of the age-one survival rate. We investigated the problem and developed three approaches to adjust for the underestimation bias. The simulation results show that the three approaches can significantly improve the estimation of the age-one survival rate.},
  langid = {english},
  keywords = {Age-specific survival,Bayesian estimation,Bird nest survival rate,Double interval censored data,Hierarchical prior,MCMC,Noninformative prior},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\556854LT\\j.1541-020X.2005.000417.html}
}

@article{caoModeling,
  title = {Modeling Age and Nest-Specific Survival Using a Hierarchical {{Bayesian}} Approach},
  author = {Cao, Jing and He, Chong Z. and Suedkamp Wells, Kimberly M. and Millspaugh, Joshua J. and Ryan, Mark R.},
  date = {2009-12-01},
  journaltitle = {Biometrics},
  volume = {65},
  number = {4},
  pages = {1052--1062},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2009.01204.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2009.01204.x},
  urldate = {2022-06-21},
  abstract = {Summary: Recent studies have shown that grassland birds are declining more rapidly than any other group of terrestrial birds. Current methods of estimating avian age-specific nest survival rates require knowing the ages of nests, assuming homogeneous nests in terms of nest survival rates, or treating the hazard function as a piecewise step function. In this article, we propose a Bayesian hierarchical model with nest-specific covariates to estimate age-specific daily survival probabilities without the above requirements. The model provides a smooth estimate of the nest survival curve and identifies the factors that are related to the nest survival. The model can handle irregular visiting schedules and it has the least restrictive assumptions compared to existing methods. Without assuming proportional hazards, we use a multinomial semiparametric logit model to specify a direct relation between age-specific nest failure probability and nest-specific covariates. An intrinsic autoregressive prior is employed for the nest age effect. This nonparametric prior provides a more flexible alternative to the parametric assumptions. The Bayesian computation is efficient because the full conditional posterior distributions either have closed forms or are log concave. We use the method to analyze a Missouri dickcissel dataset and find that (1) nest survival is not homogeneous during the nesting period, and it reaches its lowest at the transition from incubation to nestling; and (2) nest survival is related to grass cover and vegetation height in the study area.},
  langid = {english},
  keywords = {Age-specific survival probability,Bayesian hierarchical model,Intrinsic autoregressive prior,Nest survival,Nest-specific covariate},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\TYBEQLFH\\j.1541-0420.2009.01204.html}
}

@article{cevikShedding,
  title = {{{SARS-CoV-2}}, {{SARS-CoV}}, and {{MERS-CoV}} Viral Load Dynamics, Duration of Viral Shedding, and Infectiousness: A Systematic Review and Meta-Analysis},
  shorttitle = {{{SARS-CoV-2}}, {{SARS-CoV}}, and {{MERS-CoV}} Viral Load Dynamics, Duration of Viral Shedding, and Infectiousness},
  author = {Cevik, Muge and Tate, Matthew and Lloyd, Ollie and Maraolo, Alberto Enrico and Schafers, Jenna and Ho, Antonia},
  date = {2020-11-19},
  journaltitle = {The Lancet Microbe},
  shortjournal = {The Lancet Microbe},
  volume = {2},
  number = {1},
  pages = {e13-e22},
  publisher = {{Elsevier}},
  issn = {2666-5247},
  doi = {10/ghk47x},
  url = {https://www.thelancet.com/journals/lanmic/article/PIIS2666-5247(20)30172-5/fulltext},
  urldate = {2020-11-23},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}h3{$>$}Background{$<$}/h3{$><$}p{$>$}Viral load kinetics and duration of viral shedding are important determinants for disease transmission. We aimed to characterise viral load dynamics, duration of viral RNA shedding, and viable virus shedding of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in various body fluids, and to compare SARS-CoV-2, SARS-CoV, and Middle East respiratory syndrome coronavirus (MERS-CoV) viral dynamics.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}In this systematic review and meta-analysis, we searched databases, including MEDLINE, Embase, Europe PubMed Central, \emph{medRxiv}, and \emph{bioRxiv}, and the grey literature, for research articles published between Jan 1, 2003, and June 6, 2020. We included case series (with five or more participants), cohort studies, and randomised controlled trials that reported SARS-CoV-2, SARS-CoV, or MERS-CoV infection, and reported viral load kinetics, duration of viral shedding, or viable virus. Two authors independently extracted data from published studies, or contacted authors to request data, and assessed study quality and risk of bias using the Joanna Briggs Institute Critical Appraisal Checklist tools. We calculated the mean duration of viral shedding and 95\% CIs for every study included and applied the random-effects model to estimate a pooled effect size. We used a weighted meta-regression with an unrestricted maximum likelihood model to assess the effect of potential moderators on the pooled effect size. This study is registered with PROSPERO, CRD42020181914.{$<$}/p{$><$}h3{$>$}Findings{$<$}/h3{$><$}p{$>$}79 studies (5340 individuals) on SARS-CoV-2, eight studies (1858 individuals) on SARS-CoV, and 11 studies (799 individuals) on MERS-CoV were included. Mean duration of SARS-CoV-2 RNA shedding was 17·0 days (95\% CI 15·5–18·6; 43 studies, 3229 individuals) in upper respiratory tract, 14·6 days (9·3–20·0; seven studies, 260 individuals) in lower respiratory tract, 17·2 days (14·4–20·1; 13 studies, 586 individuals) in stool, and 16·6 days (3·6–29·7; two studies, 108 individuals) in serum samples. Maximum shedding duration was 83 days in the upper respiratory tract, 59 days in the lower respiratory tract, 126 days in stools, and 60 days in serum. Pooled mean SARS-CoV-2 shedding duration was positively associated with age (slope 0·304 [95\% CI 0·115–0·493]; p=0·0016). No study detected live virus beyond day 9 of illness, despite persistently high viral loads, which were inferred from cycle threshold values. SARS-CoV-2 viral load in the upper respiratory tract appeared to peak in the first week of illness, whereas that of SARS-CoV peaked at days 10–14 and that of MERS-CoV peaked at days 7–10.{$<$}/p{$><$}h3{$>$}Interpretation{$<$}/h3{$><$}p{$>$}Although SARS-CoV-2 RNA shedding in respiratory and stool samples can be prolonged, duration of viable virus is relatively short-lived. SARS-CoV-2 titres in the upper respiratory tract peak in the first week of illness. Early case finding and isolation, and public education on the spectrum of illness and period of infectiousness are key to the effective containment of SARS-CoV-2.{$<$}/p{$><$}h3{$>$}Funding{$<$}/h3{$><$}p{$>$}None.{$<$}/p{$>$}},
  langid = {english}
}

@online{cisMethodsONS,
  title = {Coronavirus ({{COVID-19}}) {{Infection Survey}}: Methods and Further Information},
  author = {{Office for National Statistics}},
  date = {2023-04-20},
  url = {https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/methodologies/covid19infectionsurveypilotmethodsandfurtherinformation#incidence},
  urldate = {2023-05-25},
  organization = {{Office for National Statistics}}
}

@online{cisProtocol,
  title = {Protocol and Information Sheets},
  author = {{Nuffield Department of Medicine}},
  date = {2023},
  url = {https://www.ndm.ox.ac.uk/covid-19/covid-19-infection-survey/protocol-and-information-sheets},
  urldate = {2023-05-25},
  organization = {{Nuffield Department of Medicine}},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\IPS47RYI\\protocol-and-information-sheets.html}
}

@article{degruttolaAnalysis,
  title = {Analysis of Doubly-Censored Survival Data, with Application to {{AIDS}}},
  author = {De Gruttola, Victor and Lagakos, Stephen W.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  number = {1},
  eprint = {2532030},
  eprinttype = {jstor},
  pages = {1--11},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10.2307/2532030},
  url = {https://www.jstor.org/stable/2532030},
  urldate = {2022-10-20},
  abstract = {This paper proposes nonparametric and weakly structured parametric methods for analyzing survival data in which both the time origin and the failure event can be right- or interval-censored. Such data arise in clinical investigations of the human immunodeficiency virus (HIV) when the infection and clinical status of patients are observed only at several time points. The proposed methods generalize the self-consistency algorithm proposed by Turnbull (1976, Journal of the Royal Statistical Society, Series B 38, 290-295) for singly-censored univariate data, and are illustrated with the results from a study of hemophiliacs who were infected with HIV by contaminated blood factor.}
}

@article{dempsterMaximum,
  title = {Maximum Likelihood from Incomplete Data via the {{{\emph{EM}}}} Algorithm},
  shorttitle = {Maximum Likelihood from Incomplete Data},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  date = {1977-09},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
  shortjournal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {39},
  number = {1},
  pages = {1--22},
  issn = {00359246},
  doi = {10.1111/j.2517-6161.1977.tb01600.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1977.tb01600.x},
  urldate = {2022-11-24},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
  langid = {english}
}

@article{freemanPrevalence,
  title = {Prevalence, Incidence and Duration},
  author = {Freeman, Jonathon and Hutchinson, George B.},
  date = {1980-11-01},
  journaltitle = {American Journal of Epidemiology},
  shortjournal = {American Journal of Epidemiology},
  volume = {112},
  number = {5},
  pages = {707--723},
  issn = {0002-9262},
  doi = {10/ghz7dp},
  url = {https://academic.oup.com/aje/article/112/5/707/78756},
  urldate = {2021-02-09},
  abstract = {Prevalence, incidence and duration of a condition or illness in a steady-state population are interrelated in such a way that two of these quantities may be used to obtain the third. Data may be collected in the most expedient manner, either as prevalence or incidence series of cases, and the results expressed as both incidence and prevalence. Information about the distribution of total durations of the condition in an incidence series of cases, or about the distribution of total durations or durations-to-date in a prevalence series is necessary in order to use these relations between prevalence and incidence of a condition or illness. The duration of a condition may be taken as one measure of the effect of the condition or illness on a population, and a “treatment effect” measured by comparing two populations may be termed the etiologic duration. Exact methods are presented for interconverting the distribution of total durations of condition among prevalence and incidence series of cases arising from the same steady-state population. Both prevalence and incidence series of cases may naturally arise in the same epidemiologic study, such as the initiation and conduct of a periodic screening program, and under certain conditions the size and even the direction of the etiologic duration may differ as measured in corresponding prevalence and incidence series of cases.},
  file = {C\:\\Users\\Joshua\\Documents\\paper_pdfs\\FREEMAN_HUTCHISON_1980_Prevalence,_incidence_and_duration.pdf}
}

@book{gelmanBayesian,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  date = {2013-11-01},
  eprint = {ZXL6AQAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{CRC Press}},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
  isbn = {978-1-4398-4095-5},
  langid = {english},
  pagetotal = {677},
  keywords = {Computers / Mathematical \& Statistical Software,Mathematics / Probability \& Statistics / General,Psychology / Research \& Methodology}
}

@article{goudieJoining,
  title = {Joining and Splitting Models with {{Markov}} Melding},
  author = {Goudie, Robert J. B. and Presanis, Anne M. and Lunn, David and De Angelis, Daniela and Wernisch, Lorenz},
  date = {2019-01},
  journaltitle = {Bayesian analysis},
  shortjournal = {Bayesian Anal},
  volume = {14},
  number = {1},
  eprint = {30631389},
  eprinttype = {pmid},
  pages = {81--109},
  issn = {1936-0975},
  doi = {10/ghj572},
  url = {https://projecteuclid.org/journals/bayesian-analysis/volume-14/issue-1/Joining-and-Splitting-Models-with-Markov-Melding/10.1214/18-BA1104.full?tab=ArticleLinkSupplemental},
  urldate = {2020-11-16},
  abstract = {Analysing multiple evidence sources is often feasible only via a modular approach, with separate submodels specified for smaller components of the available evidence. Here we introduce a generic framework that enables fully Bayesian analysis in this setting. We propose a generic method for forming a suitable joint model when joining submodels, and a convenient computational algorithm for fitting this joint model in stages, rather than as a single, monolithic model. The approach also enables splitting of large joint models into smaller submodels, allowing inference for the original joint model to be conducted via our multi-stage algorithm. We motivate and demonstrate our approach through two examples: joining components of an evidence synthesis of A/H1N1 influenza, and splitting a large ecology model.},
  pmcid = {PMC6324725}
}

@article{hakkiOnset,
  title = {Onset and Window of {{SARS-CoV-2}} Infectiousness and Temporal Correlation with Symptom Onset: A Prospective, Longitudinal, Community Cohort Study},
  shorttitle = {Onset and Window of {{SARS-CoV-2}} Infectiousness and Temporal Correlation with Symptom Onset},
  author = {Hakki, Seran and Zhou, Jie and Jonnerby, Jakob and Singanayagam, Anika and Barnett, Jack L and Madon, Kieran J and Koycheva, Aleksandra and Kelly, Christine and Houston, Hamish and Nevin, Sean and Fenn, Joe and Kundu, Rhia and Crone, Michael A and Ahmad, Shazaad and Derqui-Fernandez, Nieves and Conibear, Emily and Freemont, Paul S and Taylor, Graham P and Ferguson, Neil and Zambon, Maria and Barclay, Wendy S and Dunning, Jake and Lalvani, Ajit and Badhan, Anjna and Varro, Robert and Luca, Constanta and Quinn, Valerie and Cutajar, Jessica and Nichols, Niamh and Russell, Jessica and Grey, Holly and Ketkar, Anjeli and Miserocchi, Giulia and Tejpal, Chitra and Catchpole, Harriet and Nixon, Koji and Di Biase, Berenice and Hopewell, Tamara and Narean, Janakan Sam and Samuel, Jada and Timcang, Kristel and McDermott, Eimear and Bremang, Samuel and Hammett, Sarah and Evetts, Samuel and Kondratiuk, Alexandra},
  date = {2022-08-18},
  journaltitle = {The Lancet Respiratory Medicine},
  shortjournal = {The Lancet Respiratory Medicine},
  issn = {2213-2600},
  doi = {10.1016/S2213-2600(22)00226-0},
  url = {https://www.sciencedirect.com/science/article/pii/S2213260022002260},
  urldate = {2022-08-26},
  abstract = {Background Knowledge of the window of SARS-CoV-2 infectiousness is crucial in developing policies to curb transmission. Mathematical modelling based on scarce empirical evidence and key assumptions has driven isolation and testing policy, but real-world data are needed. We aimed to characterise infectiousness across the full course of infection in a real-world community setting. Methods The Assessment of Transmission and Contagiousness of COVID-19 in Contacts (ATACCC) study was a UK prospective, longitudinal, community cohort of contacts of newly diagnosed, PCR-confirmed SARS-CoV-2 index cases. Household and non-household exposed contacts aged 5 years or older were eligible for recruitment if they could provide informed consent and agree to self-swabbing of the upper respiratory tract. The primary objective was to define the window of SARS-CoV-2 infectiousness and its temporal correlation with symptom onset. We quantified viral RNA load by RT-PCR and infectious viral shedding by enumerating cultivable virus daily across the course of infection. Participants completed a daily diary to track the emergence of symptoms. Outcomes were assessed with empirical data and a phenomenological Bayesian hierarchical model. Findings Between Sept 13, 2020, and March 31, 2021, we enrolled 393 contacts from 327 households (the SARS-CoV-2 pre-alpha and alpha variant waves); and between May 24, 2021, and Oct 28, 2021, we enrolled 345 contacts from 215 households (the delta variant wave). 173 of these 738 contacts were PCR positive for more than one timepoint, 57 of which were at the start of infection and comprised the final study population. The onset and end of infectious viral shedding were captured in 42 cases and the median duration of infectiousness was 5 (IQR 3–7) days. Although 24 (63\%) of 38 cases had PCR-detectable virus before symptom onset, only seven (20\%) of 35 shed infectious virus presymptomatically. Symptom onset was a median of 3 days before both peak viral RNA and peak infectious viral load (viral RNA IQR 3–5 days, n=38; plaque-forming units IQR 3–6 days, n=35). Notably, 22 (65\%) of 34 cases and eight (24\%) of 34 cases continued to shed infectious virus 5 days and 7 days post-symptom onset, respectively (survival probabilities 67\% and 35\%). Correlation of lateral flow device (LFD) results with infectious viral shedding was poor during the viral growth phase (sensitivity 67\% [95\% CI 59–75]), but high during the decline phase (92\% [86–96]). Infectious virus kinetic modelling suggested that the initial rate of viral replication determines the course of infection and infectiousness. Interpretation Less than a quarter of COVID-19 cases shed infectious virus before symptom onset; under a crude 5-day self-isolation period from symptom onset, two-thirds of cases released into the community would still be infectious, but with reduced infectious viral shedding. Our findings support a role for LFDs to safely accelerate deisolation but not for early diagnosis, unless used daily. These high-resolution, community-based data provide evidence to inform infection control guidance. Funding National Institute for Health and Care Research.},
  langid = {english},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\Z9KLCRGI\\S2213260022002260.html}
}

@article{heBayesian,
  title = {Bayesian Modeling of Age-Specific Survival in Bird Nesting Studies under Irregular Visits},
  author = {He, Chong Z.},
  date = {2003-12-01},
  journaltitle = {Biometrics},
  volume = {59},
  number = {4},
  pages = {962--973},
  issn = {1541-0420},
  doi = {10.1111/j.0006-341x.2003.00111.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2003.00111.x},
  urldate = {2022-06-21},
  abstract = {Summary. In this article, a Bayesian model for age-specific nest survival rates is presented to handle the irregular visit case. Both informative priors and noninformative priors are investigated. The reference prior under this model is derived, and, therefore, the hyperparameter specification problem is solved to some extent. The Bayesian method provides a more accurate estimate of the total survival rate than the standard Mayfield method, if the age-specific hazard rates are not constant. The Bayesian method also lets the biologist look for high- and low-survival rates during the whole nesting period. In practice, it is common for data of several types to be collected in a single study. That is, some nests may be aged, others are not. Some nests are visited regularly; others are visited irregularly. The Bayesian method accommodates any mix of these sampling techniques by assuming that the aging and visiting activities have no effect on the survival rate. The methods are illustrated by an analysis of the Missouri northern bobwhite data set.},
  langid = {english},
  keywords = {Age-specific survival,Bayesian estimation,Beta priors,Double-interval censoring,Gibbs sampling,Latent variable,Nest study,Truncation},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\QQF8TTDS\\j.0006-341X.2003.00111.html}
}

@incollection{heBayesiana,
  title = {Bayesian Survival Analysis for Discrete Data with Left-Truncation and Interval Censoring},
  booktitle = {Handbook of {{Statistics}}},
  author = {He, Chong Z. and Sun, Dongchu},
  editor = {Dey, D. K. and Rao, C. R.},
  date = {2005},
  series = {Bayesian {{Thinking}}},
  volume = {25},
  pages = {907--928},
  publisher = {{Elsevier}},
  doi = {10.1016/S0169-7161(05)25032-0},
  url = {https://www.sciencedirect.com/science/article/pii/S0169716105250320},
  urldate = {2022-06-01},
  abstract = {In this chapter, a Bayesian model for discrete left-truncation and right censoring data is presented with applications to the age-specific nest survival rates under an irregular visit. Independent beta priors are placed on the age-specific hazard rates and conditional encounter rates. A two-stage hierarchical prior is placed on the number of encountered nests. Four types of latent variables are introduced to simplify the likelihood function. A class of informative and noninformative priors is given for the unknown number of nests encountered. We find some mild condition so that the posterior is proper. All the conditional posterior densities are standard densities such as beta, gamma, Poisson, negative binomial, and multinormal. Therefore, the Gibbs sampling computation is efficient. The reference prior under this model is derived, and the hyperparameter specification problem is solved to some extent. The simulation result shows that the proposed Bayesian model provides accurate and stable estimates of survival rates. The model also is applied to a real-nest data set.},
  isbn = {978-0-444-51539-1},
  langid = {english},
  keywords = {age-specific survival,Bayesian estimation,beta priors,double-interval censoring,Gibbs sampling,latent variable,nest study,Poisson distribution,truncation},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\INB67Y24\\S0169716105250320.html}
}

@article{heiseyABCs,
  title = {The {{ABCs}} of Nest Survival: Theory and Application from a Biostatistical Perspective},
  author = {Heisey, Dennis M and Shaffer, Terry L and White, Gary C},
  date = {2007},
  journaltitle = {Studies in Avian Biology},
  volume = {34},
  pages = {13--33},
  url = {https://sora.unm.edu/node/139706},
  abstract = {We consider how nest-survival studies fit into the theory and methods that have been developed for the biostatistical analysis of survival data. In this framework, the appropriate view of nest failure is that of a continuous time process which may be observed only periodically. The timing of study entry and subsequent observations, as well as assumptions about the underlying continuous time process, uniquely determines the appropriate analysis via the data likelihood. We describe how continuous-time hazard-function models form a natural basis for this approach. Nonparametric and parametric approaches are presented, but we focus primarily on the middle ground of weakly structured approaches and how they can be performed with software such as SAS PROC NLMIXED. The hazard function approach leads to complementary log-log (cloglog) link survival models, also known as discrete proportional-hazards models. We show that cloglog models have a close connection to the logistic-exposure and related models, and hence these models share similar desirable properties. We raise some cautions about the application of random effects, or frailty, models to nest-survival studies, and suggest directions that software development might take.},
  langid = {english},
  keywords = {⛔ No DOI found}
}

@article{heiseyModelling,
  title = {Modelling Age-Specific Survival in Nesting Studies, Using a General Approach for Doubly-Censored and Truncated Data},
  author = {Heisey, Dennis M. and Nordheim, Erik V.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  number = {1},
  eprint = {2533314},
  eprinttype = {jstor},
  pages = {51--60},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10.2307/2533314},
  url = {https://www.jstor.org/stable/2533314},
  urldate = {2022-06-21},
  abstract = {In typical nest survival studies, the observed sample of nests is usually biased by left-truncation (i.e., only active nests enter the study); additionally the failure data may be doubly censored, because the exact dates of nest initiation and failure are uncertain. We present a general bivariate contingency table approach for analyzing such data. We use weakly structured step spline hazard models, which avoid estimability problems encountered in a strictly nonparametric approach, yet still permit flexibility. Our method eliminates a potential source of bias noted by Heisey and Nordheim (1990, Biometrics 46, 855-862) in the nest survival method of Pollock and Cornelius (1988, Biometrics 44, 397-404). We compare our approach to related techniques developed for estimating the incubation distribution of AIDS.}
}

@book{ibrahimBayesian,
  title = {Bayesian Survival Analysis},
  author = {Ibrahim, Joseph G. and Chen, Ming-Hui and Sinha, Debajyoti},
  date = {2001},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4757-3447-8},
  url = {http://link.springer.com/10.1007/978-1-4757-3447-8},
  urldate = {2022-06-14},
  isbn = {978-1-4419-2933-4},
  langid = {english}
}

@article{lascolaViral,
  title = {Viral {{RNA}} Load as Determined by Cell Culture as a Management Tool for Discharge of {{SARS-CoV-2}} Patients from Infectious Disease Wards},
  author = {La Scola, Bernard and Le Bideau, Marion and Andreani, Julien and Hoang, Van Thuan and Grimaldier, Clio and Colson, Philippe and Gautret, Philippe and Raoult, Didier},
  date = {2020-06-01},
  journaltitle = {European Journal of Clinical Microbiology \& Infectious Diseases},
  shortjournal = {Eur J Clin Microbiol Infect Dis},
  volume = {39},
  number = {6},
  pages = {1059--1061},
  issn = {1435-4373},
  doi = {10.1007/s10096-020-03913-9},
  url = {https://doi.org/10.1007/s10096-020-03913-9},
  urldate = {2023-06-10},
  abstract = {In a preliminary clinical study, we observed that the combination of hydroxychloroquine and azithromycin was effective against SARS-CoV-2 by shortening the duration of viral load in Covid-19 patients. It is of paramount importance to define when a treated patient can be considered as no longer contagious. Correlation between successful isolation of virus in cell culture and Ct value of quantitative RT-PCR targeting E gene suggests that patients with Ct above 33–34 using our RT-PCR system are not contagious and thus can be discharged from hospital care or strict confinement for non-hospitalized patients.},
  langid = {english},
  keywords = {Co-culture,Correlation,Covid-19,RT-PCR,SARS-CoV2,Viral load}
}

@article{liSemiparametric,
  title = {Semiparametric Regression Analysis of Doubly Censored Failure Time Data from Cohort Studies},
  author = {Li, Shuwei and Sun, Jianguo and Tian, Tian and Cui, Xia},
  date = {2020-04-01},
  journaltitle = {Lifetime Data Analysis},
  shortjournal = {Lifetime Data Anal},
  volume = {26},
  number = {2},
  pages = {315--338},
  issn = {1572-9249},
  doi = {10.1007/s10985-019-09477-x},
  url = {https://doi.org/10.1007/s10985-019-09477-x},
  urldate = {2023-06-10},
  abstract = {Doubly censored failure time data occur when the failure time of interest represents the elapsed time between two events, an initial event and a subsequent event, and the observations on both events may suffer censoring. A well-known example of such data is given by the acquired immune deficiency syndrome (AIDS) cohort study in which the two events are HIV infection and AIDS diagnosis, and several inference methods have been developed in the literature for their regression analysis. However, all of them only apply to limited situations or focus on a single model. In this paper, we propose a marginal likelihood approach based on a general class of semiparametric transformation models, which can be applied to much more general situations. For the implementation, we develop a two-step procedure that makes use of both the multiple imputation technique and a novel EM algorithm. The asymptotic properties of the resulting estimators are established by using the modern empirical process theory, and the simulation study conducted suggests that the method works well in practical situations. An application is also provided.},
  langid = {english}
}

@article{panNote,
  title = {A Note on Inconsistency of {{NPMLE}} of the Distribution Function from Left Truncated and Case {{I}} Interval Censored Data},
  author = {Pan, Wei and Chappell, Rick},
  date = {1999-09-01},
  journaltitle = {Lifetime Data Analysis},
  shortjournal = {Lifetime Data Anal},
  volume = {5},
  number = {3},
  pages = {281--291},
  issn = {1572-9249},
  doi = {10.1023/A:1009632400580},
  url = {https://doi.org/10.1023/A:1009632400580},
  urldate = {2022-06-21},
  abstract = {We show that under reasonable conditions the nonparametric maximum likelihood estimate (NPMLE) of the distribution function from left-truncated and case 1 interval-censored data is inconsistent, in contrast to the consistency properties of the NPMLE from only left-truncated data or only interval-censored data. However, the conditional NPMLE is shown to be consistent. Numerical examples are provided to illustrate their finite sample properties.},
  langid = {english},
  keywords = {cumulative hazard function,EM algorithm,survival analysis,vague convergence}
}

@article{pouwelsCommunity,
  ids = {pouwelsCommunitya},
  title = {Community Prevalence of {{SARS-CoV-2}} in {{England}} from {{April}} to {{November}}, 2020: Results from the {{ONS Coronavirus Infection Survey}}},
  shorttitle = {Community Prevalence of {{SARS-CoV-2}} in {{England}} from {{April}} to {{November}}, 2020},
  author = {Pouwels, Koen B. and House, Thomas and Pritchard, Emma and Robotham, Julie V. and Birrell, Paul J. and Gelman, Andrew and Vihta, Karina-Doris and Bowers, Nikola and Boreham, Ian and Thomas, Heledd and Lewis, James and Bell, Iain and Bell, John I. and Newton, John N. and Farrar, Jeremy and Diamond, Ian and Benton, Pete and Walker, Ann Sarah and Pouwels, Koen B. and Walker, A. Sarah and Crook, Derrick and Matthews, Philippa C. and Peto, Tim and Pritchard, Emma and Stoesser, Nicole and Vihta, Karina-Doris and Howarth, Alison and Doherty, George and Kavanagh, James and Chau, Kevin K. and Hatch, Stephanie B. and Ebner, Daniel and Ferreira, Lucas Martins and Christott, Thomas and Marsden, Brian D. and Dejnirattisai, Wanwisa and Mongkolsapaya, Juthathip and Hoosdally, Sarah and Cornall, Richard and Stuart, David I. and Screaton, Gavin and Eyre, David and Bell, John and Cox, Stuart and Paddon, Kevin and James, Tim and House, Thomas and Newton, John N. and Robotham, Julie V. and Birrell, Paul and Jordan, Helena and Sheppard, Tim and Athey, Graham and Moody, Dan and Curry, Leigh and Brereton, Pamela and Hay, Jodie and Vansteenhouse, Harper and Bell, Iain and Diamond, Ian and Lambert, Alex and Benton, Pete and Rourke, Emma and Hawkes, Stacey and Henry, Sarah and Scruton, James and Stokes, Peter and Thomas, Tina and Allen, John and Black, Russell and Bovill, Heather and Braunholtz, David and Brown, Dominic and Collyer, Sarah and Crees, Megan and Daglish, Colin and Davies, Byron and Donnarumma, Hannah and Douglas-Mann, Julia and Felton, Antonio and Finselbach, Hannah and Fordham, Eleanor and Ipser, Alberta and Jenkins, Joe and Jones, Joel and Kent, Katherine and Kerai, Geeta and Lloyd, Lina and Masding, Victoria and Osborn, Ellie and Patel, Alpi and Pereira, Elizabeth and Pett, Tristan and Randall, Melissa and Reeve, Donna and Shah, Palvi and Snook, Ruth and Studley, Ruth and Sutherland, Esther and Swinn, Eliza and Thomas, Heledd and Tudor, Anna and Weston, Joshua and Leib, Shayla and Tierney, James and Farkas, Gabor and Cobb, Raf and Galen, Folkert Van and Compton, Lewis and Irving, James and Clarke, John and Mullis, Rachel and Ireland, Lorraine and Airimitoaie, Diana and Nash, Charlotte and Cox, Danielle and Fisher, Sarah and Moore, Zoe and McLean, James and Kerby, Matt},
  date = {2020-12-10},
  journaltitle = {The Lancet Public Health},
  shortjournal = {The Lancet Public Health},
  volume = {6},
  number = {1},
  eprint = {33308423},
  eprinttype = {pmid},
  pages = {e30--e38},
  publisher = {{Elsevier}},
  issn = {2468-2667},
  doi = {10.1016/S2468-2667(20)30282-6},
  url = {https://www.thelancet.com/journals/lanpub/article/PIIS2468-2667(20)30282-6/fulltext},
  urldate = {2021-04-07},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}h3{$>$}Background{$<$}/h3{$><$}p{$>$}Decisions about the continued need for control measures to contain the spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) rely on accurate and up-to-date information about the number of people testing positive for SARS-CoV-2 and risk factors for testing positive. Existing surveillance systems are generally not based on population samples and are not longitudinal in design.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}Samples were collected from individuals aged 2 years and older living in private households in England that were randomly selected from address lists and previous Office for National Statistics surveys in repeated cross-sectional household surveys with additional serial sampling and longitudinal follow-up. Participants completed a questionnaire and did nose and throat self-swabs. The percentage of individuals testing positive for SARS-CoV-2 RNA was estimated over time by use of dynamic multilevel regression and poststratification, to account for potential residual non-representativeness. Potential changes in risk factors for testing positive over time were also assessed. The study is registered with the ISRCTN Registry, ISRCTN21086382.{$<$}/p{$><$}h3{$>$}Findings{$<$}/h3{$><$}p{$>$}Between April 26 and Nov 1, 2020, results were available from 1 191 170 samples from 280 327 individuals; 5231 samples were positive overall, from 3923 individuals. The percentage of people testing positive for SARS-CoV-2 changed substantially over time, with an initial decrease between April 26 and June 28, 2020, from 0·40\% (95\% credible interval 0·29–0·54) to 0·06\% (0·04–0·07), followed by low levels during July and August, 2020, before substantial increases at the end of August, 2020, with percentages testing positive above 1\% from the end of October, 2020. Having a patient-facing role and working outside your home were important risk factors for testing positive for SARS-CoV-2 at the end of the first wave (April 26 to June 28, 2020), but not in the second wave (from the end of August to Nov 1, 2020). Age (young adults, particularly those aged 17–24 years) was an important initial driver of increased positivity rates in the second wave. For example, the estimated percentage of individuals testing positive was more than six times higher in those aged 17–24 years than in those aged 70 years or older at the end of September, 2020. A substantial proportion of infections were in individuals not reporting symptoms around their positive test (45–68\%, dependent on calendar time.{$<$}/p{$><$}h3{$>$}Interpretation{$<$}/h3{$><$}p{$>$}Important risk factors for testing positive for SARS-CoV-2 varied substantially between the part of the first wave that was captured by the study (April to June, 2020) and the first part of the second wave of increased positivity rates (end of August to Nov 1, 2020), and a substantial proportion of infections were in individuals not reporting symptoms, indicating that continued monitoring for SARS-CoV-2 in the community will be important for managing the COVID-19 pandemic moving forwards.{$<$}/p{$><$}h3{$>$}Funding{$<$}/h3{$><$}p{$>$}Department of Health and Social Care.{$<$}/p{$>$}},
  langid = {english}
}

@article{punchooLaboratory,
  ids = {punchooLaboratorya},
  title = {Laboratory Considerations for Reporting Cycle Threshold Value in {{COVID-19}}},
  author = {Punchoo, Rivak and Bhoora, Sachin and Bangalee, Avania},
  date = {2022-08-08},
  journaltitle = {EJIFCC},
  shortjournal = {EJIFCC},
  volume = {33},
  number = {2},
  eprint = {36313906},
  eprinttype = {pmid},
  pages = {80--93},
  issn = {1650-3414},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9562486/},
  abstract = {The Coronavirus Disease 2019 (COVID-19) pandemic is caused by the SARS-CoV-2 RNA virus. Nucleic acid amplification testing (NAAT) is the mainstay to confirm infection. A large number of reverse transcriptase polymerase chain reaction (RT-PCR) assays are currently available for qualitatively assessing SARS-CoV-2 infection. Although these assays show variation in cycle threshold values (Ct), advocacy for reporting Ct values (in addition to the qualitative result) is tabled to guide patient clinical management decisions. This article provides critical commentary on qualitative RTPCR laboratory and clinical considerations for Ct value reporting. Factors contributing to Ct variation are discussed by considering relevant viral life-cycle factors, patient factors and the laboratory total testing processes that contribute to the Ct variation and mitigate against the reporting of Ct values by qualitative NAAT.},
  langid = {english},
  pmcid = {PMC9562486},
  keywords = {⛔ No DOI found}
}

@software{R4-2-0,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2022},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}},
  version = {4.2.0}
}

@article{roystonFlexible,
  title = {Flexible Parametric Proportional-Hazards and Proportional-Odds Models for Censored Survival Data, with Application to Prognostic Modelling and Estimation of Treatment Effects},
  author = {Royston, Patrick and Parmar, Mahesh K. B.},
  date = {2002},
  journaltitle = {Statistics in Medicine},
  volume = {21},
  number = {15},
  pages = {2175--2197},
  issn = {1097-0258},
  doi = {10/dm7qn3},
  url = {https://doi.org/10.1002/sim.1203},
  urldate = {2021-01-29},
  abstract = {Modelling of censored survival data is almost always done by Cox proportional-hazards regression. However, use of parametric models for such data may have some advantages. For example, non-proportional hazards, a potential difficulty with Cox models, may sometimes be handled in a simple way, and visualization of the hazard function is much easier. Extensions of the Weibull and log-logistic models are proposed in which natural cubic splines are used to smooth the baseline log cumulative hazard and log cumulative odds of failure functions. Further extensions to allow non-proportional effects of some or all of the covariates are introduced. A hypothesis test of the appropriateness of the scale chosen for covariate effects (such as of treatment) is proposed. The new models are applied to two data sets in cancer. The results throw interesting light on the behaviour of both the hazard function and the hazard ratio over time. The tools described here may be a step towards providing greater insight into the natural history of the disease and into possible underlying causes of clinical events. We illustrate these aspects by using the two examples in cancer. Copyright © 2002 John Wiley \& Sons, Ltd.},
  langid = {english}
}

@software{roystonSTPM,
  title = {{{STPM}}: {{Stata}} Module to Fit Flexible Parametric Models for Survival-Time Data},
  shorttitle = {{{STPM}}},
  author = {Royston, Patrick},
  date = {2014-03-13},
  url = {https://econpapers.repec.org/software/bocbocode/s418605.htm},
  urldate = {2021-01-29},
  abstract = {stpm fits spline-based distributional models to right-, left- or interval-censored survival data. Three different link functions are supported. This version is updated from that published in SJ 1-1 (1-28). See also Royston P, Parmar M (2002) Stat Med 21: 2175-97.}
}

@software{rstan2-21-8,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  date = {2023},
  url = {https://mc-stan.org/},
  version = {2.21.8}
}

@online{russellWithinhost,
  title = {Within-Host {{SARS-CoV-2}} Viral Kinetics Informed by Complex Life Course Exposures Reveals Different Intrinsic Properties of {{Omicron}} and {{Delta}} Variants},
  author = {Russell, Timothy W. and Townsley, Hermaleigh and Abbott, Sam and Hellewell, Joel and Carr, Edward J. and Chapman, Lloyd and Pung, Rachael and Quilty, Billy J. and Hodgson, David and Fowler, Ashley S. and Adams, Lorin and Bailey, Christopher and Mears, Harriet V. and Harvey, Ruth and Clayton, Bobbi and O’Reilly, Nicola and Ngai, Yenting and Nicod, Jerome and Gamblin, Steve and Williams, Bryan and Gandhi, Sonia and Swanton, Charles and Beale, Rupert and Bauer, David LV and Wall, Emma C. and Kucharski, Adam},
  date = {2023-05-24},
  eprinttype = {medRxiv},
  pages = {2023.05.17.23290105},
  doi = {10.1101/2023.05.17.23290105},
  url = {https://www.medrxiv.org/content/10.1101/2023.05.17.23290105v1},
  urldate = {2023-07-13},
  abstract = {The emergence of successive SARS-CoV-2 variants of concern (VOC) during 2020-22, each exhibiting increased epidemic growth relative to earlier circulating variants, has created a need to understand the drivers of such growth. However, both pathogen biology and changing host characteristics – such as varying levels of immunity – can combine to influence replication and transmission of SARS-CoV-2 within and between hosts. Disentangling the role of variant and host in individual-level viral shedding of VOCs is essential to inform COVID-19 planning and response, and interpret past epidemic trends. Using data from a prospective observational cohort study of healthy adult volunteers undergoing weekly occupational health PCR screening, we developed a Bayesian hierarchical model to reconstruct individual-level viral kinetics and estimate how different factors shaped viral dynamics, measured by PCR cycle threshold (Ct) values over time. Jointly accounting for both inter-individual variation in Ct values and complex host characteristics – such as vaccination status, exposure history and age – we found that age and number of prior exposures had a strong influence on peak viral replication. Older individuals and those who had at least five prior antigen exposures to vaccination and/or infection typically had much lower levels of shedding. Moreover, we found evidence of a correlation between the speed of early shedding and duration of incubation period when comparing different VOCs and age groups. Our findings illustrate the value of linking information on participant characteristics, symptom profile and infecting variant with prospective PCR sampling, and the importance of accounting for increasingly complex population exposure landscapes when analysing the viral kinetics of VOCs.},
  langid = {english},
  pubstate = {preprint},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\AUCC4TPN\\Russell et al_2023_Within-host SARS-CoV-2 viral kinetics informed by complex life course exposures.pdf}
}

@thesis{saulGaussian,
  type = {phdthesis},
  title = {Gaussian Process Based Approaches for Survival Analysis},
  author = {Saul, Alan D.},
  date = {2016-12},
  institution = {{University of Sheffield}},
  url = {https://etheses.whiterose.ac.uk/17946/},
  urldate = {2022-03-07},
  abstract = {Traditional machine learning focuses on the situation where a fixed number of features are available for each data-point. For medical applications each individual patient will typically have a different set of clinical tests associated with them. This results in a varying number of observed per patient features. An important indicator of interest in medical domains is survival information. Survival data presents its own particular challenges such as censoring. The aim of this thesis is to explore how machine learning ideas can be transferred to the domain of clinical data analysis. We consider two primary challenges; firstly how survival models can be made more flexible through non-linearisation and secondly methods for missing data imputation in order to handle the varying number of observed per patient features. We use the framework of Gaussian process modelling to facilitate conflation of our approaches; allowing the dual challenges of survival data and missing data to be addressed. The results show promise, although challenges remain. In particular when a large proportion of data is missing, greater uncertainty in inferences results. Principled handling of this uncertainty requires propagation through any Gaussian process model used for subsequent regression.},
  langid = {english},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\SREWQBTR\\17946.html}
}

@article{shenNonparametric,
  title = {Nonparametric Estimation with Doubly Censored and Truncated Data},
  author = {Shen, Pao-sheng},
  date = {2011-03-01},
  journaltitle = {Computational Statistics},
  shortjournal = {Comput Stat},
  volume = {26},
  number = {1},
  pages = {145--157},
  issn = {1613-9658},
  doi = {10.1007/s00180-010-0214-4},
  url = {https://doi.org/10.1007/s00180-010-0214-4},
  urldate = {2022-06-21},
  abstract = {Data from longitudinal studies in which an initiating event and a subsequent event occur in sequence are called doubly censored data if the time of both events is interval-censored. In some cases, the second event also suffers left-truncation. This article is concerned with using doubly censored and truncated data to estimate the distribution function F of the duration time, i.e. the elapsed time between the originating event and the subsequent event. An iterative procedure is proposed to obtain the estimate of F. A simulation study is conducted to investigate the performance of the proposed estimator. A modified data set is used to illustrate the proposed approach.},
  langid = {english},
  keywords = {Interval-censoring,Left truncation,Self-consistent}
}

@article{shenNonparametrica,
  title = {Nonparametric Estimators of Survival Function under the Mixed Case Interval-Censored Model with Left Truncation},
  author = {Shen, Pao-Sheng},
  date = {2020-07-01},
  journaltitle = {Lifetime Data Analysis},
  shortjournal = {Lifetime Data Anal},
  volume = {26},
  number = {3},
  pages = {624--637},
  issn = {1572-9249},
  doi = {10.1007/s10985-020-09493-2},
  url = {https://doi.org/10.1007/s10985-020-09493-2},
  urldate = {2022-06-21},
  abstract = {It is well known that the nonparametric maximum likelihood estimator (NPMLE) can severely underestimate the survival probabilities at early times for left-truncated and interval-censored (LT-IC) data. For arbitrarily truncated and censored data, Pan and Chappel (JAMA Stat Probab Lett 38:49–57, 1998a, Biometrics 54:1053–1060, 1998b) proposed a nonparametric estimator of the survival function, called the iterative Nelson estimator (INE). Their simulation study showed that the INE performed well in overcoming the under-estimation of the survival function from the NPMLE for LT-IC data. In this article, we revisit the problem of inconsistency of the NPMLE. We point out that the inconsistency is caused by the likelihood function of the left-censored observations, where the left-truncated variables are used as the left endpoints of censoring intervals. This can lead to severe underestimation of the survival function if the NPMLE is obtained using Turnbull’s (JAMA 38:290–295, 1976) EM algorithm. To overcome this problem, we propose a modified maximum likelihood estimator (MMLE) based on a modified likelihood function, where the left endpoints of censoring intervals for left-censored observations are the maximum of left-truncated variables and the estimated left endpoint of the support of the left-censored times. Simulation studies show that the MMLE performs well for finite sample and outperforms both the INE and NPMLE.},
  langid = {english},
  keywords = {EM algorithm,Interval censoring,Left truncation,NPMLE}
}

@article{singanayagamDuration,
  title = {Duration of Infectiousness and Correlation with {{RT-PCR}} Cycle Threshold Values in Cases of {{COVID-19}}, {{England}}, {{January}} to {{May}} 2020},
  author = {Singanayagam, Anika and Patel, Monika and Charlett, Andre and Bernal, Jamie Lopez and Saliba, Vanessa and Ellis, Joanna and Ladhani, Shamez and Zambon, Maria and Gopal, Robin},
  date = {2020-08-13},
  journaltitle = {Eurosurveillance},
  volume = {25},
  number = {32},
  pages = {2001483},
  publisher = {{European Centre for Disease Prevention and Control; http://web.archive.org/web/20200918093149/https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2020.25.32.2001483}},
  issn = {1560-7917},
  doi = {10/gg9jt7},
  url = {10/gg9jt7},
  urldate = {2020-09-18},
  abstract = {Severe acute respiratory syndrome coronavirus 2 viral load in the upper respiratory tract peaks around symptom onset and infectious virus persists for 10 days in mild-to-moderate coronavirus disease (n = 324 samples analysed). RT-PCR cycle threshold (Ct) values correlate strongly with cultivable virus. Probability of culturing virus declines to 8\% in samples with Ct \&gt; 35 and to 6\% 10 days after onset; it is similar in asymptomatic and symptomatic persons. Asymptomatic persons represent a source of transmissible virus.},
  langid = {english}
}

@article{sinhaTimediscrete,
  title = {Time-Discrete Beta-Process Model for Interval-Censored Survival Data},
  author = {Sinha, Debajyoti},
  date = {1997-12-01},
  journaltitle = {Canadian Journal of Statistics},
  volume = {25},
  number = {4},
  pages = {445--456},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1708-945X},
  doi = {10.2307/3315340},
  url = {https://onlinelibrary.wiley.com/doi/10.2307/3315340},
  urldate = {2022-06-15},
  abstract = {Grouped survival data with possible interval censoring arise in a variety of settings. This paper presents nonparametric Bayes methods for the analysis of such data. The random cumulative hazard, com...},
  langid = {english}
}

@incollection{sunAnalysis,
  title = {Analysis of {{Doubly Censored Data}}},
  booktitle = {The {{Statistical Analysis}} of {{Interval-censored Failure Time Data}}},
  editor = {Sun, Jianguo},
  date = {2006},
  series = {Statistics for {{Biology}} and {{Health}}},
  pages = {177--203},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/0-387-37119-2_8},
  url = {https://doi.org/10.1007/0-387-37119-2_8},
  urldate = {2023-06-10},
  abstract = {As discussed in Section 1.3, doubly censored data occur in studies that consist of two related events with one followed by the other. A typical example is given by a disease progression study in which the onset of the disease is caused or preceded by certain virus infection. In these situations, three variables are present, and they are time to infection, time between infection and the onset of the disease, and time to the onset of the disease. It is apparent that one only needs to know two of the three variables. If the variable of interest is the time to infection or the time to the onset of the disease, in general, one only needs to analyze the variable of interest without the need of dealing with the other two variables.},
  isbn = {978-0-387-37119-1},
  langid = {english}
}

@article{sunEmpirical,
  title = {Empirical Estimation of a Distribution Function with Truncated and Doubly Interval-Censored Data and Its Application to {{AIDS}} Studies},
  author = {Sun, Jianguo},
  date = {1995},
  journaltitle = {Biometrics},
  shortjournal = {Biometrics},
  volume = {51},
  number = {3},
  eprint = {2533008},
  eprinttype = {jstor},
  pages = {1096},
  issn = {0006341X},
  doi = {10/dxgrwp},
  url = {https://www.jstor.org/stable/2533008?origin=crossref},
  urldate = {2022-01-07},
  abstract = {In this paper we discuss the non-parametric estimation of a distribution function based on incomplete data for which the measurement origin of a suivival time or the date of enrollment in a study is known only to belong to an interval. Also the survival time of interest itself is observed from a truncated distribution and is known only to lie in an interval. To estimate the distribution function, a simple self-consistency algorithm, a generalization of Turnbull's (1976, Joulrn1al of the Royal Statistical Association, Series B 38, 290-295) self-consistency algorithm, is proposed. This method is then used to analyze two AIDS cohort studies, for which direct use of the EM algorithm (Dempster, Laird and Rubin, 1976, Journal of the Royal Statistical Association, Series B 39, 1-38), which is computationally complicated, has previously been the usual method of the analysis.},
  langid = {english},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\N28BDN8W\\Sun - 1995 - Empirical Estimation of a Distribution Function wi.pdf}
}

@article{sunSelfconsistency,
  title = {Self-Consistency Estimation of Distributions Based on Truncated and Doubly Censored Survival Data with Applications to {{AIDS}} Cohort Studies},
  author = {Sun, Jianguo},
  date = {1997-12-01},
  journaltitle = {Lifetime Data Analysis},
  shortjournal = {Lifetime Data Anal},
  volume = {3},
  number = {4},
  pages = {305--313},
  issn = {1572-9249},
  doi = {10/dj57mj},
  url = {https://doi.org/10.1023/A:1009609227969},
  urldate = {2022-01-31},
  abstract = {Gomez and Lagakos (1994) propose a nonparametric method for estimating the distribution of a survival time when the origin and end points defining the survival time suffer interval-censoring and right-censoring, respectively. In some situations, the end point also suffers interval-censoring as well as truncation. In this paper, we consider this general situation and propose a two-step estimation procedure for the estimation of the distribution of a survival time based on doubly interval-censored and truncated data. The proposed method generalizes the methods proposed by DeGruttola and Lagakos (1989) and Sun (1995) and is more efficient than that given in Gomez and Lagakos (1994). The approach is based on self-consistency equations. The method is illustrated by an analysis of an AIDS cohort study.},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20180605173942/https://link.springer.com/article/10.1023\%2FA\%3A1009609227969}
}

@incollection{sunStatistical,
  title = {Statistical Analysis of Doubly Interval-Censored Failure Time Data},
  booktitle = {Handbook of {{Statistics}}},
  author = {Sun, Jianguo},
  date = {2003-01-01},
  series = {Advances in {{Survival Analysis}}},
  volume = {23},
  pages = {105--122},
  publisher = {{Elsevier}},
  doi = {10.1016/S0169-7161(03)23006-6},
  url = {https://www.sciencedirect.com/science/article/pii/S0169716103230066},
  urldate = {2022-01-31},
  abstract = {This chapter discusses the statistical analysis of doubly interval-censored failure-time data. One field that often sees doubly interval-censored failure-time data is disease progression or epidemiological studies where initial and subsequent events may represent infection and subsequent onset of certain disease, respectively. In these situations, doubly interval-censored observations occur mainly because of the nature of the disease and/or the structure of the study design. Doubly interval-censored failure-time data include usual right- or interval-censored failure-time data as special cases. The analysis of doubly interval-censored data has recently attracted much attention, especially in the context of the analysis of AIDS incubation time. The chapter discusses nonparametric estimation of the distribution of the survival time of interest by considering the situation where no truncation exists and the situation with truncation on observations on the occurrence of subsequent events. Several algorithms are described and compared for the nonparametric estimation. The chapter deals with regression analysis of doubly interval-censored failure-time data by discussing two methods for fitting the proportional hazards model to the data. The problem of nonparametric comparison of survival functions based on doubly interval-censored failure-time data is considered and some discussion and directions for future researches are mentioned.},
  isbn = {978-0-444-50079-3},
  langid = {english},
  file = {C\:\\Users\\Joshua\\Zotero\\storage\\2M9FW34U\\S0169716103230066.html}
}

@book{sunStatisticala,
  title = {The Statistical Analysis of Interval-Censored Failure Time Data},
  author = {Sun, Jianguo},
  date = {2006},
  series = {Statistics for Biology and Health},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-32905-5},
  pagetotal = {302},
  keywords = {Failure time data analysis}
}

@article{targetsPackage,
  title = {The Targets {{R}} Package: A Dynamic {{Make-like}} Function-Oriented Pipeline Toolkit for Reproducibility and High-Performance Computing},
  author = {Landau, William Michael},
  date = {2021},
  journaltitle = {Journal of Open Source Software},
  volume = {6},
  number = {57},
  pages = {2959},
  doi = {10.21105/joss.02959},
  url = {https://doi.org/10.21105/joss.02959}
}

@article{tidyverse,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  date = {2019},
  journaltitle = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  doi = {10.21105/joss.01686}
}

@article{turnbullEmpirical,
  title = {The Empirical Distribution Function with Arbitrarily Grouped, Censored and Truncated Data},
  author = {Turnbull, Bruce W.},
  date = {1976},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {38},
  number = {3},
  eprint = {2984980},
  eprinttype = {jstor},
  pages = {290--295},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  doi = {10.1111/j.2517-6161.1976.tb01597.x},
  url = {https://www.jstor.org/stable/2984980},
  urldate = {2022-11-24},
  abstract = {This paper is concerned with the non-parametric estimation of a distribution function F, when the data are incomplete due to grouping, censoring and/or truncation. Using the idea of self-consistency, a simple algorithm is constructed and shown to converge monotonically to yield a maximum likelihood estimate of F. An application to hypothesis testing is indicated.}
}
