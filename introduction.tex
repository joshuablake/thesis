\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Introduction} \label{intro}

COVID-19 (coronavirus disease 2019), the disease caused by the virus SARS-CoV-2 (severe acute respiratory syndrome coronavirus 2), is estimated to have killed approximately 15 million in the acutest phase (to the end of 2021) and 30 million in total~\autocite{whoCOVIDExcess,economistCOVIDExcess}.
History suggests severe pandemics are not rare (see \cref{intro:fig:pandemic-timeline}).
\begin{figure}
    \includegraphics[width=\textwidth]{introduction/pandemic-timeline}
    \caption[Timeline of pandemics.]{%
        Timeline of pandemics.
        See \url{https://ourworldindata.org/historical-pandemics} for details and sources.
        Licensed under \href{https://creativecommons.org/licenses/by/4.0/}{CC-BY} by Saloni Dattani, Klara Auerbach, Marwa Boukarim, and Max Roser.
    }
    \label{intro:fig:pandemic-timeline}
\end{figure}
Fully quantifying the burden of historical pandemics is challenging due to the absence of systematic records.
However, our best records suggests that, since 1600, they have (on average) occurred every four years with a mean death toll of 5.6 million~\autocite{maraniNovelEpidemics}.
Recent estimates suggest that the current mean impact of pandemics is over 2.5 million deaths per year~\autocite{madhavPandemicMortality}.

All pandemics start as an \emph{outbreak}, a sudden and unexpected rise in the number of people with a disease in a local area; if this spreads over a larger geographic area (\eg a country) it becomes an \emph{epidemic}; if it spreads globally then it is a \emph{pandemic}~\autocite{grennanPandemic}.
The precise meaning of these terms is contested, determined implicitly by their usage rather than formal definitions~\autocite{morensPandemic,doshiElusive}.
I will refer to the SARS-CoV-2 epidemic within England (or the UK), and the global impact as the pandemic.

In this context, \emph{surveillance} is the ability to detect and monitor the spread of an outbreak.
Surveillance is important at every stage: early on, for detecting a new outbreak quickly and assessing its likely impact and later for monitoring the ongoing burden of the disease and the effectiveness of interventions~\autocite{whoFluSurveillance}.
In all cases, surveillance is required to inform public health policy.
In this thesis, I consider methods to improve surveillance, using the SARS-SARS-CoV-2 epidemic in England as a case study.

\section{Surveillance metrics}

No single metric summarises the full state of an epidemic, and no single data source fully informs all metrics of interest~\autocite{royalSocietyRnumber,pellisEstimation,paragGrowthRates}.
Therefore, a range of metrics and surveillance systems are required to understand the state of an epidemic and the danger of a pathogen (a pathogen is any biological agent that can cause disease).

\subsection{Growth of an epidemic}

Various forms of \emph{reproduction number} were prominent throughout the SARS-CoV-2 pandemic~\autocite{pellisEstimation}.
Broadly, a reproduction number describes the number of secondary infections generated by a single infection.
Here, following \textcite{pellisEstimation},  building on over a century of infectious disease dynamics literature, I define three that are broadly useful.

The most famous reproduction number is the \emph{basic reproduction number}, $\R$.
$\R$ is the mean number of secondary infections generated by a single infection in a \emph{fully susceptible} population with \emph{standard behaviour patterns}.
A fully susceptible population means none of its members have any immunity to the disease.
Note that this definition is a constant for a given pathogen and population.
In the early stages of an epidemic caused by a novel pathogen, the number of individuals with immunity is negligible, and hence $\R$ describes this part of the epidemic well.
$\R$ has a threshold value of 1: if $\R < 1$ then the epidemic will die out.

The \emph{effective reproduction number}, $\Re$, is the mean number of secondary infections generated by a single infection at time $t$.
In particular, it uses the behaviour and immunity status of the population at time $t$.
With constant behaviour and a disease that grants immunity following infection, $\Re$ declines smoothly.
$\Re$ describes the current dynamics of the epidemic: $\Re > 1$ means the epidemic is growing, $\Re < 1$ means it is shrinking, and $\Re = 1$ means it is stable.
In simple epidemic models (see \cref{E-SEIR:sec:SIR}), $\Re$ is proportional to the product of the rate of contacts, the riskiness of those contacts, and the proportion of the population that is susceptible.
Therefore, it informs the strength of intervention, \eg social distancing or vaccination, required to control the epidemic.

The \emph{control reproduction number}, $\Rc$, is the mean number of secondary infections generated by a single infection with the behaviour at time $t$ but in a fully susceptible population.
$\Rc$ is also known as the \emph{reproduction number excluding immunity}.
It describes the effect on the epidemic of interventions (except vaccination) that have been put into place.
$\Rc$ is useful when comparing the effects of interventions at different points in time, when the immunity status of the population has changed.
For example, when comparing the English lockdown in March 2020 and January 2021, there are two effects in play: that there are more individuals with immunity in January 2021, and that the lockdown had different measures in place.
$\Rc$ focuses on the latter effect.

These definitions ignore many complexities that arise when theoretically defining or practically estimating any of the reproduction numbers~\autocite{pellisEstimation}.
For example, effects due to changing weather, what a ``mean infection'' means in a heterogeneous population, and the lack of a ground truth for these numbers in almost all practical situations.
However, their intuitive simplicity and convenient properties in simple epidemic models (see \cref{E-SEIR:sec:mechanistic-models}) mean that they are useful concepts for guiding policy.

Reproduction numbers are strongly connected to \emph{growth rates}.
Over short periods of time, epidemics tend to grow exponentially, and hence have an exponential growth rate, normally denoted $r$.
For a given disease and population, an analogous growth rate can be defined for each reproduction number~\autocite{pellisEstimation,paragGrowthRates,wallingaGI}.
The advantage of using the growth rate is that they are easier to estimate and capture how quickly spread happens in calendar time; however, they do not capture the strength of intervention required to control the epidemic~\autocite{royalSocietyRnumber}.

\subsection{Size of an epidemic}

Growth rates and reproduction numbers only provide information on how an epidemic is changing.
Yet the size of the epidemic is at least as important as how it is changing~\autocite{pellisEstimation}.
\emph{Incidence} (the number of new infections in a given time period) is the primary metric for the magnitude of a pandemic.
Incidence informs the burden of the disease, for example, the future number of severe events (hospitalisations or deaths).

\todo[inline]{What is a good definition of ``transmission'' as a concept?}
The \emph{transmission} of an infectious disease generates new infections.
The components of transmission (\eg number of contacts per day and age-stratified rates) inform how interventions can be targeted.
They are also important for forecasting future incidence.

However, incidence and transmission are almost never directly observed.
Therefore, they need to be estimated from other data sources.

\emph{Prevalence} is the proportion of the population with the disease at a given time.
Whether an individual is prevalent (has the disease) is normally measurable.
Therefore, the prevalence of the population can be estimated with a prevalence survey.

See \cref{E-inc-prev:sec:definitions} for a formal definition of incidence and prevalence.
Prevalence and incidence are strongly related, with the relationship determined by how long the disease lasts (see \cref{E-inc-prev}).

To translate incidence into the burden of the disease, a measure of severity is required.
For example, the IFR (infection fatality rate), the proportion of infected individuals who die.
Estimation of severity is beyond the scope of this thesis.
% Severity does not feature in this thesis, but it is important to note that it is a key component of understanding the burden of a pandemic.\todo{maybe reword sentence}

\section{Data sources} \label{intro:sec:data-sources}

A wide variety of designed studies, administrative data, and other data sources have been used for pandemic and epidemic surveillance.
In the context of the SARS-CoV-2 pandemic in England, the most prominent were: community testing (known as pillar 2 testing), the number of severe events (\eg hospital admissions or deaths), seroprevalence testing (seroprevalence is the proportion of people with antibodies to a disease, a marker of prior infection), and prevalence surveys.
Each of these data sources have strengths and weaknesses, see \textcite{royalSocietyRnumber} for further details.

Community testing is broadly available, but does not test a random sample of the population.
The number of tests conducted varies over time and space, for a variety of known and unknown reasons.
These include: policy on who is eligible for testing, the availability of tests, and the willingness of individuals to be tested.
Therefore, fluctuations in the number of positive tests may not reflect changes in the true incidence of the disease.
For large parts of the pandemic, community testing was widely available in the UK.
Therefore, there are many test results, allowing detailed analyses to be performed, including stratification by small geographic areas or age groups.

Seroprevalence testing provides information on a marker of recent prior infection.
Prior infection is more common than current infection, hence seroprevalence estimation requires a smaller sample size than current prevalence.
However, there is a delay between infection and the development of antibodies, hence seroprevalence is not a real-time measure of the burden of the disease.
Furthermore, seroprevalence data is normally based on convenience samples (\eg blood donors) who are not representative of the general population.

Severe events counts are generally a reliable measure of the burden of the disease.
The criteria for being a severe event are normally well-defined and generally well-recorded in the UK context\todo{ref severe events criteria}.
Therefore, the data is subject to fewer biases than community testing.
However, SARS-CoV-2 rarely leads to severe events in younger individuals, meaning severe event counts are insensitive to changes in transmission only occurring in younger individuals.

Prevalence surveys in representative samples of the population are the most reliable measure of the burden of the disease.
They are not subject to the biases of community testing and observe the whole population, unlike severe events, although they can suffer from non-response bias.
However, they are expensive to power to inform detailed analyses.
Often, some modelling is required to borrow information across strata or time to provide stable estimates, as well as to correct for non-response bias (see \cref{E-intro:sec:cis}).

The use of prevalence surveys for estimating incidence and transmission is the focus of this thesis.
In particular, I focus on the CIS (Coronavirus (COVID-19) Infection Survey), run by the ONS (Office for National Statistics)~\autocite{CIS,cisMethodsONS}.
The CIS was a longitudinal study, testing a large number of indidividuals weekly or monthly for SARS-CoV-2; it is described in detail in \cref{E-intro:sec:cis}.
Early in the pandemic, a methodology was developed for using CIS data to estimate prevalence (see \cref{E-intro:sec:cis}).

A second prevalence survey ran in the UK, known as REACT (REal-time Assessment of Community Transmission)~\autocite{rileyResurgence,rileyREACT}.
REACT was a series of cross-sectional surveys, run across 19 rounds between May 2020 and March 2022.
Each round consisted of at least 100,000 randomly-sampled individuals from the UK contributing swabs for testing and questionnaire data~\autocite{elliottTwin}.

A major advantage of the CIS over REACT is that the CIS has daily testing of individuals, while REACT has no test results between rounds.
This means that REACT cannot be used to estimate transmission or incidence between rounds, instead relying on model assumptions at these times.
A particular instance of this is that a peak in late December 2020 occurred between rounds of the REACT survey, complicating analysis of the survey data at that time~\autocite{rileyREACTround8}.

The primary aim of this thesis is to estimate incidence and transmission from the CIS data.

\section{Estimating incidence and transmission} \label{intro:sec:estimating-incidence}

As noted above, incidence and transmission are extremely important quantities for informing the response to a pandemic but cannot be observed directly.
Therefore, they must be inferred from observable quantities.

Many methods for estimating incidence and transmission were developed in the context of the HIV/AIDS pandemic.
% HIV is transmitted sexually or through blood and causes the disease AIDS.
This ongoing pandemic has killed 40 million people, peaking at 2 million annual deaths~\autocite{unaids2023}.
The large burden of the disease has motivated many advances in infectious disease epidemiology and biostatistics, including several which form the methodological background of this thesis.

\subsection{Backcalculation} \label{intro:sec:backcalc}

\emph{Backcalculation} is a statistical procedure for estimating incidence based on a measurement of prevalence.
It was proposed by \textcite{brookmeyerMethod} in the context of HIV/AIDS.
In this context, backcalculation estimates the incidence of HIV infection from data on the number of AIDS diagnoses, and the time between infection and AIDS diagnosis~\autocite{brookmeyerBackcalculation,brookmeyerMeasuring}.
Two processes needed to be considered: one generating infections and one relating infections to prevalence.
% AIDS is incurable, therefore, AIDS prevalence is equivalent to cumulative incidence.

The statistical framework developed for HIV is applicable to SARS-CoV-2.
(see \cref{E-inc-prev:sec:infection-process}).
However, unlike with HIV/AIDS, recovery from SARS-CoV-2 infection is possible, so recoveries need to be considered in the backcalculation.
This introduces a dependency structure in the prevalence data (see \cref{E-inc-prev:sec:prevalence-process}).
The development of this framework makes clear that the duration of positivity (how long an individual tests positive for SARS-CoV-2) is the key quantity relating prevalence to incidence.
Therefore, estimation of duration is central to this thesis (see \cref{intro:sec:duration}).

Furthermore, prevalence surveys are noisy because they are based on population sampling.
The original formulations of backcalculation neglected any observation noise.
AIDS is almost always diagnosed and recorded in developed countries.
That is, the observations of AIDS diagnoses are the same as the true incidence of AIDS.
An exception is that the reporting delay may be important~\autocite{paganoHIV}; but reporting delay is not important for this thesis's work.
Since its development, backcalculation has been further developed for a wide-variety of contexts.
I incorporate observation noise into the backcalculation approach in \cref{inc-prev:sec:observation-process}.
% Reporting delay is not relevant to the studies in this thesis, and I ignore it in this and further discussion.

\Textcite{abbottCISincidence} applied backcalculation to CIS data to estimate the incidence of SARS-CoV-2 in the UK.
They used a Gaussian process prior to smooth the incidence, applying the prior to either smooth the log-incidence or its derivative; smoothing of the incidence is required to stabalise the estimates~\autocite{brookmeyerBackcalculation}.
\Textcite{abbottCISincidence} used \textcite{hellewellPCRSensitivity}'s estimates of the sensitivity of testing to inform the backcalculation, which are based on a longitudinal study in healthcare workers (see \cref{intro:sec:duration-SARS-CoV-2}).
They fit to summary statistics of the CIS data, using a daily, independent Gaussian likelihood with parameters estimated from the posterior point estimate and 95\% credible interval published by the ONS.

The estimates I present in \cref{E-backcalc} are methodologically similar.
However, I fully propagate the uncertainty from the prevalence estimation procedure and use estimates of the duration of positivity from a general population study.
\Textcite{abbottCISincidence} include the short period of low but increasing test sensitivity at the start of an infection (see \cref{E-biology-data:sec:natural-history}).


\subsection{Mechanistic models}

\subsubsection{Background}

Mechanistic models make assumptions on the biological and epidemiological mechanisms driving transmission~\autocite{lesslerMechanistic}.
Therefore, the model's state and parameters have a biological and/or epidemiological interpretation.
% Of particular interest is that the basic reproduction number, $\R$, and the effective reproduction number, $R_e(t)$, which can both be calculated as functions of the model parameters; using \cref{E-backcalc}'s approach, additional modelling would be required to estimate these numbers.
In particular, this allows changes in transmission to be decomposed into the contributing factors, \eg the number of contacts per day or the probability of transmission upon contact (see \cref{E-SEIR:sec:mechanistic-models}).
The ability to estimate the contribution of each of these factors can inform public health policy.
Furthermore, mechanistic models can be used for scenario modelling, which simulates the effect of interventions.
A scenario is the effect of a proposed intervention (or lack thereof), simulated by modifying the relevant parameters.
% The mechanistic model can then be simulated forward in time to understand the intervention's effects.
% All of these properties make mechanistic models a useful tool for understanding and controlling infectious diseases.
% However, they make stronger assumptions about the disease and population behaviour than statistical models.

The literature on mechanistic models is vast, having been developed for over a century.
The model I introduce in \cref{E-SEIR:sec:SIR} was first formulated by \textcite{kermackContribution}.
However, the earliest mechanistic model to be formulated mathematically was probably \textcite{rossMalariaA}'s model of malaria transmission~\autocite{lesslerMechanistic}.
This early contribution led to an important insight for public health, showing that malaria could be controlled even if mosquitoes were not fully eliminated.

\Textcite{kermackContribution} was a seminal paper for the field, explaining the observation that epidemics ended before all individuals were infected.
They developed a model showing that a population-level build-up of immunity known as \emph{herd immunity} is sufficient to explain this observation.
Their model has inspired much of the subsequent literature, a full review of which is beyond the scope of this thesis.
The relevant background information is explained in \cref{E-SEIR:sec:mechanistic-models}.

Two types of mechanistic models were prominent during the SARS-CoV-2 pandemic: those based on a \emph{renewal equation} and those with a \emph{compartmental} structure.

The renewal equation~\autocite{fraserRenewal} for an infectious disease, in the most general form, is:
\begin{align}
    I(t) &= \int_{0}^{t} \beta(t,\tau) I(t-\tau) d \tau
\end{align}
where $I(t)$ is the mean incidence at time $t$ and $\beta(t, \tau)$ is the instantaneous probability of an individual infected $\tau$ time units ago infects an individual at time $t$.
A scaled measure of $I(t)$ (\eg hospital admissions or community test results) allows estimating $\beta$.
The most common implementations are the R packages EpiNow2~\autocite{EpiNow2} and EpiEstim~\autocite{EpiEstim}.
Renewal equations do not feature in this thesis, for further information, including practical considerations when using them as the basis of a statistical model, see \textcite{nashEstimating,gosticPractical}.

Compartmental models split the population into compartments, each representing a different state of the disease.
The \emph{dynamics} of the epidemic, how it changes over time, are represented by the transitions between compartments.
Mathematically, the dynamics are described by ODEs (ordinary differential equations) or SDEs (stochastic differential equations).
Unlike renewal equations, there are not widely-used implementations of compartmental models.
A commonly used frameork is the SEIR (susceptible, exposed, infectious, recovered) model.
The SEIR model, has four components (susceptible, exposed, infectious, recovered), with the population divided into these components; it is described in detail in \cref{E-SEIR:sec:mechanistic-models}.

Compartmental models can be fitted to almost any data source, and commonly incorporate multiple data sources, known as \emph{data synthesis}, a technique reviewed by \textcite{birrellEvidence}.



\subsubsection{Application to SARS-CoV-2}
{\color{red} you are missing a big opportunity here. You could elaborate a bit more the SPIMO part to explain what kind of data people used and introduce the question of whether the same evidence could be provided just by using data from a CIS type model. This is what motivates your research. Other people have used (only?) prevalence data (you give a lot of references below)..but have they recosntructed incidence and transmission only using prevalence data?}

Many studies involving mechanistic models were conducted during the pandemic, with at least 100 articles published in the first six months of 2020 alone~\autocite{shankarSystematic}.
In the UK, the Scientific Pandemic Influenza Group on Modelling, Operational sub-group (SPI-M-O) was a sub-committee of the Scientific Advisory Group for Emergencies (SAGE), using this type of models to generate evidence for policy development~\autocite{medleySPIM,govSPIMO}.
For example, each of the stages of lifting the lockdown in 2021 was supported by  modelling studies informing the government's decision~\autocite{sageEvidence}.

Each week, the members of SPI-M would produce a set of estimates of the current state of the epidemic (\eg the value of $\Re$), known as \emph{nowcasting}.
The nowcasting estimates were mainly based on mechanistic models.
These estimates, once any estimates unduly affected by issues (\eg data quality issues), were statistically combined into a consensus value~\autocite{parkCombining}.
The consensus value was published on \url{gov.uk} and informed the government's response to the epidemic~\autocite{govRnumber}.
The academic groups contributing estimates used a variety of models, reviewed by \textcite{royalSocietyRnumber} (see appendix 2 of that review for details of the specific implementations).
Most compartmental models used by SPI-M-O were age-stratified, as differences between age groups are important for both the transmission and severity of SARS-CoV-2 (see \cref{E-SEIR:sec:structured-populations}).

In this thesis, I focus on the use of data from prevalence surveys.
Specifically, surveys which collect swabs from individuals for testing by RT-PCR (reverse transcription polymerase chain reaction, described in detail in \cref{E-biology-data:sec:PCR}).
Several compartmental models incorporated data from SARS-CoV-2 prevalence surveys, alongside other data sources~\autocite{daviesAssociation,ironsEstimating,knockKey,nicholsonImproving,pooleyEstimation,birrellRTM2}.
These models incorporate prevalence survey data by adding additional compartments representing RT-PCR positive individuals, who may not be infectious (this is common, see \cref{E-biology-data}); except \textcite{nicholsonImproving} who have a more sophisticated approach (below) and \textcite{ironsEstimating}, who assume RT-PCR positivity coincides with infectiousness.
The length of stay in these compartments (the duration of time positive) is assumed to follow a gamma distribution, with the parameters estimated from external data or having at most one free parameter.
The proportion of the population in these compartments are then fit to the prevalence survey data using a binomial likelihood where possible, although some approaches take a Gaussian approximation.
These approaches are similar to how these models are fit to other data sources, such as hospital admissions or deaths.

\Textcite{nicholsonImproving} have the most sophisticated use of prevalence survey data.
They allow an arbitrary distribution of the duration of positivity, based on the estimates of \textcite{hellewellPCRSensitivity} (see \cref{intro:sec:duration-SARS-CoV-2} for discussion of the \textcite{hellewellPCRSensitivity} study).
Furthermore, they incorporate the sensitivity and specificity of the RT-PCR test into their model.
% However, they do not incorporate age-stratification into their transmission model, and primarily aim to estimate the bias of community testing in the UK rather than incidence and/or transmission.

\todo[inline]{Maybe the following paragraph should be in the contribution section?}
In \cref{E-SEIR}, I describe a compartmental model for SARS-CoV-2 transmission, which I fit to CIS data.
I allow a more flexible distribution of the duration of positivity than any of the papers discussed above, except \textcite{nicholsonImproving}, incorporating the skew of the distribution.
This distribution is based on data from a representative sample of the UK population, rather than convenience samples (see \cref{intro:sec:duration-SARS-CoV-2}).
Unlike \textcite{nicholsonImproving}, I include age-stratification in the transmission model, allowing estimation of how transmission varies by age.
I use only data from the CIS, and show this is sufficient for estimating incidence and transmission.
Finally, I fit directly to counts from the CIS, rather than an approximation of this data, which has not previously be done.

\subsection{Other approaches}

Other approaches have been taken to estimate incidence and/or transmission from the CIS data.

\Textcite{mccabeCISincidence}, adapting the methodology \textcite{ealesAppropriately} developed for REACT, estimate $\Re$ and the growth rate from the CIS data.
They estimate a posterior distribution of the parameters of a spline by fitting to the prevalence results via a binomial distribution.
Their setup penalises the spline deviating from a constant growth rate.
The growth rate is then calculated from the derivative of the spline, an analytical transformation of the parameters.
Since, under reasonable model assumptions, there is a one-to-one correspondence between reproduction numbers and growth rates~\autocite{wallingaGI}, and they assume that the growth rate in incidence and prevalence is equal, this also estimates $\Re$.

\Textcite{colmanAscertainment} used CIS prevalence estimates to estimate the \emph{ascertainment rate} of community testing (the proportion of all infections that community testing detected).
Their methodology was similar to \textcite{abbottCISincidence} (see \cref{intro:sec:backcalc}), including using estimates from \textcite{hellewellPCRSensitivity} for how the sensitivity of RT-PCR testing varies over an infection.
Rather than using a Gaussian process, as \textcite{abbottCISincidence} do, \textcite{colmanAscertainment} provide stability by assuming the ascertainment rate is assumed to be piecewise constant.
They do not fully propagate the uncertainty from the CIS prevalence estimates, considering only the bounds of the 95\% confidence intervals the ONS publishes for prevalence.

    \section{Estimating duration} \label{intro:sec:duration}

The distribution of the duration of positivity is central to the relationship between incidence and prevalence (see \cref{E-inc-prev:sec:prevalence-process}).
Therefore, a reliable estimate of this quantity is required to achieve this thesis's aims.

\subsection{Methodology}

Two approaches are commonly used to estimate the duration of a disease: either modelling an underlying biomarker or modelling the duration directly~\autocite{sweetingEstimating}.
For SARS-CoV-2, both approaches would be based on the results of RT-PCR testing.

The biomarker approach, which I take in \cref{E-ATACCC}, models how the amount of virus in an individual varies over time.
The RT-PCR tests commonly used give a proxy for viral load for positive tests (see \cref{E-biology-data:sec:PCR-process}).
Modelling a biomarker uses more information per observation, but requires stronger assumptions.
For example, a functional form of the behaviour over time of the biomarker is required.
In addition, if individual-level variation wants to be included, which is generally important, a distributional form of random effects is required.
This requires both sufficient observations per individual and an assumption on the form of the distribution.

Modelling the duration directly, as I do in \cref{E-perf-test,E-imperf-test} considers only the binary result at each test (positive or negative); in this thesis a \emph{survival analysis} framework is adopted.
This approach generally requires fewer parameters, and no random effect(s), reducing the computational burden.
It is also easier to specify non-parameteric forms of the distribution, which is important for SARS-CoV-2 as the tail behaviour may be important.
A more detailed review of the literature is in the relevant chapters.
% Survival analysis is the area of statistics concerned with estimating the distribution of the times between two events.
Other related approaches, such as a multi-state model (reviewed by \textcite{jacksonMSM}), could also be considered; multi-state models can be viewed as a generalisation of survival analysis.

In both cases, longitudinal data is required.
Therefore, cohort studies, where the same group of indivdiuals are followed over time, are the most appropriate study design.

\subsection{SARS-CoV-2} \label{intro:sec:duration-SARS-CoV-2}

\subsubsection{Cohort studies}

In this thesis, I make use of two cohort studies with differing designs.
These designs have complementary strengths, and I combine information from the studies to make use of these.
Both of the studies recruited individuals from the general population, aiming to observe a cohort of infections that are representative of the infections in the UK community.

% In addition to population-level surveillance, cohort studies help understand other aspects of the pathogen~\autocite{royalSocietyRnumber}.
% For example, contact tracing data can inform how likely it is for transmission to occur in different settings and/or between different groups of people.
The first study I use, ATACCC (Assessment of Transmission and Contagiousness of COVID-19 in Contacts)~\autocite{singanayagamCommunity,hakkiOnset}, performed daily testing of a small number of individuals with short follow-up.
The density of this sampling allows for reliable estimates of the viral load dynamics and other quantities of interest, most importantly the duration of detectability, but the results are limited because the small sample size and short follow-up means that the tails of these distributions cannot be estimated.
I describe ATACCC in detail in \cref{E-biology-data:sec:ataccc} and use it to estimate duration in \cref{E-ATACCC}.

The second study is the CIS, which I previously mentioned.
In addition to estimating prevalence, the CIS followed the same individuals over a long period of time (over a year in many cases), collecting longitudinal data.
The large sample size and long follow-up mean that the tails of the distribution of the duration of positivity can be estimated.
However, the lack of frequent testing (at most weekly) means that the viral load dynamics cannot be estimated.
In particular, the vast majority of detected infections had only one or two positive tests, and hence the viral load trajectory of these infections cannot be estimated.
I describe the CIS in detail in \cref{E-intro:sec:cis} and use it to estimate duration in \cref{E-perf-test,E-imperf-test}.


\subsubsection{Previous estimates}

An early meta-analysis estimated that individuals test positive for SARS-CoV-2 for a mean of 14.6 days (95\% CI: 9.3--20.0 days)~\autocite{cevikShedding}.
The longest reported duration was observed at 83 days, although beyond day 9 no live virus was detected, indicating that the individuals testing positive for longer than this were not infectious.
However, most studies included in the meta-analysis involved hospitalised patients or had unclear inclusion criteria, and hence may not be representative of the general population.
These summary estimates are insufficient for backcalculation, which requires a distribution of the duration of positivity.

\Textcite{hellewellPCRSensitivity} estimated the probability of an individual testing positive at each day after infection.
This measure is highly related to the duration of positivity.
The cohort in their study was drawn from healthcare workers, and hence was focused on working-age adults.

\Textcite{binnySensitivity} applied a slight variant of \textcite{hellewellPCRSensitivity}'s methodology to data from New Zealand.
The situation in New Zealand, who were successfully pursuing a zero-COVID strategy at this time, means that the individuals in the study were unusual.
For example, a third were travelers detected during their quarantine period on arrival to New Zealand, but would have had negative RT-PCR tests before their departure.

\Textcite{ealesCharacterising} estimated the duration of positivity from REACT data.
Specifically, individuals who tested positive in round 8 of REACT (6th--22nd Jan 2021) were invited to take two additional swab tests.
Defining the time of the initial positive test at time 0, \textcite{ealesCharacterising} estimated the probability of remaining positive at each day after the initial positive test.
They made a strong parametric assumption that the probability decreases exponentially, with a sensitivity analysis assuming a plateau before the decay.
This assumption is necessary because they had at most 17 days of follow-up, and hence could not estimate the tail of the distribution.
Overall, they estimate a median duration of 14.0 days (95\% CI: 12.9--15.4 days) but that this varied substantially by the viral load of an individual at the time of the initial positive test.
Individuals with a higher viral load were estimated to have a longer duration of positivity; the highest viral load individuals were estimated to have a median duration of 19.6 days (16.1--25.8 days).
This could be due to the higher viral load leading to a longer duration of positivity, or that individuals with a higher viral load were more likely to have been recently infected at the time of the initial positive test.
They cannot estimate how long before the initial positive test the individual was infected; therefore, they cannot distinguish between these two possibilities.
This also means they underestimate the duration of positivity.

For the purposes of this thesis, estimates applicable to the general population are required.
There are no reliable estimates of the full distribution of the duration of positivity in a general population cohort available in the literature.
Therefore, I estimate the duration of positivity from the ATACCC and CIS studies, as described above.

\section{Bayesian inference} \label{intro:sec:Bayes}

All inference in this thesis is Bayesian.
Including prior information allows identifiability in situations where this would not otherwise be possible and allows for combining knowledge from multiple sources.
Many previous studies I build on used Bayesian inference.

Analytically deriving the posterior distribution is impossible for the models in this thesis.
Therefore, I use computational methods to sample from the posterior distribution.
The method I use for the majority of the analyses is MCMC (Markov chain Monte Carlo).

\subsection{Markov chain Monte Carlo} \label{intro:sec:MCMC}

MCMC is a class of algorithms for sampling from a distribution where the normalising constant for the distribution is unknown.
I will use it to sample a set of parameters, say $\psi$ (which may be a scalar or vector), from a posterior distribution $p(\psi \mid y)$ where $y$ is the data (again, scalar or vector).
MCMC algorithms produce a sample $\psi^1, \psi^2, \dots, \psi^M$ from $p(\psi \mid y)$ by constructing a Markov chain with $p(\psi \mid y)$ as its stationary distribution~\autocite[275]{gelmanBDA}.
It can be proved that as $M\to\infty$, the sample tends towards a sample from the stationary distribution, \ie the target posterior.
Further details of MCMC are given in \cref{E-MCMC}.
Two practical issues arise when applying MCMC: \emph{convergence} and \emph{stability}~\autocite[72]{lunnBUGS}.

Convergence is how close a MCMC chain's samples are to its stationary distribution.
Early draws from the Markov chain reflect the choice of the starting point, $\psi^0$, rather than the stationary distribution that the chain will eventually converge to~\autocite[282]{gelmanBDA}.
Various metrics quantify this, I will make use of the improved Rhat statistic~\autocite{vehtariRhat}.
%The Rhat statistic is defined for a scalar parameter $\psi$.
%Let $\psi^{(ij)}$ denote the $i$th (of $M$) sample from the $j$th chain (of $N$).
%Let $\bar{\psi}^j$ denote the mean value of the samples of $\psi$ from the $j$th chain, $\bar{\psi}^j = \frac{1}{M} \sum_{i=1}^M \psi^{(ij)}$.
%Let $\bar{\psi}$ denote the mean value of the samples of $\psi$ from all chains, $\bar{\psi} = \frac{1}{N} \sum_{j=1}^N \bar{\psi}^j$.
%Then the between-chain variance is $B = \frac{M}{N-1} \sum_{j=1}^N (\bar{\psi}^j - \bar{\psi})^2$.
%The within-chain variance is $W = \frac{1}{N} \sum_{j=1}^N \frac{1}{M-1} \sum_{i=1}^M (\psi^{(ij)} - \bar{\psi}^j)^2$.
A Rhat of 1 means that the within-chain and between-chain variance are equal, informally that convergence is perfect, as far as can be measured by this technique.
Various rules-of-thumb exist for what should be considered an acceptable Rhat.
Historically, 1.1 has commonly been recommended, although more recent work suggests that 1.01 or 1.05 is more appropriate~\autocite{vehtariRhat}.

The stability of estimates considers the error arising from only using a finite sample of the distribution and the samples being autocorrelated.
Autocorrelation means that estimates using the sample have higher variance than if it were an iid sample from the posterior~\autocite[286]{gelmanBDA}.
The \emph{effective sample size} corrects for the autocorrelation.
The effective sample size can be interpreted as the number of iid samples that would have the same variance as the MCMC sample~\autocites[286]{gelmanBDA}{vehtariRhat}.
Various techniques have been proposed for computing the effective sample size, I will follow the approach of \textcite{vehtariRhat}, implemented in RStan~\autocite{RStan-2-32-3}.


% \section{Notational conventions}

% \begin{itemize}
%     \item Lower-case variables are realisations of the respective upper-case random variables.
%     \item Matrices and vectors are bold and have elements with the same unbolded letter, \eg $\vec{x} = [x_1, x_2, \dots]^T$
%     \item $\cdot$ denotes element-wise multiplication
%     \item Distributions used defined in \cref{E-distributions}
% \end{itemize}

\section{Thesis aims and contribution} \label{intro:sec:aims}

The overall question that I investigate in this thesis is: how can prevalence surveys best be used to understand incidence and transmission?
Prevalence surveys provide data that is far more representative of the general population than other data sources (see \cref{intro:sec:data-sources}), therefore, conclusions based on them should be far more robust.
There are two components to this question.
First, how can prevalence surveys be designed to help estimate these quantities.
Second, what statistical methodology can be used to estimate these quantities from prevalence surveys.
This thesis will focus on the second component.
However, natural extensions of the work I undertake would inform the first component.

In order to achieve these aims, I use a case study, specifically the SARS-CoV-2 epidemic in England from Mon 31st Aug 2020 until Sun 25th Jan 2021.
This case study has several features that make it useful for the aims of this thesis.
These include that the CIS was of sufficient size and incidence sufficiently high that there is enough data to perform the analyses.
Additionally, incidence begins rising over this period, which is the period when a surveillance system is needed to provide a warning of upcoming issues.
The CIS began in April 2020, when incidence was falling due to the first lockdown in the UK.
Incidence remained low and fairly flat in England over summer 2020, until it began rising in mid or late August.
Finally, the period ends before the roll-out of the vaccine, which likely affects many important aspects of the analysis.
In particular, the duration of positivity and the susceptibility of the population.
Including both of these elements would require more complex modelling but include idiosyncratic features of the SARS-CoV-2 pandemic that are probably less generalisable to future diseases.

A secondary aim of this thesis is to improve our understanding of the epidemic in England over this period, and our understanding of the SARS-CoV-2 virus more broadly.
The results of the analyses I perform in pursuit of the primary aim will naturally contribute to this aim.

\subsection{Software and data availability}

In order to best fulfill this thesis's primary aim, the methodology developed should be easy for others to use.
Therefore, the code for the analyses in this thesis is available online.
An index to the various repositories is available at\todo{insert GitHub link}.
Two elements of the code have been structured as R packages to enable their application to future contexts.

First, the framework to simulate the CIS (used in \cref{E-imperf-test:sec:simulate,E-perf-test:sec:simulation-study}).
The package enables customisation of various features of the study, for example the testing regime of the participants, the sensitivity of the tests, and the duration of positivity.
This package would be particularly useful in answering questions regarding the design of future prevalence surveys, for example, how frequently should individuals be tested, or how many individuals should be tested.

Second, the survival analysis framework used to infer the duration of positivity in \cref{E-perf-test,E-imperf-test}.
The framework allows for all the different analyses performed in these chapters to be specified by the user in a simple interface.
Furthermore, adding new analyses, for example varying the priors or the inclusion of covariates, is straightforward.

Where possible, aggregated, non-disclosive versions of the datasets are available alongside the code.
The original ATACCC data used is available alongside the code.
The original CIS data can only be accessed by accredited researchers within the ONS's SRS (Secure Research Service); see \url{https://www.ons.gov.uk/aboutus/whatwedo/statistics/requestingstatistics/secureresearchservice} for details.

Almost all code, excluding dependencies, was written from scratch for these analyses.
The exception is the Markov chain Monte Carlo sampler used in \cref{E-SEIR}, which was written by Sanmitra Ghosh for the article \textcite{ghoshApproximate}.

\subsection{Methodological contributions}

As its primary aim, this thesis makes several methodological contributions.

First, in \cref{E-inc-prev:sec:observation-process}, I provide a theoretic justification for the use of deterministic backcalculation in this setting.
A deterministic backcalculation approach was used by \textcite{abbottCISincidence} and I will use it in \cref{E-backcalc}.
This approach models the prevalence at any time as a deterministic function of the incidence, rather than as a random variable.
I show that, this is a good approximation as long as the proportion of the population sampled is small.
In particular, it does not require the prevalence or incidence to be large.

Next, in \cref{E-perf-test}, I estimate the duration of RT-PCR-positivity from double censored data with arbitrary periods where infections could be missed (a generalisation of truncation).
This is based on the CIS data.
While statistical frameworks have been previously developed which included this case, they had not been used in practice.
In \cref{E-imperf-test}, I extend this framework to include false negatives.

Within these analyses, I include information derived from the ATACCC study.
In order to do so, I propose a novel prior which appropriately discounts the information from analysing ATACCC study, which has inappropriate model assumptions when applied to the larger sample size in the CIS data.

A particular challenge with these analyses is that they must be performed within the SRS because they require individual-level data.
The SRS is a form of TRE (Trusted Research Environment), with limited computing power.
Analyses with long run times (\ie days) and/or requiring large amount of parallelisation (\eg a high-performance cluster) are not feasible.

Finally, in \cref{E-SEIR}, I estimate the transmission of SARS-CoV-2 in England using a mechanistic model, from only the CIS data.
This includes the development of a novel observation model to link the mechanistic transmission model to the data.
The observation model allows the inclusion of the skew in the duration of positivity, without being computationally infeasible.

\subsection{Epidemiological contributions}

The secondary aim of this thesis is providing new estimates to improve our understanding of SARS-CoV-2 in general, and the epidemic in England over the period being studied.

In \cref{E-imperf-test}, I present estimates of the duration of RT-PCR-positivity in the general population.
These estimates could be used to inform public health policy, for example, in interpreting RT-PCR test results or formulating quarantine policies.

In \cref{E-transmission}, I present estimates of the incidence and transmission of SARS-CoV-2 in England over the period being studied.
These estimates contribute to the literature reconstructing the SARS-CoV-2 epidemic in England.
Understanding the dynamics of the past infection is important for informing the response to future pandemics, and the future burden of SARS-CoV-2.

\subsection{Structure}

In \cref{E-biology-data}, I provide background information on the natural history of SARS-CoV-2, the RT-PCR testing process used to produce the data used throughout this thesis, and describe the two cohort studies used in this thesis.
Then, in \cref{E-inc-prev}, I formally describe the stochastic processes which generate infections, prevalence, and the observations of prevalence.
A key insight in this chapter is that the distribution of the duration of positivity is the key quantity linking incidence and prevalence.

Therefore, I then turn to estimating this distribution.
I start, in \cref{E-ATACCC}, by estimating the duration of positivity from the ATACCC study.
This provides a reliable estimate of the bulk of the distribution (out to around 20 days) but shows that there is a significant tail.
To estimate the tail, a large sample size and long follow-up is required.
Therefore, I turn to the CIS data in \cref{E-perf-test,E-imperf-test}.
In \cref{E-perf-test}, I provide a framework for estimating the duration of positivity from the CIS data, assuming perfect tests.
However, the assumption of perfect tests is not realistic; in \cref{E-imperf-test}, I extend the framework to include false negatives.

Having estimated the duration of positivity, I then turn to estimating incidence and transmission from the CIS data in \cref{E-transmission}, thus fulfilling the primary aim of this thesis.
I use both of the approaches discussed in \cref{intro:sec:estimating-incidence}, contrasting their results and discussing the advantages and disadvantages of each in this context.
Finally, I conclude in \cref{E-conclusion}.

Definitions of the probability distributions used throughout this thesis, are given in \cref{E-distributions}.
Other appendices provide additional details.

\ifSubfilesClassLoaded{
  \appendix
  \subfile{MCMC-appendix}
  \listoftodos
}{}
\end{document}