\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Introduction} \label{intro}

Infection with the SARS-CoV-2 virus is estimated to have killed approximately 15 million in the most acute phase (to the end of 2021) and 30 million in total~\autocite{whoCOVIDExcess,economistCOVIDExcess}.
Beyond the lives lost, there were massive health, economic, and societal costs.

History suggests severe pandemics are not rare (see \cref{intro:fig:pandemic-timeline}).
\begin{figure}
    \includegraphics[width=\textwidth]{introduction/pandemic-timeline}
    \caption[Timeline of pandemics.]{%
        Timeline of pandemics.
        See \url{https://ourworldindata.org/historical-pandemics} for details and sources.
        Licensed under \href{https://creativecommons.org/licenses/by/4.0/}{CC-BY} by Saloni Dattani, Klara Auerbach, Marwa Boukarim, and Max Roser.
    }
    \label{intro:fig:pandemic-timeline}
\end{figure}
Fully quantifying the burden of historical pandemics is challenging due to the absence of systematic records.
However, our best records suggests that, since 1600, they have (on average) occurred every four years with a mean death toll of 5.6 million~\autocite{maraniNovelEpidemics}.
Recent estimates suggest that the current impact of pandemics is on average of over 2.5 million deaths per year~\autocite{madhavPandemicMortality}.

All pandemics start as an \emph{outbreak}, a sudden and unexpected rise in the number of people with a disease in a local area; if this spreads over a larger geographic area (\eg a country) it becomes an \emph{epidemic}; if it spreads globally then it is a \emph{pandemic}~\autocite{grennanPandemic}.
The precise meaning of these terms varies, they are defined implicitly by their usage rather than formal definitions~\autocite{morensPandemic,doshiElusive}.
I will refer to the SARS-CoV-2 epidemic within England (or the UK), and the global impact as the pandemic.

In this context, \emph{surveillance} is the ability to detect and monitor the spread of an outbreak.
Surveillance is important at every stage: early on, for detecting a new outbreak quickly and assessing its likely impact and later for monitoring the ongoing burden of the disease and the effectiveness of interventions~\autocite{whoFluSurveillance}.
In all cases, surveillance informs public health policy.
In this thesis, I consider methods to improve surveillance, using the SARS-CoV-2 epidemic in England as a case study.

\section{Surveillance metrics} \label{intro:sec:metrics}

No single metric summarises the full state of an epidemic, and no single data source fully informs all metrics of interest~\autocite{royalSocietyRnumber,pellisEstimation,paragGrowthRates}.
Therefore, a range of metrics and surveillance systems are required to understand the state of an epidemic and the risk it poses.

\subsection{Growth of an epidemic}

Various forms of \emph{reproduction number} were prominent throughout the SARS-CoV-2 pandemic~\autocite{pellisEstimation}.
Broadly, a reproduction number describes the number of secondary infections generated by a single infection.
Here, following \textcite{pellisEstimation}, and building on over a century of infectious disease dynamics literature, I define three that are broadly useful.

The most common reproduction number is the \emph{basic reproduction number}, $\R$.
$\R$ is the mean number of secondary infections generated by a single infection in a \emph{fully susceptible} population with \emph{standard behaviour patterns}.
A fully susceptible population means that none of its members have any immunity to the disease.
Note that this definition implies $\R$ is constant for a given pathogen and population.
In the early stages of an epidemic caused by a novel pathogen, the number of individuals with immunity is negligible, and hence $\R$ describes this part of the epidemic well.
$\R$ has a threshold value of 1: an outbreak has the potential to cause an epidemic if and only if $\R > 1$~\autocite[76]{diekmannMathematical}.

The \emph{effective reproduction number}, $\Re$, is the mean number of secondary infections generated by a single infection at time $t$.
In particular, it uses the behaviour and immunity status of the population at time $t$.
With constant behaviour and a disease that grants immunity following infection, $\Re$ declines smoothly.
$\Re$ describes the current dynamics of the epidemic: $\Re > 1$ means the epidemic is growing, $\Re < 1$ means it is shrinking, and $\Re = 1$ means it is stable.
In simple epidemic models (see \cref{E-SEIR:sec:SIR}), $\Re$ is proportional to the product of the rate of contact, the probability of transmission upon contact, and the proportion of the population that is susceptible.
Interventions act by reducing one of these components \eg masks reduce the probability of transmission and vaccination reduce the susceptible population.
Therefore, $\Re$ informs the strength of intervention required to control the epidemic.

The \emph{control reproduction number}, $\Rc$, is the mean number of secondary infections that would be generated by a single infection at time $t$ if in a fully susceptible population.
$\Rc$ is also known as the \emph{reproduction number excluding immunity}.
It describes the effect on the epidemic of interventions (except vaccination) that are in place at time $t$.
$\Rc$ is useful when comparing the effects of interventions at different points in time, when the immunity status of the population has changed.
For example, when comparing the English lockdown in March 2020 and January 2021, there are two effects in play: the number ofindividuals with immunity, higher in 2021; and the different measures already (?) in place when the lockdown was implemented???
$\Rc$ quantifies the latter effect.

These definitions ignore many complexities that arise when theoretically defining or practically estimating any of the reproduction numbers~\autocite{pellisEstimation}.
For example, effects due to seasonality, what a ``mean infection'' means in a heterogeneous population, and the lack of a ground truth for these numbers in almost all situations.
However, their intuitive simplicity and convenient properties in simple epidemic models mean that they are useful concepts for guiding policy.

Reproduction numbers are strongly connected to \emph{growth rates}.
If changes in behaviour and susceptibility are negligible, as they often are over short periods of time, epidemics grow (or shrink) exponentially, with a \emph{growth rate} $r$.
For a given disease and population, an analogous growth rate can be defined for each definition of the reproduction number~\autocite{pellisEstimation,paragGrowthRates,wallingaGI}.
The advantages of using the growth rates are that they are easier to estimate and capture how quickly spread happens in calendar time; however, they do not directly give the strength of intervention required to control the epidemic~\autocite{royalSocietyRnumber}.

\subsection{Size of an epidemic}

Growth rates and reproduction numbers only provide information on whether how an epidemic is changing.
The size of the epidemic is just as, if not more, important~\autocite{pellisEstimation}.
\emph{Incidence}, the number of new infections in a given time period  is the primary metric for the magnitude of a pandemic.
Incidence informs the short-term future burden of the disease, for example, the future number of severe events (hospitalisations or deaths) when combined with severity measures, such as the infection fatality rate (IFR), the proportion of infected individuals who die.

\emph{Transmission} refers to the process by which an infectious individual generates new infections. Estimating transmission refers to inferring this process. Understanding components of transmission  (\it{e.g.} the number of contacts each individual makes per day) allow interventions to be targeted.
and to forecast future incidence.

\emph{Prevalence} is the proportion of the population with the disease at a given time .
Whether a given individual is \emph{prevalent}, {\it{i.e.}} has the disease, is often measurable through diagnostic testing.
Performing diagnostic tests in a sample of the population at a given point in time is known as a \emph{prevalence survey}.
Prevalence surveys can estimate the population prevalence but are typically very expensive to power appropriately.
Prevalence and incidence are strongly related, via the duration of an infection (see \cref{E-inc-prev}).

% Severity does not feature in this thesis, but it is important to note that it is a key component of understanding the burden of a pandemic.\todo{maybe reword sentence}

Collecting data that {\it directly} inform inference of the quantities in this section is challenging or prohibitively expensive .
Hence, they are typically estimated from other data sources through appropriate inferential methodologies.{\color{red{refer to some papers examples:Phil O'neil, stats in medicine, 1990 on linking models to data; ; De Angelis, Presanis, 2018, Analysing Multiple Epidemic Data Sources. "Handbook of
Infectious Disease Data Analysis", Held, L., Hens, N., O'Neill, P.D. and Wallinga, J. (Eds.).
Chapman & Hall/CRC, 2019.}}}

\section{Data sources}

Data sources to inform outbreak surveillance are often observational in nature.
Therefore, they suffer from biases that can be hard to understand and quantify~\autocite{shadboltChallenges}.
These biases need to be accounted for when analysing the data.

In what follows I discuss three types of data: incidence-type, prevalence-type, and data from specific studies.
\emph{Incidence-type} and \emph{prevalence-type} data can inform estimation of incidence and transmission; however, this estimation almost always relies on prior knowledge of epidemiological and/or biological quantities.
For example, the time between infection and symptom onset. These quantities can be estimated from other studies.

\subsection{Incidence-type data}

Incidence-type data originate from observations of the consequences of an infection, \eg the development of symptoms or admission to hospital.
This type of data typically suffers from reporting biases, particularly that the proportion of infections which are detected can vary over time or within different subgroups of the population~\autocites[chapter 9]{lashModern}{shadboltChallenges}.

An example of incidence-type data is the number of cases identified through community testing, reliant on individuals presenting for a test.
However, individuals' ability and willingness to be tested varies over time, which needs to be accounted for in order to perform unbiased inference.
Unfortunately, data to estimate these changes is normally unavailable.

Data on severe disease is typically less affected by these biases.
An extreme example is the development of AIDS following infection by HIV.
Here, the disease is so severe that it is extremely unlikely for an individual to develop the disease without seeking healthcare~\autocite{evansCompleteness}.

However, severe disease can be rare in some population subgroups (\eg young, otherwise healthy individuals infected with SARS-CoV-2~\autocite{wardSero,bhopalChildren}) and the resulting sparse data 
 does not provide much information on incidence in those subgroups.
Furthermore, the delay between infection and the severe event occurring means that recent infections cannot be estimated with much precision~\autocite{swallow2022challenges}.

\subsection{Prevalence-type data}

Prevalence-type data originates from observations of the number or proportion of a population in a specific \emph{disease state} at a specific time.
For example, the number of individuals hospitalised with the disease or the proportion of the population with a marker of prior infection.
The issues associated with incidence-type data often also apply to prevalence-type data.

Prevalence surveys designed to draw random samples from the population are one source of prevalence-type data that can be unbiased.
For instance, a representative proportion of the population (or a sub-population of interest) are tested for a marker of current infection.
For many diseases, prevalence is sufficiently low that this is prohibitively expensive to power.

However, \emph{seroprevalence} surveys are more feasible.
Seroprevalence is the proportion of individuals in the population which have antibodies to the disease, indicating that the individual was previously infected~\autocite{cdcSeroprevalence}.
Many more individuals have ever been infected than are currently infected, therefore, seroprevalence surveys can be powered much more cheaply~\autocite{wuSeroprevSimulation}.
However, seroprevalence is a delayed measure because there is a lag between an individual being infected and them developing antibodies.

\subsection{Cohort studies}

Other epidemiological and/or biological quantities are normally required to estimate transmission.
These depend on the model type, often including the duration of different disease states or the distribution of the time between infection events~\autocite{wallingaGI,dankwaStructural}.
Cohort studies (following a group of individuals over time), are a study design which can estimate many of these quantities.

Well-designed cohort studies can provide direct estimates of incidence and/or prevalence in the cohort~\autocite[chapter 7]{lashModern}.
However, recruiting a representative sample of the population is challenging, and the results of these studies are often not generalisable to the whole population.
Furthermore, these studies often require a large cohort to be appropriately powered.
Large cohort studies are expensive to run.

\section{Infection models}

The first component required to estimate incidence and transmission is a model of the infection process, a mathematical description of the process through which incidence arises.
A spectrum of models exists, categorised by the strength of assumptions they make about the transmission process~\autocite{beckerCOVIDmodels}.
Stronger assumptions allow more insight into the transmission process and lower the variance of the estimates but can introduce bias and be computationally challenging to fit.

The models with the weakest assumptions are \emph{phenomenological} models.
These make almost no assumptions about the transmission process, viewing incidence as a generic counting process (introduced in full in \cref{E-inc-prev:sec:infection-process}).
The most common model is that incidence follows a Poisson process, and the intensity of the process is the target of inference.
% The use of Poisson processes to model incidence of an infectious disease was very popular in the context of HIV/AIDS\todo{maybe a ref for Poisson in HIV/AIDS?}.

Next, are semi-mechanistic models.
These have components of the transmission process in them but do not fully represent the process.
A common type of semi-mechanistic model is those based on a \emph{renewal equation}~\autocite{bhattSemimechanistic}.
The renewal equation for an infectious disease~\autocite{fraserRenewal}, in the most general form, is:
\begin{align}
    Z(t) &= \int_{0}^{t} \beta(t,\tau) Z(t-\tau) d \tau
    \label{intro:eq:renewal}
\end{align}
where $Z(t)$ is the mean incidence at time $t$ and $\beta(t, \tau)$ is the mean rate at which an individual infected $\tau$ time units ago infects individuals at calendar time $t$.
Therefore, the renewal equation relates incidence in the past to incidence in the future.
This partially describes the transmission process, hence the name semi-mechanistic.
The effective reproduction number is $\Re = \int_0^\infty \beta(t, \tau) d\tau$.
% A scaled measure of $I(t)$ (\eg hospital admissions or community test results) allows estimating $\beta$.
% The most common implementations are the R packages EpiNow2~\autocite{EpiNow2} and EpiEstim~\autocite{EpiEstim}.
Extensions of \cref{intro:eq:renewal} that track the number of susceptible individuals become full mechanistic models, equivalent to the compartmental models introduced next~\autocite{champredonEquivalence}.
Renewal equations do not feature further in this thesis; for further details, including practical considerations when using them as the basis for inference, see \textcite{nashEstimating,gosticPractical}.

Finally, mechanistic models are the most complex models, representing the transmission process in varying levels of detail.
\emph{Compartmental} models, the most common type of mechanistic model, split the population into compartments, each representing a different state of the disease.
The \emph{dynamics} of the epidemic, how it changes over time, are represented by the transitions between compartments (for more details see \cref{E-SEIR:sec:mechanistic-models}).
Simple mechanistic models use a homogeneous population, with individuals differing only due to their disease state, and exponential distributions for the time in each disease state.
More complex models relax these assumptions, in particular to incorporate heterogeneity.
The age structure of the population is important for respiratory diseases because individuals meet individuals of their own age more frequently.
% Mathematically, the dynamics are described by ODEs (ordinary differential equations) or SDEs (stochastic differential equations).
% Unlike renewal equations, there are not widely-used implementations of compartmental models.
% A commonly used frameork is the SEIR (susceptible, exposed, infectious, recovered) model.
% The SEIR model, has four components (susceptible, exposed, infectious, recovered), with the population divided into these components; it is described in detail in \cref{E-SEIR:sec:mechanistic-models}.

\section{Disease models} \label{intro:sec:disease-model}

\emph{Disease models} link the transmission model to a latent quantity, $W_t$.
$W_t$ will then be recorded through some system (\eg a testing programme) described by the observation model (see next section).
For example, $W_t$ could be the incidence or prevalence of symptomatic individuals on day $t$.

At the core of many observation models is a \emph{convolution equation} or an approximation of it~\autocite[e.g.][]{brookmeyerBackcalculation,abbottEstimating,birrellRealtimea}.
This equation describes the expectation of $W_t$, conditional on the incidence prior to time $t$.
In discrete time, it is:
\begin{align}
    \E(W_t \mid Z_1, Z_2, \dots) &= \zeta \sum_{i=0}^\infty Z_{t-i} f(i)
    \label{intro:eq:disease-model}
\end{align}
where $Z_t$ is the incidence at time $t$; $\zeta$ is the proportion of infections that ever appear in $W_t$; and $f(i)$ is the probability that an infection at time $t-i$ is included in count $W_t$, conditional on it ever being in one of the counts.
$f$ is known as a \emph{delay function}.
$f$ is commonly the pdf of a distribution, or a transformation of it.

Solving \cref{intro:eq:disease-model} for $Z$ is an ill-posed problem.
The forwards error of the solution is large when $\max_{i > 0} f(i) / f(0)$~\autocite[chapter 8.2]{highamAccuracy}.
A large forwards error means that the computed value is far from the true solution~\autocite[6--9]{highamAccuracy}; this is avoided by either using an approach which gives a large $f(0)$ or smoothing $Z_t$.

\section{Observation models}

Observation models link $W_t$ to a possibly biased and/or noisy observation of it at time $t$.

Biases can arise in a variety of ways, \eg healthcare-seeking behaviour or tests which are less than 100\% accurate.
Bias can be modelled through additional parameters or data quantifying these issues~\autocite[e.g.][]{sherrattExploring,birrellRealtimea,nicholsonImproving,swallow2022challenges}.

Noise could come from a variety of sources, \eg sampling error, clustering, or unexplained overdispersion.
Noise is typically modelled by a parametric distribution \eg the negative binomial distribution allowing for overdispersion compared to a Poisson process assumption~\autocite[e.g.][]{birrellRealtimea,frassoBayesian}.

\section{Delay functions}

Applying \cref{intro:eq:disease-model} requires the delay function, $f$.
Typically, this is either the time until an event or the duration of a disease stage.
Time series data on $W_t$ cannot normally identify $f$, instead external information needs incorporating~\autocite{swallow2022challenges}.

Two approaches are commonly used to estimate the duration of a disease stage: either modelling an underlying biomarker or modelling the duration directly~\autocite[e.g.][]{sweetingEstimating}.
Modelling a biomarker uses more information per observation but requires stronger assumptions.

The biomarker approach models the trajectory of a biomarker over time in a cohort of individuals.
An individual is in the disease state while the biomarker is above or below some threshold.
This approach often requires parametric assumption(s) such as a functional form of the biomarker's trajectory.
In addition, if individual-level variation is included, which is generally important, a distributional form of random effects is required.
This requires both sufficient observations of the biomarker per individual and an assumption on the form of the distribution.
More details are in \cref{E-ATACCC}.

Modelling the duration directly considers only the binary result at each test (positive or negative), for instance in a \emph{survival analysis} framework.
This approach generally requires fewer parameters reducing the computational burden.
It is also easier to specify non-parametric forms of the distribution, which is important for SARS-CoV-2 as the tail behaviour may be important.
% A more detailed review of the literature is in the relevant chapters.
% Survival analysis is the area of statistics concerned with estimating the distribution of the times between two events.
% Other related approaches, such as a multi-state model (reviewed by \textcite{jacksonMSM}), could also be considered; multi-state models can be viewed as a generalisation of survival analysis.
More details are in \cref{E-perf-test}.

Both cases require longitudinal data, suggesting that cohort studies are the most appropriate study design.

\section{SARS-CoV-2 in England}

The surveillance systems used in response to SARS-CoV-2 are historically unique.
Modern technology allowed large amounts of data to be collected, distributed, and analysed.
While the HIV/AIDS pandemic inspired the development of a large amount of statistical methodology, it was far slower moving.
Much analysis of SARS-CoV-2 data was done at great haste, requiring trade-offs to be made between timeliness and rigour of results presented.

A deep understanding of each data source's potential was not possible in real-time.
In this thesis, I will investigate the potential of the prevalence surveys in greater detail.
The disease model will be a prevalence model (defined further in \cref{E-inc-prev:sec:prevalence-process}) with the delay function being the duration of PCR positivity.

\subsection{Data sources} \label{intro:sec:data-for-estimating}

The main data sources informing the response to the SARS-Cov-2 epidemic in England were based on: community testing (known as pillar 2 testing), the number of severe events, seroprevalence surveys, and prevalence surveys.
Each of these data sources have strengths and weaknesses, see \textcite{royalSocietyRnumber} and references therein for further details on each of these data sources.

\subsubsection{Incidence-type data}

For large parts of the pandemic, community testing was widely available in the UK.
However, it did not test a representative sample of the population.
The number of tests conducted varied over time and space, for a variety of known and unknown reasons.
These include: the policy on who is eligible for testing, the availability of tests, and the willingness of individuals to be tested.
Therefore, fluctuations in the number of positive tests may not reflect changes in the true incidence of the disease.
The large number of tests conducted allowed detailed analyses to be performed, including stratification by small geographic areas or age groups, although this does not solve the issue of the biases present.

Severe events counts are generally a more reliable measure of the burden of the disease.
The criteria for being a severe event are normally well-defined and generally well-recorded in the UK context.
Therefore, these data are subject to fewer biases than community testing.
However, SARS-CoV-2 rarely leads to severe events in younger individuals, meaning severe event counts are insensitive to changes in transmission only affecting younger individuals.

\subsubsection{Prevalence-type data}

Seroprevalence surveys were conducted throughout the epidemic, the largest of which was tested donated blood~\autocite{amirthalingamSeroprevalence}.
In addition to the normal problem of the delay between infection and antibody response, blood donors are a convenience sample whose representativeness of the wider population is unclear.

The extraordinary impact of SARS-CoV-2 led the UK Government to fund two large prevalence surveys in representative samples of the general population.
These were designed to avoid the biases of community testing and observe the whole population.
Therefore, some modelling is required to borrow information across strata or time to provide stable estimates, as well as to correct for non-response bias (see \cref{E-intro:sec:cis}).
Despite this, they are considered the gold-standard metric.

The use of prevalence surveys for estimating incidence and transmission is the focus of this thesis.
These surveys use RT-PCR (reverse transcription polymerase chain reaction, described in detail in \cref{E-biology-data:sec:PCR}) testing to detect the presence of the virus in a swab from an individual.
I focus on the CIS (Coronavirus (COVID-19) Infection Survey), run by the ONS (Office for National Statistics)~\autocite{CIS,cisMethodsONS}.
The CIS was a longitudinal study, testing a large number of individuals weekly or monthly for SARS-CoV-2; it is described in detail in \cref{E-intro:sec:cis}.

A second prevalence survey ran in the UK, known as REACT (REal-time Assessment of Community Transmission)~\autocite{rileyResurgence,rileyREACT}.
REACT was a series of cross-sectional surveys, run across 19 rounds between May 2020 and March 2022.
Each round consisted of at least \numprint{100000} randomly sampled individuals from the UK contributing swabs for testing and questionnaire data~\autocite{elliottTwin}.

A major advantage of the CIS over REACT is that the CIS had continual data collection, while REACT has no test results between rounds.
The lack of data between rounds meant that using REACT data to infer transmission in these periods requires strong model assumptions.
A particular instance of this is that a peak in late December 2020 occurred between rounds of the REACT survey, complicating analysis of the survey data at that time~\autocite{rileyREACTround8}.

\subsubsection{Cohort studies}

Many cohort studies, to estimate a wide variety of quantities, ran throughout the pandemic.
In this thesis, I make use of two cohort studies with differing designs to estimate the duration of PCR positivity.
These designs have complementary strengths, and I combine information from the studies.
Both of the studies recruited individuals from the general population, aiming to observe a cohort of infections that are representative of the infections in the UK community.

% In addition to population-level surveillance, cohort studies help understand other aspects of the pathogen~\autocite{royalSocietyRnumber}.
% For example, contact tracing data can inform how likely it is for transmission to occur in different settings and/or between different groups of people.
The first study I used, ATACCC (Assessment of Transmission and Contagiousness of COVID-19 in Contacts)~\autocite{singanayagamCommunity,hakkiOnset}, performed daily testing of a small number of individuals with short follow-up.
The density of this sampling allows for reliable estimates of the viral load dynamics and other quantities of interest, most importantly the duration of detectability, but the results are limited because the small sample size and short follow-up prohibit estimation of the tails of these distributions.
I describe ATACCC in detail in \cref{E-biology-data:sec:ataccc} and use it to estimate duration in \cref{E-ATACCC}.

The second study is the CIS (introduced in \cref{intro:sec:data-for-estimating}).
In addition to its role as a prevalence survey, the CIS followed the same individuals over a long period of time (over a year in many cases), collecting longitudinal data.
The large sample size and long follow-up allows estimation of the tails of the distribution of the duration of positivity.
However, the lack of frequent testing (at most weekly) prohibits estimation of the viral load dynamics.
In particular, the vast majority of detected infections had only one or two positive tests, and hence the viral load trajectory of these infections cannot be estimated.
I describe the CIS in detail in \cref{E-intro:sec:cis} and use it to estimate duration in \cref{E-perf-test,E-imperf-test}.

Early on in the epidemic, incidence could be estimated directly from the longitudinal survey data by considering the proportion of the cohort that tested negative then positive at consecutive tests~\autocite{onsIncidenceOld}.
However, the method was abandoned in autumn 2020 when the testing was too infrequent to ensure that all infections were captured (\ie tested positive at least once).

\subsection{Models}

Members of SPI-M-O (the Scientific Pandemic Influenza Group on Modelling, Operational sub-group) produced the most prominent modelling of the UK epidemic.
SPI-M-O was a sub-committee of SAGE (the Scientific Advisory Group for Emergencies), generating evidence based on infectious disease modelling for policy development~\autocite{medleySPIM,govSPIMO}.
This used a wide range of  modelling approaches depending on the data available, which fluctuated throughout the epidemic, and the question being addressed.
Some were fit to data while others were purely used for simulation based on plausible parameter values.

Each week, members of SPI-M-O would produce a set of estimates of the current state of the epidemic (\eg the value of $\Re$), known as \emph{nowcasting}.
The committee peer-reviewed these estimates to provide quality assurance, removing any estimates unduly affected by issues (\eg data quality issues).
They then formed a consensus value using a statistical combination of the estimates~\autocite{parkCombining}.
The consensus value was published on the UK Government's website and informed its response to the epidemic~\autocite{govRnumber}.

The nowcasting estimates were based on mechanistic and semi-mechanistic models with a wide variety of data sources.
The mechanistic models commonly incorporated multiple data sources, known as \emph{data synthesis}, a technique reviewed by \textcite{birrellEvidence}.
The models used were reviewed by \textcite{royalSocietyRnumber} (see appendix 2 of that review for details of the specific implementations).

Additionally, these models were used to explore policy scenarios.
For example, the decision at each of stage of lifting the lockdown in 2021 was informed by modelling studies~\autocite{sageEvidence}.
These aided decision-makers in understanding plausible impacts of their actions.

\section{Thesis context}

In this thesis, I consider how prevalence surveys could be used for epidemic surveillance, in particular estimates of incidence and transmission.
These surveys have well-understood designs which means that estimates derived from them are more robust.
A crucial quantity in their use will be the distribution of the duration of RT-PCR positivity.

In the following subsection, I introduce the most relevant related work, from both prior to the pandemic and during its course.

\subsection{Backcalculation}

\emph{Backcalculation} is a modelling framework developed in the context of HIV/AIDS~\autocite{brookmeyerMethod} but applied very broadly.
It specifies a particular combination of infection, disease, and observation model which relate times of HIV infection with times of AIDS diagnosis via the incubation period.
Further details are in the recent review \textcite{sunModeling}.
The theory behind the framework underpins much of the work in this thesis.

The original formulations~\autocite{brookmeyerMethod,rosenbergBackcalculation} used a Poisson process as the infection model; a disease model where all infections are eventually observed ($\zeta = 1$) and the delay function, $f$, is the incubation period distribution's pdf; and an observation model where all diagnoses are observed, and hence has no influence on the data.

The disease and observation models must be adapted to apply backcalculation to SARS-CoV-2 prevalence surveys (see \cref{E-inc-prev}).
The disease model must consider that this is now prevalence-type, rather than incidence-type data.
This difference induces a dependency structure between the observations on each day.
The observation model must now include the with error arising from using a sample of the population rather than (assumed) full recording of AIDS diagnoses.

\subsection{Existing duration estimates} \label{intro:sec:previous-duration-estimates}

An early meta-analysis estimated that individuals test positive for SARS-CoV-2 for a mean of 14.6 days (95\% CI: 9.3--20.0 days)~\autocite{cevikShedding}.
The longest reported duration was observed at 83 days, although beyond day 9 no live virus was detected, indicating that the individuals testing positive for longer than this were not infectious.
However, most studies included in the meta-analysis involved hospitalised patients or had unclear inclusion criteria, and hence may not be representative of the general population.
These summary estimates are insufficient for backcalculation, which requires a distribution of the duration of positivity.

\Textcite{hellewellPCRSensitivity} estimated the probability of an individual testing positive each day after infection.
This measure is highly related to the duration of positivity.
However, the study's cohort consisted only of healthcare workers, \ie working-age adults.

\Textcite{binnySensitivity} applied a slight variant of \textcite{hellewellPCRSensitivity}'s methodology to data from New Zealand.
The situation in New Zealand, who were successfully pursuing a zero-COVID strategy at this time, means that the individuals in the study were unusual.
For example, a third were travellers detected during their quarantine period on arrival to New Zealand but would have had negative RT-PCR tests before their departure.

\Textcite{ealesCharacterising} estimated the duration of positivity from REACT data.
Specifically, individuals who tested positive in round 8 of REACT (6th--22 Jan 2021) were invited to take two additional swab tests.
Defining the time of the initial positive test at time 0, \textcite{ealesCharacterising} estimated the probability of remaining positive at each day after the initial positive test.
They made a strong parametric assumption that the probability decreases exponentially, with a sensitivity analysis assuming a plateau before the decay.
This assumption is necessary because they had at most 17 days of follow-up, and hence could not estimate the tail of the distribution.
Overall, they estimate a median duration of 14.0 days (95\% CI: 12.9--15.4 days) with substantial positive correlation with each individual’s viral load at the time of the initial positive test (\ie a higher initial viral load was associated with a longer duration of positivity).
The individuals with the highest viral load individuals were estimated to have a median duration of 19.6 days (16.1--25.8 days).
The association could be due to individuals with a higher initial viral load being (on average) more recently infected at the time of the initial positive test.
The study design prohibits estimating how long before the initial positive test the infection occurred.
The same issue means the study underestimates the duration of positivity.

For the purposes of this thesis, I require estimates applicable to the general population.
There are no reliable estimates of the full distribution of the duration of positivity in a general population cohort available in the literature.
Therefore, I estimate the duration of positivity from the ATACCC and CIS studies.


\subsection{Existing estimation from prevalence surveys}

Several previous studies have used SARS-CoV-2 prevalence surveys to estimate incidence and/or transmission.

\Textcite{abbottCISincidence} applied backcalculation to CIS data to estimate the incidence of SARS-CoV-2 in the UK.
They used a Gaussian process prior to smooth the incidence and stabilise the estimates.
\Textcite{abbottCISincidence} used \textcite{hellewellPCRSensitivity}'s estimates of the sensitivity of testing to inform the observation model, which are based on a longitudinal study in healthcare workers (see \cref{intro:sec:previous-duration-estimates}).
They fit to summary statistics of the CIS data, using a daily, independent normal likelihood with parameters estimated from the posterior point estimate and 95\% credible interval published by the ONS.

\Textcite{colmanAscertainment} used CIS prevalence estimates to estimate the \emph{ascertainment rate} of community testing (the proportion of all infections that community testing detected).
Their methodology was similar to \textcite{abbottCISincidence}, including using estimates from \textcite{hellewellPCRSensitivity} for how the sensitivity of RT-PCR testing varies over an infection.
Rather than using a Gaussian process to provide stability, as \textcite{abbottCISincidence} do, \textcite{colmanAscertainment} assume the ascertainment rate is piecewise constant.
They do not fully propagate the uncertainty from the CIS prevalence estimates, considering only the bounds of the 95\% confidence intervals the ONS publishes for prevalence.

Several compartmental models incorporated data from SARS-CoV-2 prevalence surveys, alongside other data sources~\autocite{daviesAssociation,ironsEstimating,knockKey,nicholsonImproving,pooleyEstimation,birrellRTM2}.
% These models incorporate prevalence survey data by adding additional compartments representing RT-PCR positive individuals, who may not be infectious (this is common, see \cref{E-biology-data}); except \textcite{nicholsonImproving} who have a more sophisticated approach (below) and \textcite{ironsEstimating}, who assume RT-PCR positivity coincides with infectiousness.
% The length of stay in these compartments (the duration of time positive) is assumed to follow a gamma distribution, with the parameters estimated from external data or having at most one free parameter.
Their model structure limits the form of the duration of positivity. 
They fit the models to prevalence survey data using a binomial likelihood where possible, although some approaches take a normal approximation.
% These approaches are similar to how these models are fit to other data sources, such as hospital admissions or deaths.

\Textcite{nicholsonImproving} fit a simple mechanistic model, notably without age structure, but have the most sophisticated observation model.
They allow an arbitrary distribution of the duration of positivity, based on the estimates of \textcite{hellewellPCRSensitivity} (see \cref{intro:sec:previous-duration-estimates} for discussion of the \textcite{hellewellPCRSensitivity} study).
Furthermore, they incorporate the sensitivity and specificity of the RT-PCR test into their model.

\Textcite{mccabeCISincidence}, adapting the methodology \textcite{ealesAppropriately} developed for REACT, estimate $\Re$ and the growth rate from the CIS data.
They estimate a posterior distribution of the parameters of a spline by fitting to the prevalence results via a binomial distribution.
Their set-up penalizes the spline deviating from a constant growth rate.
They calculate the growth rate from the derivative of the spline, an analytical transformation of the parameters. 
Since, under reasonable model assumptions, there is a one-to-one correspondence between reproduction numbers and growth rates~\autocite{wallingaGI}, and they assume that the growth rate in incidence and prevalence is equal, this also estimates $\Re$.

\section{Bayesian inference} \label{intro:sec:Bayes}

All inference in this thesis is Bayesian.
Including prior information allows identifiability in situations where this would not otherwise be possible and allows for combining knowledge from multiple sources.
Many previous studies I build on used Bayesian inference.

Analytically deriving the posterior distribution is impossible for the models in this thesis.
Therefore, I use computational methods to sample from the posterior distribution.
The method I use for the majority of the analyses is MCMC (Markov chain Monte Carlo) (see \cref{E-MCMC} for details).

\section{Thesis aims and contribution} \label{intro:sec:aims}

The overall question that I investigate in this thesis is: can prevalence surveys alone be used to infer incidence and transmission, and if so how?
Prevalence surveys provide data that is far more representative of the general population than other data sources, therefore, conclusions based on them should be far more robust.
There are two components to this question.
First, how can prevalence surveys be designed to help estimate these quantities?
Second, what statistical methodology can be used to estimate these quantities from prevalence surveys?
This thesis will focus on the second component.
However, natural extensions of the work I undertake would inform the first component.

In order to achieve these aims, I use a case study, specifically the SARS-CoV-2 epidemic in England from Mon 31 Aug 2020 until Sun 25 Jan 2021.
This case study has several features that make it useful for the aims of this thesis.
These include that the CIS was of sufficient size and incidence sufficiently high that there is enough data to perform the analyses.
Additionally, incidence begins rising over this period, which is the period when a surveillance system needs to provide a warning of upcoming issues.
The CIS began in April 2020, when incidence was falling due to the first lockdown in the UK.
Incidence remained low and fairly flat in England over summer 2020, until it began rising in mid or late August.
Finally, the period ends before the roll-out of the vaccine, which likely affects many important aspects of the analysis.
In particular, the duration of positivity and the susceptibility of the population.
Including both of these elements would require more complex modelling and including idiosyncratic features of the SARS-CoV-2 pandemic that are less generalisable to other diseases.

A secondary aim of this thesis is to improve our understanding of the epidemic in England over this period, and our understanding of the SARS-CoV-2 virus more broadly.
The results of the analyses I perform in pursuit of the primary aim will naturally contribute to this aim.

\subsection{Methodological contributions}

As its primary aim, this thesis makes several methodological contributions.

First, in \cref{E-inc-prev:sec:observation-process}, I provide a theoretic justification for the use of deterministic backcalculation in this setting.
A \emph{deterministic} backcalculation approach was used by \textcite{abbottCISincidence} and I will use it in \cref{E-backcalc}.
The deterministic approach models the prevalence at any time as a deterministic function of the incidence, rather than as a random variable.
I show that this is a good approximation as long as the proportion of the population sampled is small.
In particular, it does not require the prevalence or incidence to be large.
The estimates I produce in \cref{E-backcalc} fully propagate the uncertainty from the prevalence estimation procedure and use estimates of the duration of positivity from a general population study, unlike prior work.

In \cref{E-perf-test} I estimate the duration of RT-PCR-positivity from double censored data with arbitrary periods where infections could be undetected (a generalisation of truncation).
This is based on the CIS data.
While statistical frameworks have been previously developed which included this case, they had not been used in practice.
In \cref{E-imperf-test}, I extend this framework to include false negatives.

A particular challenge with these analyses is that they must be performed within a trusted research environment with limited computational resources.

Within these analyses, I include information derived from the ATACCC study.
In order to do so, I propose a prior which appropriately discounts the information from analysing the ATACCC study, which has inappropriate model assumptions when applied to the larger sample size in the CIS data.


Finally, in \cref{E-SEIR}, I describe a compartmental model for SARS-CoV-2 transmission, which I fit to CIS data.
I allow a more flexible distribution of the duration of positivity than any of the papers discussed above, except \textcite{nicholsonImproving}, incorporating the skew of the distribution.
This distribution is based on data from a representative sample of the UK population, rather than convenience samples (see \cref{intro:sec:previous-duration-estimates}).
Unlike \textcite{nicholsonImproving}, I include age-stratification in the transmission model, allowing estimation of how transmission varies by age.
I use only data from the CIS and show this is sufficient for estimating incidence and transmission.

\subsection{Epidemiological contributions}

The secondary aim of this thesis is providing new estimates to improve our understanding of SARS-CoV-2 in general, and the epidemic in England over the period I study.

In \cref{E-imperf-test}, I present estimates of the duration of RT-PCR-positivity in the general population.
These estimates could inform public health policy, for example, in interpreting RT-PCR test results or formulating quarantine policies.

In \cref{E-transmission}, I present estimates of the incidence and transmission of SARS-CoV-2 in England over the period.
These estimates contribute to the literature reconstructing the SARS-CoV-2 epidemic in England.
Understanding the dynamics of the past infection is important for informing the response to future pandemics, and the future burden of SARS-CoV-2.

\subsection{Software and data availability}

In order to best fulfil this thesis's primary aim, the methodology developed should be easy for others to use.
Therefore, the code for the analyses in this thesis is available online.
An index to the code and, where possible, data are available at \url{https://github.com/joshuablake/thesis-index}.
I structured two elements of the code as R packages to enable their application to future contexts.

First, the framework to simulate the CIS (used in \cref{E-imperf-test:sec:simulate,E-perf-test:sec:simulation-study}).
The package enables customisation of various features of the study, for example the testing regime of the participants, the sensitivity of the tests, and the duration of positivity.
This package would be particularly useful in answering questions regarding the design of future prevalence surveys, for example, how frequently individuals should be tested, or how many individuals should be tested.

Second, the survival analysis framework used to infer the duration of positivity in \cref{E-perf-test,E-imperf-test}.
The framework allows the user to specify all the different analyses performed in these chapters in a simple interface. 
Furthermore, adding new analyses, for example varying the priors or the inclusion of covariates, is straightforward.

Where possible, aggregated, non-disclosive versions of the datasets are available alongside the code.
The original ATACCC data used is available alongside the code.
The original CIS data can only be accessed by accredited researchers within the ONS's SRS (Secure Research Service); see \url{https://www.ons.gov.uk/aboutus/whatwedo/statistics/requestingstatistics/secureresearchservice} for details.

Almost all code, excluding dependencies, was written from scratch for these analyses.
The exceptions are the Markov chain Monte Carlo sampler used in \cref{E-SEIR}, the model for prevlaence used in \cref{E-backcalc}, and the original viral load model used in \cref{ATACCC:sec:hakki}.

\subsection{Structure}

In \cref{E-biology-data}, I provide background information on the natural history of SARS-CoV-2, the RT-PCR testing process used to produce the data used throughout this thesis, and describe the two cohort studies used in this thesis.
Then, in \cref{E-inc-prev}, I formally describe the stochastic processes which generate infections, prevalence, and the observations of prevalence.
A key insight in this chapter is that the distribution of the duration of positivity is the key quantity linking incidence and prevalence.

I then turn to estimating this distribution.
I start, in \cref{E-ATACCC}, by estimating the duration of positivity from the ATACCC study.
This provides a reliable estimate of the bulk of the distribution (out to around 20 days) but shows that there is a significant tail.
Estimating the tail requires a large sample size and long follow-up. 
Therefore, I turn to the CIS data in \cref{E-perf-test,E-imperf-test}.
In \cref{E-perf-test}, I provide a framework for estimating the duration of positivity from the CIS data, assuming perfect tests.
However, the assumption of perfect tests is not realistic; in \cref{E-imperf-test}, I extend the framework to include false negatives.

Having estimated the duration of positivity, next I estimate incidence and transmission from the CIS data in \cref{E-transmission}, thus fulfilling the primary aim of this thesis.
I use both a phenomenological and mechanistic transmission model, contrasting their results and discussing the advantages and disadvantages of each in this context.
Finally, I conclude in \cref{E-conclusion}.

\Cref{E-distributions} provides definitions of the probability distributions used in this thesis.
Other appendices provide additional details.

\ifSubfilesClassLoaded{
  \appendix
%   \subfile{MCMC-appendix}
  \listoftodos
}{}
\end{document}