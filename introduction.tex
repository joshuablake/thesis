\documentclass[thesis.tex]{subfiles}

\begin{document}

\chapter{Introduction} \label{intro}

Infection with the SARS-CoV-2 virus is estimated to have killed approximately 15 million in the most acute phase (to the end of 2021) and 30 million in total~\autocite{whoCOVIDExcess,economistCOVIDExcess}.
Beyond the lives lost, there were massive health, economic, and societal costs.

History suggests severe pandemics are not rare (see \cref{intro:fig:pandemic-timeline}).
\begin{figure}
    \includegraphics[width=\textwidth]{introduction/pandemic-timeline}
    \caption[Timeline of pandemics.]{%
        Timeline of pandemics.
        See \url{https://ourworldindata.org/historical-pandemics} for details and sources.
        Licensed under \href{https://creativecommons.org/licenses/by/4.0/}{CC-BY} by Saloni Dattani, Klara Auerbach, Marwa Boukarim, and Max Roser.
    }
    \label{intro:fig:pandemic-timeline}
\end{figure}
Fully quantifying the burden of historical pandemics is challenging due to the absence of systematic records.
However, our best records suggests that, since 1600, they have, on average, occurred every four years with a mean death toll of 5.6 million~\autocite{maraniNovelEpidemics}.
Recent estimates suggest that the current impact of pandemics is, on average, over 2.5 million deaths per year~\autocite{madhavPandemicMortality}.

All pandemics start as an \emph{outbreak}, a sudden and unexpected rise in the number of people with a disease in a local area; if this spreads over a larger geographic area (\eg a country) it becomes an \emph{epidemic}; if it spreads globally then it is a \emph{pandemic}~\autocite{grennanPandemic}.
The precise meaning of these terms varies; they are defined implicitly by their usage rather than formal definitions~\autocite{morensPandemic,doshiElusive}.
I will refer to the SARS-CoV-2 epidemic within England (or the UK), and the global impact as the pandemic.

In this context, \emph{surveillance} is the ability to detect and monitor the spread of an outbreak.
Surveillance is important at every stage: early on, for detecting a new outbreak quickly and assessing its likely impact and later for monitoring the ongoing burden of the disease and the effectiveness of interventions~\autocite{whoFluSurveillance}.
In all cases, surveillance informs public health policy.
In this thesis, I consider methods to improve surveillance, using the SARS-CoV-2 epidemic in England as a case study.

\section{Surveillance metrics} \label{intro:sec:metrics}

No single metric summarises the full state of an epidemic, and no single data source fully informs all metrics of interest~\autocite{royalSocietyRnumber,pellisEstimation,paragGrowthRates}.
Therefore, a range of metrics and surveillance systems are required to understand the state of an epidemic and the risk it poses.

\subsection{Growth of an epidemic}

Various forms of \emph{reproduction number} were prominent throughout the SARS-CoV-2 pandemic~\autocite{pellisEstimation}.
Broadly, a reproduction number describes the number of secondary infections generated by a single infection.
Here, following \textcite{pellisEstimation}, and building on over a century of infectious disease dynamics literature, I define three below.

The most common reproduction number is the \emph{basic reproduction number}, $\R$.
$\R$ is the mean number of secondary infections generated by a single infection in a \emph{fully susceptible} population with \emph{standard behaviour patterns}.
A fully susceptible population means that none of its members have any immunity to the disease.
Note that this definition implies $\R$ is constant for a given pathogen and population.
In the early stages of an epidemic caused by a novel pathogen, the number of individuals with immunity is negligible, and hence $\R$ describes this part of the epidemic well.
$\R$ has a threshold value of 1: an outbreak has the potential to cause an epidemic if and only if $\R > 1$~\autocite[76]{diekmannMathematical}.

The \emph{effective reproduction number}, $\Re$, is the mean number of secondary infections generated by a single infection at time $t$.
In particular, it includes the effects of the behaviour and immunity status of the population at time $t$.
With constant behaviour and a disease that grants immunity following infection, $\Re$ declines smoothly.
$\Re$ describes the current dynamics of the epidemic: $\Re > 1$ means the epidemic is growing, $\Re < 1$ means it is shrinking, and $\Re = 1$ means it is stable.
In simple epidemic models (see \cref{E-SEIR:sec:SIR}), $\Re$ is proportional to the product of the rate of contacts, the probability of transmission upon contact, and the proportion of the population that is susceptible.
Interventions act by reducing one of these components \eg masks reduce the probability of transmission and vaccination reduce the susceptible population.
Therefore, $\Re$ informs the strength of intervention required to control the epidemic.

The \emph{control reproduction number}, $\Rc$, is the mean number of secondary infections that would be generated by a single infection at time $t$ if in a fully susceptible population.
$\Rc$ is also known as the \emph{reproduction number excluding immunity}.
It describes the effect on the epidemic of interventions (except vaccination) that are in place at time $t$.
$\Rc$ is useful when comparing the effects of interventions at different points in time, when the immunity status of the population has changed.

% To see the differing uses of the reproduction numbers, consider the difference in the epidemic in England in March 2020, just following the start of the first lockdown, and in January 2021 just following the start of the third lockdown.
% These times have (at least) three epidemiologically relevant differences: (1) in January 2021 the Alpha variant was circulating which is more transmissible than the original variant present in March 2020; (2) the population behaved differently because the exact meaning of ``lockdown'' differed and attitudes had changed; (3) in January 2021, some individuals had immunity due to either prior infection or the start of the vaccination roll-out.
% The original and Alpha variants have different values for $\R$, isolating effect 1.
% $\Rc$ differs during the two periods, including effects 1 and 2.
% $\Re$ includes all these effects, as well as any others.

% These definitions ignore many complexities that arise when theoretically defining or practically estimating any of the reproduction numbers~\autocite{pellisEstimation}.
% For example, how to average across seasonal effects and a heterogeneous population, and the lack of a ground truth for these numbers in almost all situations.
% However, their intuitive simplicity and convenient properties in simple epidemic models mean that they are useful concepts for guiding policy.

Reproduction numbers are strongly connected to \emph{growth rates}.
If changes in behaviour and susceptibility are negligible, as they often are over short periods of time, epidemics grow (or shrink) exponentially, with a growth rate $r$.
For a given disease and population, a growth rate can be defined corresponding to each definition of the reproduction number~\autocite{pellisEstimation,paragGrowthRates,wallingaGI}.
The advantages of using the growth rates are that they are easier to estimate and capture how quickly spread happens in calendar time; however, they do not directly give the strength of intervention required to control the epidemic~\autocite{royalSocietyRnumber}.

\subsection{Size of an epidemic}

Growth rates and reproduction numbers only provide information on how an epidemic is changing.
The size of the epidemic is just as, if not more, important~\autocite{pellisEstimation}.

\emph{Incidence} is the number of new infections in a given time period (see \cref{E-inc-prev:sec:definitions} for a formal definition).
It is the primary metric for the magnitude of a pandemic.
Incidence informs the short-term future burden of the disease, for example, the future number of severe events (hospitalisations or deaths) through a severity measure, such as the infection fatality rate, the proportion of infected individuals who die.

\emph{Transmission} refers to the process by which an infectious individual generates further infections.
Estimating transmission refers to inferring this process.
Understanding this process, \eg the number of contacts each individual makes per day, allows targeting interventions and forecasting future incidence.

\emph{Prevalence} is the proportion of the population with the disease at a given time (see \cref{E-inc-prev:sec:definitions} for a formal definition).
Whether a given individual is \emph{prevalent}, \ie has the disease, is often measurable through diagnostic testing.
Prevalence and incidence are strongly related, via the duration of an infection (see \cref{E-inc-prev}).

% Severity does not feature in this thesis, but it is important to note that it is a key component of understanding the burden of a pandemic.\todo{maybe reword sentence}

Collecting data that \emph{directly} inform inference of the quantities in this section is challenging or prohibitively expensive.
Hence, they are typically estimated from other data sources through appropriate statistical methods~\autocite{heldHandbook,oneillIntroduction}.

\section{Data sources}

Data sources to inform outbreak surveillance are often observational in nature, \ie they are not the output of designed studies.
Therefore, they suffer from biases that can be hard to understand and quantify~\autocite{shadboltChallenges}.
These biases need to be accounted for when analysing the data.

In what follows, I discuss three types of data: incidence-type, prevalence-type, and data from longitudinal studies.
\emph{Incidence-type} and \emph{prevalence-type} data can inform estimation of incidence and transmission.
However, this estimation almost always relies on prior knowledge of epidemiological and/or biological quantities, typically estimated from longitudinal studies.
For example, the time between infection and symptom onset.

\subsection{Incidence-type data}

Incidence-type data originate from observations of the consequences of an infection, \eg the development of symptoms or admission to hospital.
This type of data typically suffers from reporting biases, most problematically that the proportion of infections detected varies over time or within different subgroups of the population~\autocites[chapter 9]{lashModern}{shadboltChallenges}.

An example of incidence-type data is the number of cases identified through community testing, which relies on individuals presenting for a test.
Individuals' ability and willingness to be tested varies over time, which needs to be accounted for in order to perform unbiased inference.

Data on the severe consequences of an infection are typically less affected by biases.
An extreme example is the development of AIDS following infection by HIV.
Here, the disease is so severe that it is extremely unlikely for an individual to develop the disease without seeking healthcare~\autocite{evansCompleteness}.

However, severe consequences can be rare in some population subgroups (\eg young, otherwise healthy individuals infected with SARS-CoV-2~\autocite{wardSero,bhopalChildren}), meaning they rarely appear in these data.
Therefore, the data do not provide much information on incidence in those subgroups.
Furthermore, the delay between infection and the severe event occurring means that recent infections cannot be estimated with much precision~\autocite{swallow2022challenges}.

\subsection{Prevalence-type data}

Prevalence-type data originate from observations of the number or proportion of a population in a specific \emph{disease state} at a specific time.
For example, the number of individuals in hospital with the disease or the proportion of the population with a marker of prior infection.
The same issues associated with incidence-type data often also apply to prevalence-type data.

Prevalence can be estimated through a \emph{prevalence survey}.
A prevalence survey is a designed study which performs diagnostic testing of a sample of the population; they are typically very expensive to power appropriately but can provide unbiased prevalence-type data.
An example of an unbiased prevalence survey is testing a representative proportion of the population (or a subpopulation of interest) for a marker of current infection.

\emph{Seroprevalence} surveys are more feasible.
Seroprevalence is the proportion of individuals in the population which have antibodies against a particular infection, indicating that the individual was previously infected~\autocite{cdcSeroprevalence}.
Many more individuals have ever been infected than are currently infected; therefore, seroprevalence surveys can be powered much more cheaply~\autocite{wuSeroprevSimulation}.
However, seroprevalence is a delayed measure because there is a lag between an individual being infected and them developing antibodies.

\subsection{Longitudinal studies}

Other epidemiological and/or biological quantities are normally required to estimate transmission.
These include the duration of different disease states or the distribution of the time between infection events~\autocite{wallingaGI,dankwaStructural}.
Longitudinal studies, that follow the same individuals over time, allow estimation of many of these quantities.

Well-designed cohort studies can provide direct estimates of incidence and/or prevalence in the cohort~\autocite[chapter 7]{lashModern}.
However, recruiting a representative sample of the population is challenging, and the results of these studies are often not generalisable to the whole population.
Furthermore, these studies often require a large sample size to be appropriately powered, making them expensive to run.

\section{Infection models}

The first component required to estimate incidence and transmission is a model of the infection process, a mathematical description of the process through which infections are generated.
A spectrum of models exists, categorised by the strength of assumptions they make about the transmission process~\autocite{beckerCOVIDmodels}.

The models with the weakest assumptions are \emph{phenomenological} models.
These make almost no assumptions about the transmission process, viewing incidence as resulting from a generic counting process (introduced in full in \cref{E-inc-prev:sec:infection-process}), such as a Poisson process.
% The use of Poisson processes to model incidence of an infectious disease was very popular in the context of HIV/AIDS\todo{maybe a ref for Poisson in HIV/AIDS?}.

Next, are semi-mechanistic models.
These relate incidence in the past to current (and future) incidence but do not explicitly represent the susceptible population.
A common type of semi-mechanistic models is that based on a \emph{renewal equation}~\autocite{bhattSemimechanistic,fraserRenewal}.
In discrete time, it takes the form:
\begin{align}
    \E(Z_t \mid Z_0, \dots, Z_{t-1}) &= \sum_{\tau=1}^t \beta(t,\tau) Z_{t-\tau}
    \label{intro:eq:renewal}
\end{align}
where $Z_t$ is the expected incidence at time $t$ and $\beta(t, \tau)$ is the expected rate at which an individual infected $\tau$ time units ago infects individuals at calendar time $t$.
The model parameters can be used to define an effective reproduction number as either $\Re = \sum_{\tau=0}^\infty \beta(t, \tau)$ or $\Re = \sum_{\tau=0}^\infty \beta(t+\tau, \tau)$~\autocite{gosticPractical}.
% A scaled measure of $I(t)$ (\eg hospital admissions or community test results) allows estimating $\beta$.
% The most common implementations are the R packages EpiNow2~\autocite{EpiNow2} and EpiEstim~\autocite{EpiEstim}.
Renewal equations do not feature further in this thesis; for further details, including practical considerations when using them as the basis for inference, see \textcite{thompsonImproved,gosticPractical}.

Finally, mechanistic models are the most complex models, representing the transmission process in varying levels of detail.
\emph{Compartmental} models, the most common type of mechanistic model, split the population into compartments, each representing a different state of the disease.
The \emph{dynamics} of the epidemic (how it changes over time) are represented by the transitions between compartments (for more details see \cref{E-SEIR:sec:mechanistic-models}).
Simple mechanistic models use a homogeneous population, with individuals differing only due to their disease state, and exponential distributions for the time in each disease state.
More complex models relax these assumptions, incorporating more flexible definitions and/or heterogeneity (see \cref{SEIR:sec:mechanistic-models}).
% Mathematically, the dynamics are described by ODEs (ordinary differential equations) or SDEs (stochastic differential equations).
% Unlike renewal equations, there are not widely-used implementations of compartmental models.
% A commonly used frameork is the SEIR (susceptible, exposed, infectious, recovered) model.
% The SEIR model, has four components (susceptible, exposed, infectious, recovered), with the population divided into these components; it is described in detail in \cref{E-SEIR:sec:mechanistic-models}.

\section{Disease models} \label{intro:sec:disease-model}

The infection process is hardly ever directly observed; however, we often observe a consequence of an infection.
\emph{Disease models} link the infection model to the number of these consequences, $W_t$, at time $t$.
For example, $W_t$ could be the incidence or prevalence of symptomatic individuals on day $t$.
$W_t$ will then be recorded through some system (\eg a testing programme) described by the observation model (see the next section).

At the core of many observation models is a \emph{convolution equation} or an approximation of it~\autocite[e.g.][]{brookmeyerBackcalculation,abbottEstimating,birrellBayesian}.
This equation describes the expectation of $W_t$, conditional on the incidence prior to time $t$.
In discrete time, it is:
\begin{align}
    \E(W_t \mid Z_1, Z_2, \dots) &= \zeta \sum_{i=0}^\infty Z_{t-i} f(i)
    \label{intro:eq:disease-model}
\end{align}
where $Z_t$ is the incidence at time $t$; $\zeta$ is the proportion of infections that result in the consequence of interest; and, conditional on being observed, $f(i)$ describes the (discretised) probability that an infection is included in the count $W_t$ at $i$ time units after the infection.
$f$ is an example of a \emph{delay function}, and $f$ is commonly the pdf of a distribution, or a transformation of it.

Solving \cref{intro:eq:disease-model} for $Z$ is an ill-posed problem.
The forwards error of the solution is large when $\max_{i > 0} f(i) / f(0)$~\autocite[chapter 8.2]{highamAccuracy} is large.
A large forwards error means that the computed value is far from the true solution~\autocite[6--9]{highamAccuracy}; this is avoided by either using an approach which gives a large $f(0)$ or by smoothing $Z_t$.

\section{Observation models}

Observation models link $W_t$ to a (possibly biased and/or noisy) observation of it at time $t$.

Biases can arise in a variety of ways, \eg healthcare-seeking behaviour or tests which are less than 100\% accurate.
Bias can be modelled through additional parameters or data quantifying these issues~\autocite[e.g.][]{sherrattExploring,birrellBayesian,nicholsonImproving,swallow2022challenges}.

Noise could come from a variety of sources, \eg sampling error, clustering, or unexplained overdispersion.
Noise is typically modelled by a parametric distribution \eg the negative binomial distribution allowing for overdispersion compared to a Poisson process assumption~\autocite[e.g.][]{birrellBayesian,frassoBayesian}.

\section{Delay functions}

Applying \cref{intro:eq:disease-model} requires knowledge of the delay function, $f$.
Typically, this is either the time to an event or the duration of a disease stage.
Time series data on $W_t$ cannot identify $f$, instead external information needs incorporating~\autocite{swallow2022challenges}, most commonly longitudinal studies.

Two approaches are commonly used to estimate the duration of a disease stage: either modelling an underlying biomarker or modelling the duration directly, for instance, in a \emph{survival analysis} framework~\autocite[e.g.][]{sweetingEstimating}.

The biomarker approach models the trajectory of a biomarker over time.
Applying a threshold to the biomarker defines a disease state.
This approach often requires parametric assumption(s) such as a functional form of the biomarker's trajectory.
In addition, including individual-level variation, which is generally important, requires sufficient observations of the biomarker per individual and an assumption on the form of the distribution of the variation.
More details are in \cref{E-ATACCC}.

Modelling the duration directly considers only the binary result at each test (positive or negative), using less information than a biomarker approach.
This approach generally requires fewer parameters reducing the computational burden.
It is also easier to specify non-parametric forms of the distribution, which is useful in situation where the tail behaviour may be important.
% A more detailed review of the literature is in the relevant chapters.
% Survival analysis is the area of statistics concerned with estimating the distribution of the times between two events.
% Other related approaches, such as a multi-state model (reviewed by \textcite{jacksonMSM}), could also be considered; multi-state models can be viewed as a generalisation of survival analysis.
More details are in \cref{E-perf-test}.


\section{SARS-CoV-2 in England}

The response to the SARS-CoV-2 pandemic in the UK has been unprecedented, both in terms of the scientific input to policy and the surveillance data made available.
The most prominent surveillance outputs were produced by members of SPI-M-O (the Scientific Pandemic Influenza Group on Modelling Operational sub-group), a sub-committee of SAGE (the Scientific Advisory Group for Emergencies)~\autocite{medleySPIM,govSPIMO}.
SPI-M-O produced weekly estimates of the current state of the epidemic (\eg the value of $\Re$), known as \emph{nowcasting}.
The committee peer-reviewed these estimates to provide quality assurance and formed a consensus value using a statistical combination of the estimates~\autocite{parkCombining}.
The consensus value was published on the Government's website and informed its response to the pandemic~\autocite{govRnumber}.

The nowcasting estimates were based on mechanistic and semi-mechanistic models with a wide variety of data sources.
The mechanistic models, in  particular, commonly incorporated multiple data sources.
The models used were reviewed by \textcite{royalSocietyRnumber} (see appendix 2 of that review for details of the specific implementations).

Additionally, these models were used to explore policy scenarios.
For example, the decision at each of stage of lifting the lockdown in 2021 was informed by modelling studies~\autocite{sageEvidence}.
These aided decision-makers in understanding plausible impacts of their actions.

\subsection{Data sources} \label{intro:sec:data-for-estimating}

The surveillance systems set-up in response to SARS-CoV-2 were on a scale never previously seen.
The main data sources informing the response to the SARS-Cov-2 epidemic in England were based on: community testing, severe events, seroprevalence surveys, and prevalence surveys.
Each of these data sources have strengths and weaknesses, see \textcite{royalSocietyRnumber} and references therein for further details on each of these data sources.

\subsubsection{Incidence-type data}

For large parts of the pandemic, community testing was widely available in the UK.
However, the number of tests carried out varied over time and space, and for a variety of reasons.
Reasons included: policy changes on who was eligible for testing; availability of tests; and willingness of individuals to be tested.
Therefore, changes in the number of positive tests did not necessarily reflect changes in disease incidence.
The large number of tests conducted allowed detailed analyses to be performed, including stratification by small geographic areas or age groups, although the lack of interpretability remained.

The number of severe events was generally a more reliable measure of the burden of the disease, subject to fewer changes than the number of cases detected through community testing.
However, SARS-CoV-2 rarely led to severe events in younger individuals, so severe event counts were insensitive to changes in transmission only affecting younger individuals.

\subsubsection{Prevalence-type data}

Seroprevalence surveys were conducted throughout the epidemic, the largest of which tested donated blood~\autocite{amirthalingamSeroprevalence}.
In addition to the problem of the delay between infection and antibody response, blood donors are a convenience sample whose representativeness of the wider population is unclear.

The extraordinary impact of SARS-CoV-2 led the UK Government to fund two large prevalence surveys in representative samples of the general population.
These were designed to avoid the biases of community testing and observe the general population.
These surveys use RT-PCR (reverse transcription polymerase chain reaction, described in detail in \cref{E-biology-data:sec:PCR}) testing to detect the presence of the virus in a swab from an individual.
The first survey was the CIS (Coronavirus (COVID-19) Infection Survey), run by the ONS (Office for National Statistics)~\autocite{CIS,cisMethodsONS}.
The CIS was a longitudinal, household-based study, testing a large number of individuals weekly or monthly for SARS-CoV-2 infection (see \cref{E-intro:sec:cis} for a detailed description).

A second prevalence survey, known as REACT (the REal-time Assessment of Community Transmission)~\autocite{rileyResurgence,rileyREACT}, consisted in a series of cross-sectional surveys.
REACT conducted 19 surveys between May 2020 and March 2022, each including at least \numprint{100000} randomly sampled individuals from the UK, who contributed swabs for RT-PCR testing and questionnaire data~\autocite{elliottTwin}.

A major advantage of the CIS over REACT is that the CIS had continual data collection, while REACT has no test results between rounds.
This meant that using REACT data to infer transmission in these periods requires strong model assumptions.
A particular instance of this is that a peak in prevalence in late December 2020 occurred between rounds of the REACT survey, complicating any analysis of REACT data over that period~\autocite{rileyREACTround8}.

\subsubsection{Longitudinal studies}

Many longitudinal studies were conducted throughout the pandemic.
They aimed to estimate a wide variety of epidemiological and biological quantities of the SARS-CoV2 virus.
These include the CIS, previously mentioned.
% In addition to population-level surveillance, cohort studies help understand other aspects of the pathogen~\autocite{royalSocietyRnumber}.
% For example, contact tracing data can inform how likely it is for transmission to occur in different settings and/or between different groups of people.

Another study, which I use in this thesis, is the ATACCC (Assessment of Transmission and Contagiousness of COVID-19 in Contacts) study~\autocite{singanayagamCommunity,hakkiOnset}.
ATACCC recruited individuals from contacts of known infections reported to NHS Test and Trace, and collected data on them for 20 days.
This included daily RT-PCR tests, which allowed quantification of their viral load (the amount of virus in an individual), a biomarker.
The density of the sampling allows for modelling the trajectory of viral load to estimate the duration of detectability (how long an individual is RT-PCR positive for).
However, the results from ATACCC are of limited value because of the small sample size and the short follow-up; prohibiting estimation of how quantities vary over long infections.
I describe ATACCC in detail in \cref{E-biology-data:sec:ataccc} and use it to estimate the duration of detectability in \cref{E-ATACCC}.

\section{Thesis context}

Analysis of pandemic data was carried out rapidly, to provide the timely results needed to inform the ongoing and evolving response.
Therefore, a deep understanding of the potential of each data source was not possible.
In this thesis I investigate the potential of the CIS as a single source of information for incidence and transmission estimation.

I use Bayesian inference throughout this thesis.
Including prior information allows identifiability in situations where this would not otherwise be possible and allows for combining knowledge from multiple sources.
Additionally, many previous studies I build on used Bayesian inference.

In the following subsections, I introduce the most relevant related work, carried out both prior to the pandemic and during its course.

\subsection{Backcalculation}

\emph{Backcalculation} is a modelling framework developed in the context of HIV/AIDS~\autocite{brookmeyerMethod} but applied very broadly.
It specifies a particular combination of infection, disease, and observation model which relate times of HIV infection with times of AIDS diagnosis via the incubation period.
Further details are in the recent review \textcite{sunModeling}.
I build on the theory behind the framework in this thesis.

The original formulations~\autocite{brookmeyerMethod,rosenbergBackcalculation} use a phenomenological Poisson process as the infection model; a disease model with a delay function, $f$, representing the pdf of the time between HIV infection and AIDS diagnosis and assumed $\zeta=1$; and a trivial observation model where all diagnoses are recorded.

In \cref{E-inc-prev}, I will adapt this backcalculation framework for use with prevalence survey data, such as the CIS.
The use of prevalence-type data induces a dependency structure between the values of the latent process $W_1, \dots, W_t$; I include the dependency by modifying the disease model.
In addition, unlike in the original formulations, not all infections are detected by the CIS.
In the CIS, a sample of the population receive RT-PCR tests, not the entire population; I include the sampling error arising from this in the observation model.

\subsection{Existing duration estimates} \label{intro:sec:previous-duration-estimates}

In the application of \cref{intro:eq:disease-model} to the CIS data, the delay function $f$ represents the duration of detectability.
Previous work has attempted to estimate $f$.

An initial meta-analysis estimated that individuals test positive for SARS-CoV-2 for a mean of 14.6 days (95\% CI: 9.3--20.0 days)~\autocite{cevikShedding}.
The longest reported observed duration was 83 days, although no individuals were infectious beyond day 9.
However, most studies included in the meta-analysis involved hospitalised patients or had unclear inclusion criteria, and hence may not be representative of the general population.
In addition, summary estimates are insufficient for backcalculation, which requires a full distribution.

\Textcite{hellewellPCRSensitivity} estimated the probability of an individual testing positive each day after infection.
This measure is highly related to the duration of detectability.
However, the study's cohort consisted only of healthcare workers, \ie working-age adults.

\Textcite{binnySensitivity} applied a slight variant of \textcite{hellewellPCRSensitivity}'s methodology to data from New Zealand.
New Zealand was successfully pursuing a zero-COVID strategy at the time, meaning that the individuals in the study were unusual.
For example, a third were travellers detected during their quarantine period on arrival to New Zealand but would have had negative RT-PCR tests before their departure.

\Textcite{ealesCharacterising} estimated the duration of detectability from REACT data.
Specifically, individuals who tested positive in round 8 of REACT (6--22 Jan 2021) were invited to take two additional swab tests.
Taking the time of the initial positive test as time 0, \textcite{ealesCharacterising} estimated the probability of remaining positive at each day after the initial positive test.
They made a strong parametric assumption that the probability decreases exponentially, with a sensitivity analysis assuming a plateau before the decay.
Strong assumptions are necessary because they had at most 17 days of follow-up, and hence could not estimate the tail of the distribution.
Overall, they estimate a median duration of 14.0 days (95\% CI: 12.9--15.4 days) with substantial positive correlation with each individual’s viral load at the time of the initial positive test (\ie a higher initial viral load was associated with a longer duration of detectability).
The individuals with the highest viral load individuals were estimated to have a median duration of 19.6 days (16.1--25.8 days).
The association could be due to individuals with a higher initial viral load being (on average) more recently infected at the time of the initial positive test.
The study design prevents assessing this hypothesis because the design does not provide any information on how long before the initial positive test the infection occurred.
This issue also means the study underestimates the duration of detectability, because the infection's true start time would be prior to the initial positive test.

For the purposes of this thesis, I require estimates of the duration of detectability applicable to the general population.
As no such estimates of the full distribution of the duration are available in the literature, a key component of this thesis is estimating them.
To do so, I will combine the information from the ATACCC and CIS studies.


\subsection{Existing use of prevalence surveys}

Several previous studies have used SARS-CoV-2 prevalence surveys to estimate incidence and/or transmission.

\Textcite{abbottCISincidence} applied backcalculation to CIS data to estimate the incidence of SARS-CoV-2 in the UK.
They used summary statistics of prevalence estimates from the CIS, taken from the ONS website, as data; specifically, the prevalence's posterior point estimate and bounds of the 95\% credible interval.
From these summary statistics, they derive a normally-distributed likelihood, independent for each day.
They used \textcite{hellewellPCRSensitivity}'s estimates of the sensitivity of testing as $f$ in their observation model; these estimates are based on a longitudinal study in healthcare workers (see \cref{intro:sec:previous-duration-estimates}).
% They fit to summary statistics of the CIS data, using a daily, independent normal likelihood with parameters estimated from the posterior point estimate and 95\% credible interval published by the ONS.
\Textcite{colmanAscertainment} used a similar method to estimate the \emph{ascertainment rate} of community testing (the proportion of all infections that community testing detected).
% Their methodology was similar to \textcite{abbottCISincidence}, including using estimates of $f$ from \textcite{hellewellPCRSensitivity}.
% Rather than using a smooth prior to provide stability, as \textcite{abbottCISincidence} do, \textcite{colmanAscertainment} assume the ascertainment rate is piecewise constant.
% They do not fully propagate the uncertainty from the CIS prevalence estimates, considering only the bounds of the 95\% confidence intervals the ONS publishes for prevalence.

Several compartmental models incorporated data from SARS-CoV-2 prevalence surveys, alongside other data sources~\autocite{daviesAssociation,ironsEstimating,knockKey,nicholsonImproving,pooleyEstimation,birrellRTM2}.
% These models incorporate prevalence survey data by adding additional compartments representing RT-PCR positive individuals, who may not be infectious (this is common, see \cref{E-biology-data}); except \textcite{nicholsonImproving} who have a more sophisticated approach (below) and \textcite{ironsEstimating}, who assume RT-PCR positivity coincides with infectiousness.
% The length of stay in these compartments (the duration of time positive) is assumed to follow a gamma distribution, with the parameters estimated from external data or having at most one free parameter.
The model structure used in these studies limited the distribution of the duration of detectability to specific classes of distributions.
% These approaches are similar to how these models are fit to other data sources, such as hospital admissions or deaths.

\Textcite{nicholsonImproving} estimate prevalence at a small geographic scale, using REACT data to remove the observational biases in community testing data.
They use a simple mechanistic model, without age structure, but a sophisticated observation model.
They allow an arbitrary distribution of the duration of detectability, based on the estimates of \textcite{hellewellPCRSensitivity}, and incorporate the sensitivity and specificity of the RT-PCR test.

\Textcite{mccabeCISincidence}, adapting the methodology \textcite{ealesAppropriately} developed for REACT, estimate $\Re$ and $r$ from the CIS data.
They first estimate prevalence using summary statistics from the CIS, then derive $\Re$ and $r$ using a semi-mechanistic model fitted to their prevalence estimates.
% They then fit a semi-mechanistic model to the estimating prevalence 
% a posterior distribution of the parameters of a spline by fitting to the prevalence results via a binomial distribution.
% Their set-up penalizes the spline deviating from a constant growth rate.
% They calculate the growth rate from the derivative of the spline, an analytical transformation of the parameters. 
% Since, under reasonable model assumptions, there is a one-to-one correspondence between reproduction numbers and growth rates~\autocite{wallingaGI}, and they assume that the growth rate in incidence and prevalence is equal, this also estimates $\Re$.

% \section{Bayesian inference} \label{intro:sec:Bayes}

% All inference in this thesis is Bayesian.
% Including prior information allows identifiability in situations where this would not otherwise be possible and allows for combining knowledge from multiple sources.
% Many previous studies I build on used Bayesian inference.

% Analytically deriving the posterior distribution is impossible for the models in this thesis.
% Therefore, I use computational methods to sample from the posterior distribution.
% The method I use for the majority of the analyses is MCMC (Markov chain Monte Carlo) (see \cref{E-MCMC} for details).

\section{Thesis aims and contribution} \label{intro:sec:aims}

The overall question that I investigate in this thesis is: can a prevalence survey \emph{alone} be sufficient to infer incidence and transmission and, if so, what method(s) are optimal?
% First, how can prevalence surveys be designed to help estimate these quantities?

To address this question, I use a case study.
Specifically, the CIS data from the SARS-CoV-2 epidemic in England from Mon 31 Aug 2020 until Sun 25 Jan 2021.
This case study is suitable for addressing this question for several reasons.
First, the CIS was of sufficient size, and transmission was sufficiently high, to provide enough data for the analyses.
Second, incidence began to rise over this period, after the fall due to the first lockdown.
Finally, the period ends before the vaccine roll-out, which  affected many important aspects of the analysis; most relevantly, the duration of detectability and the susceptibility of the population.
Incorporating vaccination effects would require more complex modelling and include idiosyncratic features of the SARS-CoV-2 pandemic that are less generalisable to other diseases.

The secondary aim of this thesis is to improve our understanding of the epidemic in England over this period, and our understanding of the SARS-CoV-2 virus more broadly.
The results of the analyses I perform in pursuit of the primary aim will naturally contribute to this second aim.

\subsection{Methodological contributions}

This thesis makes several methodological contributions.
\begin{enumerate}
    \item In \cref{E-inc-prev:sec:observation-process}, I provide a theoretic justification for the use of a \emph{deterministic} backcalculation for prevalence surveys.
    A deterministic approach approximates the prevalence at any time as a deterministic function of the incidence, rather than as a random variable.
    This approximation has previously been used to analyse the CIS data (\eg by \textcite{abbottCISincidence}); however, no justification for the approach was provided.
    In \cref{E-inc-prev:sec:observation-process} I show that it is a good approximation as long as the proportion of the population sampled is small.
    In particular, the accuracy of the approximation does not require the prevalence or incidence to be large.
    
    \item In \cref{E-perf-test}, I develop a novel statistical framework to estimate the duration of detectability using the CIS data.
    The framework accounts for the CIS data being doubly interval censored and having arbitrary periods where infections could be undetected.
    To improve inference within this framework, I propose a novel prior to integrate information from my analysis of the ATACCC study into this analysis, accounting for model uncertainty.
    
    \item In \cref{E-imperf-test}, I extend the framework above to account for false negatives.
    A particular challenge with these analyses is that they must be performed within a trusted research environment with limited computational resources.

    \item In \cref{E-backcalc}, I use a deterministic, phenomenological backcalculation to estimate incidence, including full propagation of the uncertainty from the prevalence survey.
    Furthermore, I use my estimate of the duration of detectability, which is from general population studies.
    
    \item In \cref{E-SEIR}, I develop a compartmental model for SARS-CoV-2 transmission, relying \emph{only} on CIS data. 
    I translate my estimate of the distribution of the duration of detectability into a progression through model states.
    To do this, I use an Erlang--Coxian distribution; this distribution is more flexible than standard approaches in the infectious disease literature.
    I include age-stratification in the transmission model, allowing estimation of age-specific transmission.
    I show the CIS data are sufficient for estimating incidence and transmission.
\end{enumerate}

\subsection{Epidemiological contributions}

The secondary aim of this thesis is providing new estimates to improve our understanding of the epidemic in England over the period I study.

In \cref{E-imperf-test}, I generate estimates of the duration of RT-PCR-positivity in the general population.
These estimates could inform public health policy, for example, in interpreting RT-PCR test results or formulating quarantine policies.

In \cref{E-transmission}, I estimate incidence and transmission of SARS-CoV-2 in England over the period.
These estimates contribute to the literature reconstructing the SARS-CoV-2 epidemic in England.
Understanding the dynamics of past infection is important for informing the response to future pandemics, and the future burden of SARS-CoV-2.

\subsection{Software and data availability}

To carry out the work in this thesis I developed bespoke code.
To ensure the methodology developed can be easily adopted by others, this code is available online.
An index to the code and, where possible, data are available at \url{https://github.com/joshuablake/thesis-index}.
I structured two elements of the code as R packages to enable their application to future contexts.

First, the framework to simulate the CIS (used in \cref{E-imperf-test:sec:simulate,E-perf-test:sec:simulation-study}).
The package enables customisation of various features of the study, for example the testing regime of the participants, the sensitivity of the tests, and the duration of detectability.
This package would be particularly useful in answering questions regarding the design of future prevalence surveys, for example, how frequently individuals should be tested, or how many individuals should be tested.

Second, the survival analysis framework used to infer the duration of detectability in \cref{E-perf-test,E-imperf-test}.
The framework allows the user to specify all the different analyses performed in these chapters in a simple interface. 
Furthermore, adding new analyses, for example varying the priors or the inclusion of covariates, is straightforward.

Where possible, aggregated, non-disclosive versions of the datasets are available alongside the code.
The original ATACCC data used are available alongside the code.
The original CIS data can only be accessed by accredited researchers within the ONS's SRS (Secure Research Service); see \url{https://www.ons.gov.uk/aboutus/whatwedo/statistics/requestingstatistics/secureresearchservice} for details.

Almost all code, excluding dependencies, was written from scratch for these analyses.
The exceptions are the Markov chain Monte Carlo sampler used in \cref{E-SEIR}, the model for prevalence used in \cref{E-biology-data:sec:MRP}, and the original viral load model used in \cref{E-ATACCC:sec:hakki}.

\subsection{Structure}

In \cref{E-biology-data}, I provide background information on: the natural history of SARS-CoV-2, the RT-PCR testing process used to produce the data analysed throughout this thesis, and describe the information available in the CIS and ATACCC studies.

In \cref{E-inc-prev}, I formally describe the infection, disease, and observation models for a prevalence survey.
I show the distribution of the duration of detectability is the key quantity linking incidence and prevalence.

In \cref{E-ATACCC}, I estimate the duration of detectability from the ATACCC study.
This provides a reliable estimate of the bulk of the distribution (out to around 20 days),  but shows that estimating the tail requires a large sample size and long follow-up. 
These features are present in the CIS.
In \cref{E-perf-test}, I provide a framework for estimating the duration of detectability assuming perfect tests from prevalence surveys such as the CIS.
However, as the assumption of perfect tests is not realistic; in \cref{E-imperf-test}, I extend the framework to include false negatives.

Having estimated the duration of detectability, I estimate incidence and transmission from the CIS data in \cref{E-transmission}.
I use both a phenomenological and mechanistic transmission model, contrasting their results and discussing the advantages and disadvantages of each in this context.

Finally, I conclude in \cref{E-conclusion} with a discussion of my findings, the limitations of this work, and ideas for future research.

Appendices provide definitions of the probability distributions used in this thesis, further details, and additional results.


\ifSubfilesClassLoaded{
  \appendix
%   \subfile{MCMC-appendix}
  \listoftodos
}{}
\end{document}