\documentclass[thesis.tex]{subfiles}

\begin{document}
\ifSubfilesClassLoaded{

% \section{Definitions}
% \todo[inline]{These will be defined in the introductory chapters, but are here so that this draft is understandable}
% \begin{itemize}
% \item
%   We assume that, for all episodes $i$, $D_i$ is iid and independent
%   of the time of the infection. Define the survival function
%   $\prob(D_i \geq t \mid B_{j} = b, \vec{\theta}) = \prob(D_i \geq t \mid \vec{\theta}) = S_{\vec{\theta}}(t)$,
%   where $\vec{\theta}$ are the parameters controlling the survival
%   distribution (the discussion in this document is valid regardless of
%   the model specified for $S_{\vec{\theta}}$ and hence we consider $\vec{\theta}$
%   as an arbitrary vector of parameters).
% \item
%   The beginning of episode $i$ is known to occur in the interval
%   $[l_{j}^{(b)}, r_{j}^{(b)}]$, and similarly for the end of the infection
%   in $[l_{j}^{(e)}, r_{j}^{(e)}]$.
% \end{itemize}

\setcounter{chapter}{4}
}

\chapter{Estimating duration with infrequent testing} \label{perf-test}

When estimating incidence from prevalence, the mean duration, not its median, is the most important feature of the duration distribution~\autocite{freemanPrevalence}.
Duration distributions tend to be right-skewed.
Therefore, estimates of the mean can be sensitive to the tail of the duration distribution.

In \cref{E-ATACCC} I estimated the duration distribution from the ATACCC dataset.
However, this study had a small sample size and only 20 days of follow-up, which prevented accurate estimation of the tail.
Therefore, model assumptions drive the estimated size of the tail.

The CIS samples individuals less frequently, but has a large sample size (\numprint{4800} detected infection episodes) and up to years of follow-up.
Therefore, it is suitable for estimating the tail of the duration distribution.
In this chapter, I develop a method to estimate the duration distribution using CIS data, assuming the test has perfect sensitivity and specificity, \ie there are no false negatives or positives.
Formally, I aim to estimate the survival function $S(t)$ defined in \cref{inc-prev:sec:definitions}.

In \cref{perf-test:sec:problem}, I describe the challenges analysing the data presents.
This motivates using a survival analysis framework which I introduce in \cref{perf-test:sec:surv-analysis}, before deriving the statistical model for the CIS setting in \cref{perf-test:sec:model}.
In \cref{perf-test:sec:parameters-priors}, I consider how to parameterize the survival function and choose its priors, including vague and smoothing priors as well as a prior constructed to include the information from \cref{E-ATACCC}.
I evaluate the model and priors using a simulation study (\cref{perf-test:sec:simulation-study}), showing that they successfully recover $S(t)$.
Finally, I discuss the results in \cref{perf-test:sec:discussion}.

\section{Problem description} \label{perf-test:sec:problem}

In the CIS, individuals are tested infrequently, either weekly or monthly (see \cref{E-intro:sec:cis}), complicating the data in two ways.
First, infection episodes can go undetected.
Second, the infection episodes' start and end times are known imprecisely.
I explain these issues below and devote the rest of the chapter to the development of a method to tackle  them.

\subsection{Undetected infections} \label{perf-test:sec:undetected}

The first complication in the analysis is that infection episodes can be undetected.
Undetected infection episodes are episodes with no associated positive tests.
Therefore, there is no information directly observed about the episode; even the number that occur is latent.
They occur when an episode starts and ends between tests (see \cref{perf-test:fig:truncation}).
Undetected episodes are, on average, shorter than detected episodes; therefore, neglecting them would lead to a biased estimate of the survival distribution.
To see why they are shorter, consider the infection episode in \cref{perf-test:fig:truncation}.
Here two individuals are shown, with identical data collected for each of them (a series of negative
 tests).
The first individual was never infected whereas the second individual has an undetected infection. 
The undetected infection episode begins at time 33 and has a 10-day duration.
The individual would have been detected at their next test if their duration had instead been 24 days or more.
The gap between tests in the CIS (up to 28 days, see \cref{E-intro:sec:cis}) is longer than the duration of most infections (median 16 days, see \cref{E-ATACCC:sec:results}).
Therefore, it is likely that many infections in the CIS cohort were undetected.
\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=\textwidth]{cis-perfect-testing/truncation}}
  \caption[Undetected episodes in CIS data]{%
    Identical data for two individuals, with a series of negative tests.
    Top individual remains uninfected, bottom individual has an undetected infection.
    The shaded area represents when the individual is detectable.
    Time is relative to the individual's first CIS test.
  }
  \label{perf-test:fig:truncation}
\end{figure}

\subsection{Unobserved times for each episode's beginning and end} \label{perf-test:sec:interval-censoring}

The second complication is that the beginning and end times of detected infection episodes are latent.
Recall, from \cref{E-biology-data:sec:cis-episodes}, that the time episode $j$ starts, $b_j$, is only known to lie in the interval $[l_j^{(b)}, r_j^{(b)}]$ where $l_j^{(b)}$ is the day after the negative test prior to the start of episode $j$ and $r_j^{(b)}$ is the first positive test in episode $j$.
Similarly, for the end of the infection episode, $e_j \in [l_j^{(e)}, r_j^{(e)}]$.
\Cref{perf-test:fig:double-interval-censor} shows this issue graphically.
\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=\textwidth]{cis-perfect-testing/double-interval-censor}}
  \caption[Double-interval censoring in CIS data]{%
        The beginning and end of each episode observed in the CIS data are only known up to an interval.
        Demonstrated here by a participant who is recorded negative at time 7 and positive at time 14, bounding the start of the episode; similarly, changing from positive at time 28 to negative at time 56 bounds the end of the episode.
      Time is relative to the individual's first CIS test.
    }
    \label{perf-test:fig:double-interval-censor}
\end{figure}

\section{Survival analysis} \label{perf-test:sec:surv-analysis}

In survival analysis, the interest is in estimating the distribution of the interval between an \emph{initiating event} and a \emph{terminating event}.
In the current context, the initiating event is the episode's start; the terminating event is the episode's end.
I start by introducing the relevant, standard concepts in survival analysis; a wide range of texts cover these concepts including \textcite[chapter 1]{bogaertsSurvival}.

A common issue is that the initiating and/or terminating events are not known exactly.
This is known as the event being \emph{censored}.
An event is \emph{left censored} if it is known to have occurred before a certain time.
An event is \emph{right censored} if it is known to have occurred after a certain time.
An event is \emph{interval censored} if it is known to have occurred within an interval.
If both the initiating and terminating event are interval censored, the data are \emph{doubly interval censored}.
To handle doubly interval censored data, the times need to be jointly modelled~\autocite[and references therein]{liSemiparametric}.

Sometimes, only intervals satisfying some property are recorded.
In this case, data are \emph{truncated}.
\emph{Left truncation} is when only events lasting longer than a minimum amount of time are observed.
\emph{Right truncation} is when only events lasting shorter than a maximum amount of time are observed.
Without correcting for truncation, inference on the distribution of a duration will be biased.

In the CIS data, the initiating and terminating events are only bounded (see \cref{perf-test:sec:interval-censoring}).
Therefore, the data are doubly interval censored.

There are also undetected infections in the CIS (see \cref{perf-test:sec:undetected}).
However, the situation is subtly different from the standard truncation situation encountered in the literature.
In the standard situation, nothing is known about the unrecorded intervals.
But in CIS, individuals in which undetected infections occurred are enrolled in the study.
Therefore, we know the times that they were tested.
This provides information on how long their infections may have been.
I refer to these events as ``undetected'', rather than truncated, to emphasise this difference.

\Textcite{sunAnalysis,bogaertsSurvival} review methods for doubly interval censored data.
However, few studies look at data both doubly interval censored and with undetected (or truncated) events.
% This is especially true within the biostatistical literature on human diseases.
General theoretical frameworks, which include this case, have been developed~\autocite{turnbullEmpirical,dempsterMaximum}.
Yet only the special case where the terminating event is either uncensored or right censored has been applied in practice~\autocite[e.g.][]{sunEmpirical,bacchettiNonparametric,shenNonparametric}.
These studies base their inference on a likelihood contribution for each detected infection episode conditional on $b_j \in [l_j^{(b)}, r_j^{(b)}]$.

For this conditional likelihood to be valid, they assume this conditioning provides negligible information on the distribution of interest~\citePersonalComms{Nick Jewell}.
This assumption performs well in these settings, when the length of the intervals is fairly constant.
In particular, when the interval lengths are near-constant, $p(\text{episode $j$ detected} \mid b_j \in [l_j^{(b)}, r_j^{(b)}]) \approx p(\text{episode $j$ detected})$.
However, the interval lengths change from one to four weeks in the CIS (see \cref{E-intro:sec:cis}).

Infection episodes in an individual's one-week testing period are over-represented in the detected infections.
This is because more frequent testing will detect a higher proportion of infections.
Therefore, for the average detected episode, $p(\text{episode $j$ detected} \mid b_j \in [l_j^{(b)}, r_j^{(b)}]) > p(\text{episode $j$ detected})$ and conditioning on $b_j \in [l_j^{(b)}, r_j^{(b)}]$ is inappropriate.

Doubly interval censored and truncated data are common when assessing the survival time of bird and insect nests~\autocite{heiseyABCs}.
\textcite{heiseyModelling}, building on long-standing methodology~\autocite{dempsterMaximum,turnbullEmpirical}, develops a likelihood-based inference framework, allowing for arbitrary truncation patterns and double interval censoring.
They apply it to a situation where the visit times (possible detection times) are common to all the individuals, simplifying the likelihood.
I adapt this framework for CIS, when each individual has their own visit schedule (see \cref{perf-test:sec:model}).

I use Bayesian inference for two reasons.
First, the frequentist properties (\eg consistency and convergence rate) of existing estimators are poorly understood~\autocite{sunAnalysis,dengNonparametric}.
Second, a prior can include information from previous studies, such as \cref{E-ATACCC}.
Alternatively, the prior can favour a smoothly changing hazard, which is biologically sensible, and can overcome issues caused by the undetected episodes ~\autocite{caoBias}.

Bayesian methods have been used for nest survival before~\autocite{heBayesiana,heBayesian,caoModeling} by augmenting the data with the unobserved times of infection.
The data augmentation approach creates a parameter for each detected infection.
This increases the dimensionality of the problem greatly, making it computationally infeasible with the large sample size of the CIS within the SRS.


\section{Modelling the duration}\label{perf-test:sec:model}

In this section, I develop a computationally feasible Bayesian statistical model accounting for double interval censoring and undetected episodes.
In \cref{perf-test:sec:data}, I introduce the data, defining which quantities are observed and which are latent.
In the remainder of the section, I derive the posterior density, adapting the general approach of \textcite{heiseyModelling}.
I classify episodes based on how they would be observed (\ie the intervals that their beginning and end times would be censored to).
These potential classification can then be compared to the actual observations.

Unlike in \textcite{heiseyModelling}, I must consider each individual's probability of undetected episodes separately because they are tested at different times.
In addition, I include the information from the individuals without a detected episode.
Furthermore, I marginalise the posterior density over the number of undetected episodes.
This makes inference tractable using the large sample size and limited computing resources available within the SRS (see \cref{E-biology-data:sec:SRS}).
% In particular, the posterior can be expressed within modern, high-performance Bayesian software such as Stan.

\subsection{Data} \label{perf-test:sec:data}

I analyse the $\ndet = \numprint{4800}$ episodes with their first positive test between 10 Oct 2020 and 6 Dec 2020 inclusive, with negatives bounding the start and end time of the episode; I refer to these episodes as \emph{detected}; in \cref{perf-test:sec:prob-undetected} I formalise the conditions for an episode to be detected.
Each day in this period is denoted as $t = 1, \dots, T$; \ie day $1$ is the 10 Oct 2020 and day $T$ is the 6 Dec 2020.
I use these episodes because a negative test before the start of the episode provides a lower bound on the episode's start time; otherwise, there is little information on its length.
Similar information comes from the negative test after the end of the episode, although a negligible number of episodes are missing a negative test after the end of the episode.
How the episode data are constructed is detailed in \cref{E-biology-data:sec:cis-episodes}.

I consider the cohort of $\Ncis = \numprint{437590}$ individuals who could have had a detected episode.
This is the subset of the whole CIS cohort with at least one test between time 1 and $T$.
I index these individuals by $i = 1, \dots, \Ncis$.

An individual $i$ has a \emph{test schedule} $\sched_i$.
The test schedule $\sched_i$ is the set of times individual $i$ is tested at, starting from their last test prior to time 1, if it exists, or their time of enrolment otherwise; note that $\sched_i$ includes any tests that occur after $T$.
For example, for the individual in \cref{perf-test:fig:double-interval-censor}, $\sched_i = \{ 0, 7, 14, 21, 28, 56 \}$.
Each individual has exactly one test schedule, but it is possible that $\sched_i = \sched_{i'}$ for $i \neq i'$.
I assume that the test schedules are uninformative on all quantities of interest because they are part of the study design.
Therefore, I condition on them implicitly in all probabilities that follow.

For any episode $j$, define $O(j)$ as the observations of that episode.
Test results are deterministic based on the time of the test and the individual's infection status.
Therefore, $O(j)$ is fully determined by the triplet $(b_j, e_j, i(j))$ consisting of $j$'s beginning time, end time, and the individual in which the episode occurs respectively.
The episode's duration is $d_j = e_j - b_j + 1$ (see \cref{E-inc-prev:sec:definitions}).

If $j$ is detected, then $O(j) = [l_j^{(b)}, r_j^{(b)}, l_j^{(e)}, r_j^{(e)}, i(j)]^T$, where $i(j)$ is the individual in which the episode occurs; $l_j^{(b)}$ and $r_j^{(b)}$ are the earliest and latest time the episode could have begun respectively; and $l_j^{(e)}$ and $r_j^{(e)}$ are the earliest and latest time the episode could have ended respectively.

If $j$ is undetected, there are no observations; in which case, define $O(j) = \emptyset$.
Let $\nnodet$ denote the (latent) number of undetected episodes experienced across all $\Ncis$ individuals.
Therefore, the total number of infection episodes in the cohort is $\ntot = \ndet + \nnodet$ and I index them with $j = 1, \dots, \ntot$.

% Any infection episode, whether detected or not, is fully characterised by the triplet $(b_j, e_j, i(j))$ where $b_j$ and $e_j$ are the times the episode begin and end respectively; and $i(j)$ is the individual the episode occurred in.
% $i(j)$ identifies the test schedule.
% For all $j$, the exact values $b_j$ and $e_j$ are latent.
% If $j$ is undetected then $i(j)$ is also latent and little is known about $b_j$ or $e_j$.
% If $j$ is detected, then $i(j)$ is known; $b_j \in [l_j^{(b)}, r_j^{(b)}]$; and $e_j \in [l_j^{(e)}, r_j^{(e)}]$.
% These latter two properties are what make the data doubly interval censored.

\subsection{Posterior density} \label{perf-test:sec:posterior}

Define an integer $N_E$ and $\set{E} = \{ \vec{\nu}_1, \dots, \vec{\nu}_{N_E} \}$ as the set of all possible observations of detected episodes; that is, $O(j) \in \set{E}$ if and only if $j$ is a detected infection.
Let $\vec{\nu}_k = [l^{(b)}_k, r^{(b)}_k, l^{(e)}_k, r^{(e)}_k, i_k]^T$ be an arbitrary vector of possible observations, visualised in \cref{perf-test:fig:partitionSpace}; the conditions for $\vec{\nu}_k \in \set{E}$ are in \cref{perf-test:sec:conditions-nu-E}.

The target of inference is $\vec{\theta}$, the parameters of the survival function $S_{\vec{\theta}}(t)$.
The contents of $\vec{\theta}$ are discussed in \cref{perf-test:sec:parameters-priors}.

Let $n_k$ denote the number of observations of $\vec{\nu}_k$; $\nnodet$ denote the latent number of undetected episodes; and $\vec{n} = [n_1, \dots, n_{N_D}, \nnodet]^T$.
Hence, $\ntot = \sum_{i=1}^{N_D} n_i + \nnodet$.

Now define the probabilities of each possible outcome of $O(j)$.
For detected outcomes, \ie $\vec{\nu}_k \in \set{E}$, let $p_k = \prob(O(j) = \vec{\nu}_k \mid \vec{\theta})$.
For undetected outcomes, let $p_u = \prob(O(j) = \emptyset \mid \vec{\theta})$.
Together, $\vec{p} = [p_1, \dots, p_D, p_u]^T$.
Assume, for tractability, that the events $O(j) = \vec{\nu}_k$ and $O(j') = \vec{\nu}_{k'}$ are independent for $j \neq j'$; this assumption is discussed in \cref{perf-test:sec:discussion}.

Then:
\begin{align}
  \vec{n} \mid \ntot, \vec{\theta} &\dist \MN(\ntot, \vec{p})
\intertext{that is:}
  p(\vec{n} \mid \ntot, \vec{\theta}) &= \frac{\ntot!}{\nnodet!\prod_{k=1}^{N_D} n_k!} p_u^{\nnodet} \prod_{k=1}^{N_D} p_k^{n_k}.
  \label{perf-test:eq:multinomial-ll}
\end{align}
\begin{figure}
\makebox[\textwidth][c]{\includegraphics[width=0.9\paperwidth]{cis-perfect-testing/regions_diag}}
\thisfloatpagestyle{empty}
\caption[Episode regions]{%
  Each dot is a combination of $b_j$ and $e_j$ for an arbitrary individual $i$.
  Each box, bounded by dashed lines, are combinations giving $O(j) = \vec{\nu}_k$, $k$ corresponding to the numeric label; labels are arbitrary but unique across all individuals.
  $i$ had negative tests at times 0, 7, 14, 56, and 84 (not shown) and positive tests at times 21 and 28.
  The purple region corresponds to the doubly interval censored episode in this individual.
  That is, $n_8 = 1$ and $n_k = 0$ for $k = 1, \dots, 7, 9, \dots, 15$.
  The red region corresponds to combinations giving $O(j) = \emptyset$.
  Impossible region violates $b_j \leq e_j$.
}
\label{perf-test:fig:partitionSpace}
\end{figure}

In the CIS data, each $n_k$ ($k \neq u$) is observed as either 0 or 1.
Define $\set{D} = \{ k \ssep n_k = 1 \}$, the detected episodes.
Furthermore, note that the support of the multinomial distribution requires that $\nnodet = \ntot - \ndet$.
Let $\na = [n_{1}, \dots, n_{N_E}]^T$ be the observed portion of $\vec{n}$.
Then \cref{perf-test:eq:multinomial-ll} simplifies to:
\begin{align}
  p(\vec{n} \mid \ntot, \vec{\theta})
  &= p(\na \mid \ntot, \vec{\theta}) \\
  &= \frac{\ntot!}{(\ntot - \ndet)!} p_u^{\ntot-\ndet} \prod_{k \in \set{D}} p_k.
  \label{perf-test:eq:multinomial}
\end{align}

The relevant information from the CIS data is fully contained in the vector $\na$.
Therefore, the posterior of interest is:
\begin{align}
p(\vec{\theta} \mid \na)
&\propto p(\vec{\theta}) p(\na \mid \vec{\theta}) \\
&= p(\vec\theta) \sum_{\ntot= \ndet}^{\infty} p(\ntot, \na \mid \vec{\theta}) \\
&= p(\vec{\theta}) \sum_{\ntot=\ndet}^\infty p(\ntot \mid \vec{\theta}) p(\na \mid \ntot, \vec{\theta}) \\
&= p(\vec{\theta}) \sum_{\ntot=\ndet}^\infty p(\ntot \mid \vec{\theta}) \frac{\ntot!}{(\ntot - \ndet)!} \pnodet^{\ntot - \ndet} \prod_{k \in \set{D}} p_k &\text{by \cref{perf-test:eq:multinomial}} \\
&= p(\vec{\theta}) \left( \prod_{k \in \set{D}} p_k \right) \left( \sum_{\ntot=\ndet}^\infty p(\ntot \mid \vec{\theta}) \frac{\ntot!}{(\ntot - \ndet)!} \pnodet^{\ntot - \ndet} \right).
\label{perf-test:eq:posterior1}
\intertext{For convenience, define the summation term as:}
\eta &= 
\sum_{\ntot=\ndet}^\infty p(\ntot \mid \vec{\theta}) \frac{\ntot!}{(\ntot - \ndet)!} \pnodet^{\ntot - \ndet}.
\label{perf-test:eq:eta}
\end{align}
The rest of this section derives expressions for each of $p_{k}$, $p_{u}$ and $\eta$.

\subsection{Expression for $\eta$}

I derive an analytical solution to $\eta$ (defined in \cref{perf-test:eq:eta}).
I assume the prior $\ntot \dist \NBc(\mu, r)$ is independent of $\vec{\theta}$, the parameters of the survival distribution.
Therefore, $p(\ntot \mid \vec{\theta}) = p(\ntot)$.

Putting a negative binomial prior on $\ntot$ is equivalent to the following gamma-Poisson composite; its use simplifies the derivation.
\begin{align}
\ntot \mid \lambda &\dist \Poi(\lambda) \\
\lambda &\dist \GamDist(a, b)
\end{align}
where $b = r / \mu$ and $a = r$.
Hence:
\begin{align}
\eta
&= \int \sum_{\ntot=\ndet}^\infty \frac{\ntot!}{(\ntot-\ndet)!} \pnodet^{\ntot-\ndet} p(\ntot \mid \lambda) p(\lambda) d\lambda &\text{$\lambda$ explicit}\\
&= \int \sum_{\ntot=\ndet}^\infty \frac{\ntot!}{(\ntot-\ndet)!} \pnodet^{\ntot-\ndet} \frac{\lambda^{\ntot} e^{-\lambda}}{\ntot!} p(\lambda) d\lambda &\ntot \dist \Poi\\
%&= \int \sum_{\ntot=\ndet}^\infty \frac{1}{(\ntot-\ndet)!} \pnodet^{\ntot-\ndet} \lambda^{\ntot-\ndet} \lambda^{\ndet} e^{-\lambda} p(\lambda) d\lambda \\
&= \int \lambda^{\ndet} e^{-\lambda} p(\lambda) \sum_{\nnodet=0}^\infty \frac{(\pnodet \lambda)^{\nnodet}}{\nnodet!} d\lambda &\nnodet = \ntot-\ndet\\
&= \int \lambda^{\ndet} e^{-\lambda} p(\lambda) e^{\lambda \pnodet} d\lambda &\text{Maclaurin series of $e$} \\
&= \int \lambda^{\ndet} e^{-\lambda(1 - \pnodet)} \frac{b^a}{\Gamma(a)} \lambda^{a-1} e^{-b\lambda} \lambda d\lambda &\lambda \dist \GamDist\\
&= \int \frac{b^a}{\Gamma(a)} \lambda^{a+\ndet-1} e^{-(b+1-\pnodet)\lambda} \lambda d\lambda \\
&= \frac{b^a}{\Gamma(a)} \frac{\Gamma(a+\ndet)}{(b+1-\pnodet)^{a+\ndet}} &\text{Gamma pdf}\\
&\propto (b+1-\pnodet)^{-(a+\ndet)} \\
&= (r/\mu + 1 - \pnodet)^{-(r+\ndet)} &\text{sub in $\mu$ and $r$}\\
&\propto(r + \mu (1- \pnodet))^{-(r+\ndet)}.
\end{align}

Substituting this into \cref{perf-test:eq:posterior1} gives:
\begin{align}
p(\vec{\theta} \mid \na)
&\propto p(\vec{\theta}) \left( \prod_{i \in \set{D}} p_k \right) (r + \mu (1- \pnodet))^{-(r+\ndet)} \label{perf-test:eq:full-posterior}.
\end{align}

% $\ntot$ is generally a nuisance parameter, however, its posterior distribution can be useful for diagnostic purposes (as in X\todo{ref where I use this in the next chapter}).
% Its posterior can be reconstructed using a posterior sample of $\vec{\theta}$.
% For each posterior sample of $\vec{\theta}$, sample from the full conditional of $\ntot$ to give the joint posterior of $\ntot$ and $\vec{\theta}$.
% The full conditional of $\ntot$ is given by:
% \begin{align}
% p(n_\text{tot} \mid \ncis, \vec{\theta})
% &\propto p(\ntot \mid \vec{\theta}) p(\ncis \mid \vec{\theta}, \ntot) \\
% &\propto p(\ntot \mid \vec{\theta}) \frac{\ntot!}{(\ntot - \ndet)!} \pnodet^{\ntot - \ndet} &\text{by \cref{perf-test:eq:augmented-likelihood}} \\
% &\propto \frac{\Gamma(r + \ntot)}{\ntot!} \left( \frac{\mu}{r + \mu} \right)^{\ntot} \frac{\ntot!}{(\ntot-\ndet)!} \pnodet^{\ntot} \\
% &= \frac{\Gamma(r + \ntot)}{(\ntot-\ndet)!} \left( \frac{\mu \pnodet}{r + \mu} \right)^{\ntot}  \\
% &= \frac{\Gamma((r + \ndet) + (\ntot- \ndet))}{(\ntot-\ndet)!} \left( \frac{\mu \pnodet}{r + \mu} \right)^{\ntot-\ndet}.
% \end{align}
% Comparing this expression to the pmf of a negative binomial, we find that $\nnodet = \ntot - \ndet$ is distributed negative binomial with size parameter $r+\ndet$ and probability parameter $(r + \mu(1 - \pnodet))/(r + \mu)$.
%The mean of this distribution is $(r+\ndet)\mu \pnodet/(r+\mu(1-\pnodet))$.

\subsection{Deriving $p_k$}

Recall the definitions $p_k = \prob(O(j) = \vec{\nu}_k \mid \vec{\theta})$ where $O(j)$ are the observations of episode $j$ and $\vec{\nu}_k = [l^{(b)}_k, r^{(b)}_k, l^{(e)}_k, r^{(e)}_k, i_k]^T$.

Decompose $p_k$ as $p_k = p_{ik} \prob(i(j) = i_k \mid \vec{\theta})$
where $p_{ik} = \prob(O(j) = \vec{\nu}_k \mid i(j) = i_k, \vec{\theta})$.
% This is valid as $\prob(O(j) = \nu_k \mid i(j) \neq i_k) = 0$ due to the condition here being equivalent to equating the two vectors' final elements.
Assume that each infection episode occurs independently and with equal probability in any individual, \ie $\prob(i(j) = i_k) = 1/\Ncis$ for all $j$ and $k$.

If $i(j) = i_k$ then the event $O(j) = \vec{\nu}_k$ occurs if and only if the episode starts in the interval $[l^{(b)}_k, r^{(b)}_k]$ and ends in the interval $[l^{(e)}_k, r^{(e)}_k]$.
Omitting the conditioning on $\vec{\theta}$ and $i(j) = i$, this gives:
\begin{align}
p_{ik}
=& \prob \left( l_k^{(b)} \leq B_{j} \leq r_k^{(b)}, l_k^{(e)} \leq E_{j} \leq r_k^{(e)} \right) \\
=& \prob \left( l_k^{(e)} \leq E_{j} \leq r_k^{(e)} \mid l_k^{(b)} \leq B_{j} \leq r_k^{(b)} \right) \times\prob \left( l_k^{(b)} \leq B_{j} \leq r_k^{(b)} \right) \\
=& \sum_{b = l_k^{(b)}}^{r_k^{(b)}} \prob \left( l_k^{(e)} \leq E_{j} \leq r_k^{(e)} \mid B_{j} = b \right) \prob \left(B_{j} = b \right) \\
=& \sum_{b = l_k^{(b)}}^{r_k^{(b)}} \prob \left( l_k^{(e)} - b + 1 \leq D_{j} \leq r_k^{(e)} - b + 1 \right) \prob \left(B_{j} = b \right) &\text{by def of $D_{j}$} \\
=& \sum_{b = l_k^{(b)}}^{r_k^{(b)}} \left( S_{\vec{\theta}}(l_k^{(e)} - b + 1) - S_{\vec{\theta}}(r_k^{(e)} - b + 2) \right) \prob \left(B_{j} = b \right) &\text{by def of $S_{\vec{\theta}}$} \\
\propto& \sum_{b = l_k^{(b)}}^{r_k^{(b)}} \left( S_{\vec{\theta}}(l_k^{(e)} - b + 1) - S_{\vec{\theta}}(r_k^{(e)} - b + 2) \right)
\label{perf-test:eq:pia}
\end{align}
under the assumption of uniform probability of infection time.
This is the standard form of the likelihood for doubly interval censored data without truncation~\autocite[e.g.][]{sunEmpirical}.

\subsection{Deriving $1 - p_u$} \label{perf-test:sec:prob-undetected}

The final component of \cref{perf-test:eq:full-posterior} required is $1 - p_u$.
Recall the definition $p_u = \prob(O(j) = \emptyset \mid \vec{\theta})$.
Therefore:
\begin{align}
  1 - p_u
  &= 1 - \sum_{i=1}^{\Ncis} \prob(O(j) = \emptyset, i(j) = i \mid \vec{\theta}) \\
  &= 1 - \sum_{i=1}^{\Ncis} \prob(O(j) = \emptyset \mid i(j) = i \mid \vec{\theta}) P(i(j) = i \mid \vec{\theta}) \\
  &= 1 - \frac{1}{\Ncis}\sum_{i=1}^{\Ncis} \prob(O(j) = \emptyset \mid i(j) = i \mid \vec{\theta}) \\
  &= \frac{1}{\Ncis} \sum_{i=1}^{\Ncis} (1 - \prob(O(j) = \emptyset \mid i(j) = i \mid \vec{\theta}))
  \label{perf-test:eq:pu}
\end{align}
assuming $P(i(j) = i \mid \vec{\theta}) = 1/\Ncis$ as before.
Let $p_{iu} = \prob(O(j) = \emptyset \mid i(j) = i, \vec{\theta})$.
Therefore, the crucial component is $1 - p_{iu}$.
This is one minus the probability that an episode in individual $i$ was undetected, \ie the probability of the episode being detected.

An episode $j$ in individual $i(j)$ is detected if and only if all the following conditions are met.
\begin{enumerate}
    \item $\exists t \in \sched_{i(j)}$ such that $b_j \leq t \leq e_j$; this condition is equivalent to having at least one positive test for the episode.
    \item $b_j > \min \sched_{i(j)}$.
      For individuals enrolled during the period considered ($\min \sched_{i(j)} > 0$), this ensures that the beginning of the episode is lower bounded; thereby adjusting for those who enrolled during the period being less likely to have a detected infection.
      For individuals enrolled prior to the period considered ($\min \sched_{i(j)} \leq 0$), this means that the episode was not detected prior to time 1.
    \item $b_j \leq T_{i(j)}$ where $T_{i(j)} = \max \{ t \in \sched_{i(j)} \ssep t \leq T \}$ is the last time that $i(j)$ is tested in the period, meaning that the test is detected within the period.
    \item $\exists t \in \sched_{i(j)}$ such that $t > e_j$, upper bounding the end of the episode.
      For episodes detected in the period I consider, a negligible number of episodes are excluded due to this critera.
      It only occurs in individuals lost to follow-up; therefore, I neglect this possibility.
      % For a new context, including recent infections, this condition could be relaxed by considering episodes that do not meet this criterion as right censored.
\end{enumerate}

% An episode is undetected if and only if no tests are performed during the episode or if there was no negative test prior to the episode.
% Equivalently, that the first test at or after $b$ is after $e$, or that there is no negative test prior to $b$.
First define $\tau_{\sched_i}(t)$ as the time until the next test at or after time $t$ in the schedule $\sched_i$:
\begin{align}
\tau_{\sched_i}(t) &= \min \{ t' \in \sched_i : t' \geq t \} - t
\label{perf-test:eq:tau-def}
\end{align}
% defining $\min \emptyset = \infty$; \ie $\tau_{\sched_i}(t) = \infty$ if there is no $t' \in \sched_i$ such that $t' \geq t$.
The first condition can now be expressed as $e_j \geq b_j + \tau_{\sched_{i(j)}}(b_j)$.
Equivalently, $d_j \geq \tau_{\sched_{i(j)}}(b_j) + 1$.
% The fourth condition can be expressed as $\tau_{\sched_{i(j)}}(b_j) < \infty$.


% Then $\Omega_i$ can be written as:
% \begin{align}
% \Omega_i = \{ (b, e) \ssep \tau_{\sched_i}(b) + b > e \vee b \leq \min(\sched_i) \}.
% \end{align}
Therefore, omitting the conditioning on $\vec{\theta}$ and $i(j) = i$:
\begin{align}
1 - p_{iu}
% &= 1 - \prob((B_{j}, E_{j}) \in \Omega_i) \\
&= \prob(D_j \geq \tau_{\sched_{i}}(B_j)+ 1, \min \sched_{i(j)} < B_j \leq T_{i(j)}) \\
&= \sum_{b = \min \sched_{i} + 1}^{T_{i(j)}} \prob(D_j \geq \tau_{\sched_{i}}(b) + 1 \mid B_j = b) \prob(B_j = b)\\
&\propto \sum_{b = \min \sched_{i} + 1}^{T_{i(j)}} S_{\vec{\theta}}(\tau_{\sched_{i}}(b) + 1).
\label{perf-test:eq:piu}
\end{align}

Substituting into \cref{perf-test:eq:pu}:
\begin{align}
1 - p_u
& \propto \sum_{i=1}^{\Ncis} \sum_{b = \min \sched_{i} + 1}^{T_{i(j)}} S_{\vec{\theta}}(\tau_{\sched_{i}}(b) + 1).
\end{align}

\section{Parameterisation and priors for the survival function} \label{perf-test:sec:parameters-priors}

In this section I specify the form of $S_{\vec{\theta}}(t)$.
I parameterize $S$ in terms of the hazard $S_{\vec{\theta}}(t) = \prod_{i=1}^{t-1} (1 - \lambda_{i})$ (see \cref{E-inc-prev:sec:definitions}).
Therefore, $\vec{\theta} = [\lambda_1, \dots, \lambda_{\dmax-1}]^T$.

Priors cannot be vague on both the hazard and the survival, the implications of which I consider in what follows.
Informative priors are also attractive to allow the incorporation of the estimates from \cref{E-ATACCC}.

\subsection{Independent priors} \label{perf-test:sec:independent-priors}
Take the standard assumption of independent priors on each parameter.
Each hazard, $\lambda_t$, is a (conditional) probability, and hence a Beta distribution is a natural choice.

Uninformative Beta priors on the hazard are problematic in this context.
An uninformative prior would be of the form $\lambda_t \dist \BetaDist(\alpha, \alpha)$.
Commonly, $\alpha$ is chosen to be $0.5$ (Jeffreys' Prior) or $1$ (a uniform prior).
Even though these priors are uninformative on the hazard, they become highly informative on the survival. 
Specifically, they tend to favour shorter survival times (see \cref{perf-test:fig:flat-prior}).
An intuitive explanation of this follows from the fact that priors of this form have an expected value of 0.5.
The expected survival time, $\E \left( \prod_{i=1}^{t-1} (1-\lambda_t) \right)$, is therefore equal to $0.5^{t-1}$, a quantity that declines rapidly.
This prior expresses extreme scepticism in estimates from previous studies, such as \cref{E-ATACCC} and the meta-analysis of \textcite{cevikShedding}.
\begin{figure}
  \centering \includegraphics{cis-perfect-testing/flat-prior}
  \caption[Uninformative priors for the hazard]{
    (A) Density of Beta(1, 1) flat prior and Beta(0.5, 0.5) uninformative priors.
    (B) Prior predictive survival time (mean and 95\% CrI).
    The implied prior on the survival time is short when using either prior on the hazard at each time.
  }
 \label{perf-test:fig:flat-prior}
\end{figure}

Instead, I propose a weakly informative (or vague) prior Beta(0.1, 1.9), which has mean 0.05 and minimal information.
The amount of information in a Beta distribution is related to the sum of its parameters.
Here, the sum equals 2, the same as the flat prior case.
The central 95\% probability mass of Beta(0.1, 1.9) is 0.00--0.47.
The central estimate, of 0.05, is in line with previous estimates that the median duration in the range 15--20 days~\autocite{cevikShedding}.
This prior gives a very vague prior predictive distribution on the survival time (see \cref{perf-test:fig:vague-prior}).
\begin{figure}
  \centering \includegraphics{cis-perfect-testing/vague-prior}
  \caption[Vague prior for the hazard]{
    (A) Density of Beta(0.1, 1.9) vague prior.
    (B) Prior predictive survival time (mean and 95\% CrI).
    Note the different x-axis to \cref{perf-test:fig:flat-prior}.
  }
  \label{perf-test:fig:vague-prior}
\end{figure}


\subsection{Smoothing priors}

Smoothing priors~\autocite{gerschSmoothness} encode the biological consideration that the hazard should not vary significantly from day-to-day.
They serve the same purpose as a penalized likelihood, which is often used in the non-parametric maximum-likelihood setting~\autocite[e.g.][]{bacchettiNonparametric}.
Many possible forms of smoothing priors exist, including splines, Gaussian Processes, and random walks.
I use a second-order random walk (RW2) because it is simple and produces sensible prior predictive distributions.

An RW2 prior encodes that the hazard should be linearly changing with some random changes at each time step.
Specifically, the difference on the logit scale between $\lambda_t$ to $\lambda_{t+1}$ is the difference between $\lambda_{t-1}$ and $\lambda_t$ plus some normally distributed noise.
Formally:
\begin{align}
  \logit\lambda_{t+1}
  &= \logit\lambda_t + (\logit\lambda_t - \logit\lambda_{t-1}) + \sigma \epsilon_t &\text{for $t \geq 2$} \\
  &= 2\logit\lambda_t - \logit\lambda_{t-1} + \sigma \epsilon_t \\
  \epsilon_t &\dist \N(0, 1) &\text{for $t \geq 2$}  \\
  \logit\lambda_2 &= \logit\lambda_1 + \epsilon_1 \\\
  \epsilon_1 &\dist \N(\mu_{\epsilon_1}, \sigma_{\epsilon_1}^2) \\
  \logit \lambda_1 &\dist \N(\mu_{\lambda_1}, \sigma_{\lambda_1}^2) \\
  \sigma &\dist \Exponential(1/\mu_\sigma).
\end{align}
The hyperparameters $\mu_{\lambda_1}$ and $\sigma_{\lambda_1}$ specify the prior on the hazard at time 1; $\mu_{\epsilon_1}$ and $\sigma_{\epsilon_1}$ specify the prior on the initial gradient, $\lambda_2 - \lambda_1$; and $\mu_\sigma$ specifies the smoothness of the random walk.
I use $\mu_{\lambda_1} = -17.5$, $\sigma_{\lambda_1} = 6$, $\mu_\epsilon = 1.09$, $\sigma_\epsilon = 0.03$, and $\mu_\epsilon = 0.1$ based on the analysis in \cref{E-ATACCC} (see \cref{perf-test:fig:rw2-prior}).
\begin{figure}
  \centering \includegraphics{cis-perfect-testing/rw2-prior}
  \caption[RW2 prior for the hazard]{The prior predictive survival time (mean and 95\% central interval) for the RW2 prior specified in the main text. The posterior mean estimate using ATACCC data in \cref{E-ATACCC} is shown for comparison. \label{perf-test:fig:rw2-prior}}
\end{figure}

\subsection{Model combination priors} \label{perf-test:sec:informative-priors}

The information from \cref{E-ATACCC} can be incorporated through the prior.
This is desirable because the ATACCC study frequently sampled individuals for around the first 20 days of their infection.
Therefore, the first 20 days of \cref{E-ATACCC}'s estimate of the survival distribution is reliable.
The CIS data can then inform the posterior after this point.

When constructing the prior, two aspects need consideration.
Firstly, the model structure from \cref{E-ATACCC} leads to the posterior distribution on the hazards having a positive correlation between $\lambda_t$ and $\lambda_{t'}$, especially when $t$ and $t'$ have a small difference.
The prior used in this analysis should preserve this correlation.
Secondly, the uncertainty in the estimates from \cref{E-ATACCC} is underestimated because it extrapolates beyond the data using strong model assumptions (see \cref{E-ATACCC:sec:discussion}).
%Furthermore, there are differences in the study design and laboratories used between the two studies (see \cref{E-intro:sec:studies}) which may mean that results do not generalise between the studies.
I form the prior to include this prior information into the CIS analysis in two steps.

I first approximate the \cref{E-ATACCC} posterior estimate of the hazard as $\logit{\vec{h}} \dist \MNorm(\vec{\mu}_A, \matr{\Sigma}_A)$ where $\vec{h}$ is the hazard, and $\vec{\mu}_A$ and $\matr{\Sigma}_A$ are the mean and covariance matrix computed from the samples of $\logit{\vec{h}}$ derived using the method of \cref{ATACCC:sec:duration}.
Using a multivariate normal, as opposed to multiple univariate distribution for each $h_t$, preserves the correlation between the hazards.
% The logit transformation maps from the $[0, 1]$ interval to the full real line.
The approximation is very good (see \cref{perf-test:fig:approximate-ATACCC-hazard} and \cref{perf-test:fig:approximate-ATACCC-survival}).
\begin{figure}
  \thisfloatpagestyle{empty}
  % \vspace{-1cm}
  \makebox[\textwidth][c]{\includegraphics[width=.9\paperwidth]{cis-perfect-testing/ataccc-approximation-hazard}}
  \caption[Approximating the ATACCC posterior hazard as a logit-normal]{Comparison of the posterior estimate of the hazard from \cref{E-ATACCC} and its approximation with a logit-normal distribution (kernel density estimate smoothed) for hazards between day 4 and 15. The density for smaller hazards is concentrated very close to 0. \label{perf-test:fig:approximate-ATACCC-hazard}}
\end{figure}
\begin{figure}
  \centering \includegraphics{cis-perfect-testing/ataccc-approximation-survival}
  \caption[Approximating the ATACCC posterior survival]{Comparison of the posterior estimate of the survival from \cref{E-ATACCC} and its approximation with a logit-normal distribution (median and central 95\% interval). The survival is a function of all the hazards up until that point, therefore the correlation between the hazards must be well-approximated to have these agree. \label{perf-test:fig:approximate-ATACCC-survival}}
\end{figure}

Having approximated the estimate as a multivariate normal, I add additional uncertainty using a discrete Beta process.
The discrete Beta process prior~\autocite{ibrahimBayesian,sunStatisticala} generalises the form of prior used in \cref{perf-test:sec:independent-priors} by allowing the central estimate of the hazard to vary over time.
It is:
\begin{align}
  \logit \vec{h} &\dist \MNorm(\vec{\mu}_A, \matr{\Sigma}_A) \\
  \lambda_t &\dist \text{Beta}(\alpha_t, \beta_t) &t = 1, 2, \dots \\
  \alpha_t &= k_t h_t + \alpha_0 \\
  \beta_t &= k_t (1 - h_t) + \beta_0
\end{align}
where $k_t$, $\alpha_0$, and $\beta_0$ are hyperparameters.
An intuition for what this distribution represents derives from a conjugate model for $\lambda_t$ with a beta prior and a binomial likelihood.
If $\lambda_t$ is given the prior distribution $\text{Beta}(\alpha_0, \beta_0)$, and we then have $k_t$ observations with $k_t h_t$ successes, then the posterior distribution for $\lambda_t$ is $\text{Beta}(\alpha_t, \beta_t)$ (as defined above).

$k_t$ reflects the subjective belief that the estimates from \cref{E-ATACCC} are very reliable in the early infection period but unreliable by day 30.
The equation for $k_t$ is below and shown in \cref{perf-test:fig:kt}.
\begin{align}
k_t = \begin{cases}
  \expit(-0.4 * (t - 20)) &\text{for $t \leq 39$} \\
  0 &t > 39
\end{cases}.
\end{align}

\begin{figure}
  \centering \includegraphics{cis-perfect-testing/kt-prior}
  \caption{Function used for $k_t$. \label{perf-test:fig:kt}}
\end{figure}

\section{Simulation study} \label{perf-test:sec:simulation-study}

\subsection{Setup}

I simulate a dataset of detected episodes with the same characteristics as that in the CIS by the following procedure.
\begin{enumerate}
    \item Extract the test schedules for each individual who had at least one test during the period of interest.
    \item Draw an episode start time, $b_{j}$ for each individual uniformly at random between 2 July 2020 ($t = -100$) and 6 December 2020 ($t = T$).
    \item Draw a duration of episode for each individual, $d_i$, based on the distribution described below. Then calculate the end of their infection episode, $e_{j} = b_{j} + d_i - 1$.
    \item Simulate the test results based on the test schedule, $b_{j}$, and $e_{j}$. Tests between $b_{j}$ and $e_{j}$ (inclusive) are positive, all other tests are negative.
    \item Discard episodes where there are no positive tests (\ie undetected episodes) and then apply the same inclusions/exclusions as in \cref{perf-test:sec:problem}.
    \item Of these remaining episodes, sample \numprint{4800} to match the sample size of the true dataset. This is needed because in step 2 the entire cohort was infected, while in the real study only an (unknown) portion is infected.
    \item For this final set of episodes, calculate $(l_j^{(b)}, r_j^{b}, l_j^{(e)}, r_j^{(e)})$ by taking the day after the last negative prior to any positives, the first positive, the last positive, and the day before the negative following the last positive respectively.
\end{enumerate}

Step 3 requires a distribution of the duration of detectability.
I base this assumption on the estimate from \cref{E-ATACCC} with an inflated tail to be consistent with the CIS.
I modify the tail based on an unpublished analysis of the CIS data~\citePersonalComms{A.\ Sarah Walker}.
Walker uses survival analysis to estimate the duration from CIS data.
This analysis assumes the initiating event is known, and equal to the episode’s detection time. 
It assumes the final event is interval censored between the time of the final positive test and the subsequent negative test, or right censored if a negative test has not yet been observed.
A flexible, spline-based form is used for the baseline survival function~\autocite{roystonSTPM,roystonFlexible} with covariates introduced via proportional odds.
By not accounting for either the undetected infections or the interval censoring of the initiating event, this analysis has competing biases which makes them hard to interpret~\autocite{cisMethodsONS}.

% \todo[inline]{The following seems important to justify why we can't just use these estimates but is also basically an aside}
% We know of two biases introduced from this analysis.
% \enquote{There is a bias in estimating the clearance distribution because the analysis used to estimate how long a person stays positive only starts from their first positive test.
% Since (most) people will have become positive on an earlier day, this will bias the clearance curves downwards (making the estimates too short).
% However, there is another bias due to the survey missing positive episodes entirely if they are short.
% This means that our dataset has fewer short positive episodes than in the population as a whole, and that the sample used to run the survival analysis is biased towards people with longer positive episodes.
% This will bias the clearance curves upwards (making the estimates too long).}~\autocite{cisMethodsONS}.

To form the duration distribution used in the simulation, we combine the two estimates.
The pdf over the first 30 days is proportional to the ATACCC estimate, with the rest proportional to this CIS-based estimate.
Denote by $f_A(t)$ the distribution function estimated in \cref{E-ATACCC} and $f_C(t)$ that from the CIS-based estimates just derived.
Then define:
$$
f_S'(t) = \begin{cases}
	f_A(t) &t \leq 30 \\
	f_C(t) &t > 30
\end{cases}
$$
Then the distribution used in the simulation is the normalised version of this: $f_S(t) = f'_S(t)/\sum_i f_S'(i)$.
These curves and the combined curve are compared in \cref{perf-test:fig:duration-dist}.
Individual $i$'s duration of detectability, $D_i$, is then an independent draw from this distribution.
\begin{figure}
  \centering \includegraphics{cis-perfect-testing/input-duration-dists}
  \caption[Comparison of duration distributions]{Comparison of the duration distribution used for the simulation. ATACCC is the posterior mean from \cref{E-ATACCC}'s analysis, CIS is Sarah Walker's analysis, and Combined is the combination of these used for the simulation. \label{perf-test:fig:duration-dist}}
\end{figure}

The prior on the total number of infections was centred on the true value with a dispersion parameter of 1.

\subsection{Implementation}

I implemented the simulation in R~4.2.0~\autocite{R-4-2-0} using tidyverse~2.0.0~\autocite{tidyverse}.

I implemented the inference in Stan via RStan~2.21.8~\autocite{rstan2-21-8} using default settings.
Convergence was assessed using Rhat and ESS as described in \cref{E-MCMC:sec:convergence}, and all runs checked for divergent transitions.
This meant that the prior was very diffuse.


\subsection{Results} \label{perf-test:sec:results}

Repeating the simulation showed negligible variation in the results (not shown) due to the large sample size (\numprint{4800} detected infections).
Therefore, I show and discuss results from only a single simulation.

All analyses converged.
Rhat were below 1.01, all parameters had an effective sample size of \numprint{1000}, and there were no divergent transitions.

The true value of the survival function was generally well recovered (see \cref{perf-test:fig:survival-results}).
This was especially true for the first 30 days of the distribution.

The second-order random walk prior performed worst.
It showed oversmoothing, especially in the later parts of the distribution.
It smooths towards a linearly changing hazard; here, linearly decreasing (see \cref{perf-test:fig:hazard-results}).
This means that the survival function decreases slower than an exponential distribution in the tail.

The informative and vague independent priors performed similarly, with the informative prior having tighter credible intervals.
% The informative prior was centred on the correct value for the initial part of the distribution.
% Therefore, the narrow credible intervals are unsurprising.
For hazards after day 40, the informative and vague priors are the same.
Therefore, the posterior distributions are almost identical.
There remains a difference because the hazard estimates are partially dependent on earlier estimates.

\begin{figure}
  \centering \includegraphics{cis-perfect-testing/survival-results}
  \caption[Comparison of survival function estimates under different priors]{Comparison of the posterior estimate of the survival distribution (pointwise median and 95\% CrI) when using different priors on the hazard. Results using each of the three different priors discussed in \cref{perf-test:sec:parameters-priors} are shown. y-axis has either natural (left) or log (right) scale. I show only the first 100 days of the distribution for readability. \label{perf-test:fig:survival-results}}
\end{figure}

\begin{figure}
  \centering \includegraphics{cis-perfect-testing/hazard-results}
  \caption[Comparison of hazard estimates under different priors]{Comparison of the posterior estimate of the hazard (pointwise median and 95\% CrI) when using different priors on the hazard. Results using each of the three different priors discussed in \cref{perf-test:sec:parameters-priors} are shown. \label{perf-test:fig:hazard-results}}
\end{figure}

\section{Discussion} \label{perf-test:sec:discussion}

This chapter shows that the model I propose can recover the true survival function well.
However, the problem becomes substantially harder if false negatives are present, as we shall see in the next chapter.
Unfortunately, false negatives do occur in the CIS data.

Reasonable choices of the prior for the hazard are vague (although not flat) or informative.
A smoothing prior performed poorly, although that may be influenced by the choice of hyperparameters.
Reducing the amount of smoothing or changing the type of smoothing may help.
More flexible smoothing priors could be used, such as a Gaussian Process for additional flexibility and smoothing and different timescales~\autocite{saulGaussian}.

The derivation in \cref{perf-test:sec:model} relied on an assumption that $O(j)$ and $O(j')$ occur independently for $j \neq j'$.
This is not the case, as immunity means that an individual previously infected is less likely to be infected in the future.
Additionally, the same individual cannot have multiple detected concurrent infections, due to the way that the episodes dataset is constructed (see \cref{E-biology-data:sec:cis-episodes}); this limits certain combinations from occurring.
In practice, this means that $n_k > 1$ cannot occur.
The simulation study violated this assumption to a large extent: each individual could only have one infection.
Despite this, the method performed well, recovering the true survival function.
Therefore, it is unlikely that this assumption matters, possibly due to the large number of individuals without detected episodes.
Further work could explore different assumptions, \eg a ``full immunity'' assumption meaning each individual has zero or one episode in the period.

Various extensions could be worth exploring.
Most importantly, including covariates (\eg age, immunity from vaccination and/or previous infection, or variant).
Immunity in particular affects the duration substantially, although age and variant may also make a contribution~\autocite{hakkiOnset,russellWithinhost}.
Covariates can be included with a variety of models, the simplest being a proportional hazards model.

The prior would likely be more important if the number of detected infections was smaller.
Therefore, exploring its impact could be important for future surveys.
A particular application would be estimation in the early stages of an epidemic of a novel pathogen.
Here, little would be known about the pathogen, but gathering information with robust estimates of uncertainty is important to inform the response.

I have assumed a prior of constant incidence and that incidence is independent between individuals.
Prevalence in the CIS data was approximately constant over the period of interest (see \cref{E-biology-data:sec:positivity-results}).
A sensitivity analysis, where an epidemic in exponential growth or decline was simulated (not shown), showed minimal impact on survival estimates.
An incorrect assumption of constant incidence can lead to biased estimates~\autocite{degruttolaAnalysis}.
Therefore, the assumption could be important in other contexts, especially if the incidence is changing rapidly.

I have developed a flexible simulation and inference framework for this type of analysis.
This framework could be used to simulate alternate study designs.
The design of CIS was created on a very short timescale in March 2020, in response to the pandemic's rapid spread.
Therefore, it is likely that there are more efficient designs.
These could be more cost-effective.
Improved cost-effectiveness could allow more rapid response to potential pandemics because the threshold for policymakers to approve the study would be lower.
A long-term, preparatory effort to develop a more efficient design in preparation for a future pandemic would be worthwhile.

Other useful preparatory work would be developing reasonable priors.
These could be based on seasonal viruses that are of the same family as those likely to cause future pandemics.
For example, seasonal influenzas and coronaviruses.
These would allow analyses such as those performed in these chapters to be performed more rapidly in a future pandemic scenario.

\section{Conclusion} \label{perf-test:sec:conclusion}
This chapter has shown the feasibility of estimating the survival function from a study with a CIS-like testing schedule.
While the infrequent testing schedule is not ideal, appropriate modelling can recover the true survival function well.


\ifSubfilesClassLoaded{
  \appendix
  \subfile{cis-perf-new-ll}
  \listoftodos
}{}
\end{document}